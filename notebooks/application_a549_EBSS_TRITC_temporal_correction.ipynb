{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from cellpose import models\n",
    "from cellpose.io import imread\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from PIL import Image, ImageSequence\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import os.path\n",
    "from livecell_tracker import segment\n",
    "from livecell_tracker import core\n",
    "from livecell_tracker.core import datasets\n",
    "from livecell_tracker.core.datasets import LiveCellImageDataset\n",
    "from skimage import measure\n",
    "from livecell_tracker.core import SingleCellTrajectory, SingleCellStatic\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "import cv2\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from livecell_tracker.segment.detectron_utils import gen_cfg\n",
    "\n",
    "from livecell_tracker.segment.detectron_utils import (\n",
    "    segment_detectron_wrapper,\n",
    "    segment_images_by_detectron,\n",
    "    convert_detectron_instance_pred_masks_to_binary_masks,\n",
    "    convert_detectron_instances_to_label_masks,\n",
    ")\n",
    "from livecell_tracker.segment.detectron_utils import (\n",
    "    convert_detectron_instance_pred_masks_to_binary_masks,\n",
    "    convert_detectron_instances_to_label_masks,\n",
    "    segment_images_by_detectron,\n",
    "    segment_single_img_by_detectron_wrapper,\n",
    ")\n",
    "\n",
    "\n",
    "dataset_dir_path = Path(\n",
    "    \"../datasets/test_data_STAV-A549/DIC_data\"\n",
    ")\n",
    "\n",
    "mask_dataset_path = Path(\"../datasets/test_data_STAV-A549/mask_data\")\n",
    "mask_dataset = LiveCellImageDataset(mask_dataset_path, ext=\"png\")\n",
    "dic_dataset = LiveCellImageDataset(dataset_dir_path, ext=\"tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir_path = Path(\n",
    "    \"../datasets/EBSS_Starvation/tif_STAV-A549_VIM_24hours_NoTreat_NA_YL_Ti2e_2022-12-21/XY16/\"\n",
    ")\n",
    "\n",
    "mask_dataset_path = Path(\"../datasets/EBSS_Starvation/tif_STAV-A549_VIM_24hours_NoTreat_NA_YL_Ti2e_2022-12-21/out/XY16/seg\")\n",
    "\n",
    "mask_dataset = LiveCellImageDataset(mask_dataset_path, ext=\"png\")\n",
    "time2url = sorted(glob.glob(str((Path(dataset_dir_path) / Path(\"*_DIC.tif\")))))\n",
    "time2url = {i: path for i, path in enumerate(time2url)}\n",
    "dic_dataset = LiveCellImageDataset(time2url=time2url, ext=\"tif\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert label masks to single objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from livecell_tracker.core.io_sc import process_scs_from_label_mask, prep_scs_from_mask_dataset\n",
    "\n",
    "single_cells = prep_scs_from_mask_dataset(mask_dataset, dic_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for testing\n",
    "# single_cells = single_cells[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(single_cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_cells_by_time = {}\n",
    "for cell in single_cells:\n",
    "    if cell.timeframe not in single_cells_by_time:\n",
    "        single_cells_by_time[cell.timeframe] = []\n",
    "    single_cells_by_time[cell.timeframe].append(cell)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize one single cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = single_cells[0]\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(10, 5))\n",
    "sc.show(ax=axes[0])\n",
    "sc.show_mask(ax=axes[1])\n",
    "sc.show_contour_img(ax=axes[2])\n",
    "sc.show_contour_mask(ax=axes[3])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate overlap between two single cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.show_mask(padding=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.show_contour_mask(padding=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc1 = single_cells_by_time[0][0]\n",
    "sc2 = single_cells_by_time[0][1]\n",
    "\n",
    "def compute_overlap_bf(sc1, sc2):\n",
    "    # calculate overlap\n",
    "    img_shape = sc1.get_img().shape\n",
    "    # TODO: add a helper function in single_cell to returna mask with only the current cell in it.\n",
    "    mask1 = sc1.get_contour_mask(padding=np.max(img_shape)).astype(bool)\n",
    "    mask2 = sc2.get_contour_mask(padding=np.max(img_shape)).astype(bool)\n",
    "\n",
    "    overlap_area = np.logical_and(mask1, mask2).sum()\n",
    "    iou = overlap_area / (mask1 | mask2).sum()\n",
    "    return overlap_area, iou\n",
    "\n",
    "def bbox_overlap(bbox1, bbox2):\n",
    "    # calculate overlap\n",
    "    x1_min, y1_min, x1_max, y1_max = bbox1\n",
    "    x2_min, y2_min, x2_max, y2_max = bbox2\n",
    "    x_overlap = max(0, min(x1_max, x2_max) - max(x1_min, x2_min))\n",
    "    y_overlap = max(0, min(y1_max, y2_max) - max(y1_min, y2_min))\n",
    "    overlap_area = x_overlap * y_overlap\n",
    "    bbox1_area = (x1_max - x1_min) * (y1_max - y1_min)\n",
    "    bbox2_area = (x2_max - x2_min) * (y2_max - y2_min)\n",
    "    iou = overlap_area / (bbox1_area + bbox2_area - overlap_area)\n",
    "    return overlap_area, iou\n",
    "\n",
    "def compute_overlap(sc1: SingleCellStatic, sc2: SingleCellStatic):\n",
    "    bbox1, bbox2 = sc1.get_bbox(), sc2.get_bbox()\n",
    "    bbox_overlap_area, bbox_iou = bbox_overlap(bbox1, bbox2)\n",
    "    if bbox_iou <= 0:\n",
    "        return 0, 0\n",
    "\n",
    "    merged_bbox = (min(bbox1[0], bbox2[0]), min(bbox1[1], bbox2[1]), max(bbox1[2], bbox2[2]), max(bbox1[3], bbox2[3]))\n",
    "    # calculate overlap\n",
    "    # TODO: add a helper function in single_cell to returna mask with only the current cell in it.\n",
    "    mask1 = sc1.get_contour_mask(crop=False)[merged_bbox[0]:merged_bbox[2], merged_bbox[1]:merged_bbox[3]]\n",
    "    mask2 = sc2.get_contour_mask(crop=False)[merged_bbox[0]:merged_bbox[2], merged_bbox[1]:merged_bbox[3]]\n",
    "    overlap_area = np.logical_and(mask1, mask2).sum()\n",
    "    iou = overlap_area / (mask1 | mask2).sum()\n",
    "    return overlap_area, iou\n",
    "t1, t2 = 0, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_compute_overlap():\n",
    "    for sc in single_cells:\n",
    "        for sc_tmp in single_cells:\n",
    "            # compare two overlap algorithms\n",
    "            overlap_area, iou = compute_overlap(sc, sc_tmp)\n",
    "            overlap_area_bf, iou_bf = compute_overlap_bf(sc, sc_tmp)\n",
    "            # print(overlap_area, overlap_area_bf)\n",
    "            assert overlap_area == overlap_area_bf\n",
    "            assert iou == iou_bf\n",
    "# test_compute_overlap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "def compute_overlaps(sc_list1, sc_list2):\n",
    "    overlap_map = {}\n",
    "    for sc1 in tqdm.tqdm(sc_list1, desc=\"Computing overlaps\"):\n",
    "        for sc2 in sc_list2:\n",
    "            overlap_area, iou = compute_overlap(sc1, sc2)\n",
    "            overlap_map[(sc1, sc2)] = (overlap_area, iou)\n",
    "    # parallel version\n",
    "    return overlap_map\n",
    "\n",
    "overlap_map_by_time = {}\n",
    "times = set(sorted(list(single_cells_by_time.keys())))\n",
    "max_time = max(times)\n",
    "interval = 20\n",
    "times_by_interval = [i for i in range(0, max_time, interval)]\n",
    "times_by_interval = set(times_by_interval)\n",
    "print(\"selected times: \", times_by_interval)\n",
    "for time in times_by_interval:\n",
    "    if time + 1 not in times:\n",
    "        print(f\"Time {time} is the last time point, skipping\")\n",
    "        continue\n",
    "    overlap_map_by_time[time] = compute_overlaps(single_cells_by_time[time], single_cells_by_time[time + 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc1, sc2 = single_cells_by_time[0][0], single_cells_by_time[1][0]\n",
    "overlap_map_by_time[0][(sc1, sc2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(single_cells_by_time[2])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the cells visually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for time in overlap_map_by_time:\n",
    "#     overlap_map = overlap_map_by_time[time]\n",
    "#     for sc_tmp1, sc_tmp2 in overlap_map:\n",
    "#         if sc_tmp1 == sc_tmp2:\n",
    "#             continue\n",
    "#         if overlap_map[(sc_tmp1, sc_tmp2)][0] > 0:\n",
    "#             print(sc_tmp1.timeframe, sc_tmp2.timeframe, overlap_map[(sc_tmp1, sc_tmp2)])\n",
    "#             fig, axes = plt.subplots(1, 6, figsize=(15, 5))\n",
    "#             padding=50\n",
    "#             sc_tmp1.show_contour_mask(crop=False, ax = axes[0])\n",
    "#             sc_tmp2.show_contour_mask(crop=False, ax = axes[1])\n",
    "#             sc_tmp1.show(crop=True, ax = axes[2], padding=padding)\n",
    "#             sc_tmp2.show(crop=True, ax = axes[3], padding=padding)\n",
    "#             sc_tmp1.show_contour_mask(crop=True, ax = axes[4], padding=padding)\n",
    "#             sc_tmp2.show_contour_mask(crop=True, ax = axes[5], padding=padding)\n",
    "#             plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(sc1.mask_dataset.get_img_by_time(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(sc1.mask_dataset.get_img_by_time(1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "sc.datasets[\"img\"]\n",
    "sc.datasets[\"mask\"]\n",
    "sc.datasets[\"label\"]\n",
    "sc.datasets[\"TRITC\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from livecell_tracker.segment.utils import match_mask_labels_by_iou\n",
    "def match_mask_labels_by_iou(seg_label_mask, gt_label_mask, bg_label=0, return_all=False):\n",
    "    \"\"\"compute the similarity between ground truth mask and segmentation mask by intersection over union\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    seg_label_mask : _type_\n",
    "        _description_\n",
    "    gt_label_mask : _type_\n",
    "        _description_\n",
    "    bg_label : int, optional\n",
    "        _description_, by default 0\n",
    "    return_all : bool, optional\n",
    "        _description_, by default False\n",
    "    Returns\n",
    "    -------\n",
    "        A <gt2seg_map>, mapping ground truth keys to a dictionary of the best matching segmentation label and its iou\n",
    "    \"\"\"\n",
    "    gt2seg_map = {}\n",
    "    all_gt2seg_iou__map = {}\n",
    "    # gets all the unique labels in the labeled_seg_mask and gtly_curated_mask\n",
    "    seg_labels = np.unique(seg_label_mask)\n",
    "    gt_labels = np.unique(gt_label_mask)\n",
    "\n",
    "    temp_seg_mask = seg_label_mask.copy()\n",
    "    temp_gt_mask = gt_label_mask.copy()\n",
    "\n",
    "    for gt_label in gt_labels:\n",
    "        if gt_label == bg_label:\n",
    "            continue\n",
    "        gt_label_key = gt_label\n",
    "        all_gt2seg_iou__map[gt_label_key] = []\n",
    "        gt2seg_map[gt_label_key] = {}\n",
    "        temp_gt_mask = gt_label_mask.copy()\n",
    "        # isolates the current cell in the temp gtly_curated_mask and gets its pixels to 1\n",
    "        temp_gt_mask[temp_gt_mask != gt_label] = 0\n",
    "        temp_gt_mask[temp_gt_mask != 0] = 1\n",
    "\n",
    "        best_iou = 0\n",
    "        for seg_label in seg_labels:\n",
    "            if seg_label == bg_label:\n",
    "                continue\n",
    "            temp_seg_mask = seg_label_mask.copy()\n",
    "\n",
    "            # isolate the current cell in the temp_seg_mask and set its pixels to 1\n",
    "            temp_seg_mask[temp_seg_mask != seg_label] = 0\n",
    "            temp_seg_mask[temp_seg_mask != 0] = 1\n",
    "\n",
    "            matching_rows, matching_columns = np.where(temp_seg_mask == 1)\n",
    "            intersection_area = (temp_gt_mask[matching_rows, matching_columns] == 1).sum()\n",
    "            union_area = temp_gt_mask.sum() + temp_seg_mask.sum() - intersection_area\n",
    "            iou = intersection_area / union_area\n",
    "            io_gt = intersection_area / temp_gt_mask.sum()\n",
    "            io_seg = intersection_area / temp_seg_mask.sum()\n",
    "            all_gt2seg_iou__map[gt_label_key].append({\n",
    "                \"seg_label\": seg_label,\n",
    "                \"iou\": iou,\n",
    "                \"io_gt\": io_gt,\n",
    "                \"io_seg\": io_seg,\n",
    "            })\n",
    "\n",
    "            if iou > best_iou:\n",
    "                best_iou = iou\n",
    "                gt2seg_map[gt_label_key][\"best_iou\"] = iou\n",
    "                gt2seg_map[gt_label_key][\"seg_label\"] = seg_label\n",
    "    if return_all:\n",
    "        return gt2seg_map, all_gt2seg_iou__map\n",
    "    else:\n",
    "        return gt2seg_map\n",
    "    \n",
    "match_mask_labels_by_iou(sc1.mask_dataset.get_img_by_time(2), sc1.mask_dataset.get_img_by_time(1), return_all=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply correction CNN to fix single time-frame case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from livecell_tracker.model_zoo.segmentation.sc_correction import CorrectSegNet\n",
    "# ckpt = r\"/home/ken67/LiveCellTracker-dev/notebooks/lightning_logs/version_real-02/checkpoints/epoch=3720-test_loss=0.0085.ckpt\"\n",
    "# ckpt = r\"/home/ken67/LiveCellTracker-dev/notebooks/lightning_logs/version_802/checkpoints/epoch=2570-test_out_matched_num_gt_iou_0.5_percent_real_underseg_cases=0.8548.ckpt\"\n",
    "ckpt = r\"/home/ken67/LiveCellTracker-dev/notebooks/lightning_logs/version_v10_02/checkpoints/epoch=2999-global_step=0.ckpt\"\n",
    "\n",
    "model = CorrectSegNet.load_from_checkpoint(ckpt)\n",
    "model = model.cuda()\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from livecell_tracker.segment.ou_utils import create_ou_input_from_sc\n",
    "from torchvision import transforms\n",
    "from livecell_tracker.preprocess.utils import normalize_img_to_uint8\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from scipy import ndimage\n",
    "from skimage.segmentation import watershed\n",
    "from skimage.feature import peak_local_max\n",
    "from scipy import ndimage as ndi\n",
    "import skimage\n",
    "from skimage.morphology import local_maxima, h_maxima\n",
    "from skimage.measure import regionprops, label\n",
    "\n",
    "\n",
    "input_transforms = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize(size=(412, 412)),\n",
    "        ]\n",
    ")\n",
    "from livecell_tracker.preprocess.utils import dilate_or_erode_mask\n",
    "def create_ou_input_from_sc(sc: SingleCellStatic, padding_pixels: int = 0, dtype=float, remove_bg=True, one_object=True, scale=0, bbox=None):\n",
    "    if bbox is None:\n",
    "        bbox = sc.get_bbox()\n",
    "    if remove_bg:\n",
    "        img_crop = sc.get_contour_img(padding=padding_pixels, bbox=bbox).astype(dtype)\n",
    "    else:\n",
    "        img_crop = sc.get_img_crop(padding=padding_pixels, bbox=bbox).astype(dtype)\n",
    "    img_crop = normalize_img_to_uint8(img_crop).astype(dtype)\n",
    "    if one_object:\n",
    "        sc_mask = sc.get_contour_mask(padding=padding_pixels, bbox=bbox)\n",
    "        sc_mask = dilate_or_erode_mask(sc_mask.astype(np.uint8), scale_factor=scale).astype(bool)\n",
    "        img_crop[~sc_mask] *= -1\n",
    "    else:\n",
    "        img_crop[sc.get_mask_crop(padding=padding_pixels, bbox=bbox) == 0] *= -1\n",
    "    return img_crop\n",
    "\n",
    "def viz_ou_sc_outputs(sc: SingleCellStatic, model, transforms, padding_pixels: int = 0, dtype=float, remove_bg=True, one_object=True, scale=0, out_threshold=1):\n",
    "    ou_input = create_ou_input_from_sc(sc, padding_pixels=padding_pixels, dtype=dtype, remove_bg=remove_bg, one_object=one_object, scale=scale)\n",
    "    viz_ou_outputs(ou_input, sc.get_sc_mask(padding=padding_pixels, dtype=int), model, transforms, out_threshold=out_threshold)\n",
    "\n",
    "\n",
    "def viz_ou_outputs(ou_input, original_mask, model, input_transforms, out_threshold, show=True):\n",
    "    original_shape = ou_input.shape\n",
    "    original_ou_input = ou_input.copy()\n",
    "    ou_input = input_transforms(torch.tensor([ou_input]))\n",
    "    ou_input = torch.stack([ou_input, ou_input, ou_input], dim=1)\n",
    "    ou_input = ou_input.float().cuda()\n",
    "    output = model(ou_input)\n",
    "\n",
    "    # transform (resize) output to original shape\n",
    "    back_transforms = transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize(size=(original_shape[0], original_shape[1])),\n",
    "            ]\n",
    "    )\n",
    "    output = back_transforms(output)\n",
    "\n",
    "    # perform watershed on output\n",
    "    marker_method = \"hmax\"\n",
    "    h_threshold = 20\n",
    "\n",
    "    # marker_method = \"local\"\n",
    "    # peak_distance = 50\n",
    "    markers = None\n",
    "    edt_distance = output.cpu().detach().numpy()[0, 0]\n",
    "    \n",
    "    if markers is None and marker_method == \"hmax\":\n",
    "        # local_hmax = h_maxima(raw_crop, h_threshold)\n",
    "        local_hmax = h_maxima(edt_distance, h_threshold)\n",
    "        markers = skimage.measure.label(local_hmax, connectivity=1)\n",
    "    elif markers is None and marker_method == \"local\":\n",
    "        # use local peak as default markers\n",
    "        coords = peak_local_max(edt_distance, min_distance=peak_distance, footprint=np.ones((3, 3)))\n",
    "        mask = np.zeros(edt_distance.shape, dtype=bool)\n",
    "        mask[tuple(coords.T)] = True\n",
    "        markers, _ = ndi.label(mask)\n",
    "\n",
    "    # labels = watershed(edt_distance, markers, mask=contour_mask)\n",
    "    if show:\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(8, 2))\n",
    "        axes[0].imshow(markers)\n",
    "        axes[0].set_title(\"markers\")\n",
    "        axes[1].imshow(edt_distance)\n",
    "        axes[1].set_title(\"edt_distance\")\n",
    "        plt.show()\n",
    "\n",
    "    # watershed_mask = watershed(-edt_distance, markers, mask=original_mask)\n",
    "    watershed_mask = watershed(-edt_distance, markers, mask=edt_distance > out_threshold)\n",
    "    \n",
    "    # visualize the input and all 3 output channels\n",
    "    if show:\n",
    "        fig, axes = plt.subplots(1, 7, figsize=(15, 5))\n",
    "        axes[0].imshow(original_ou_input)\n",
    "        axes[0].set_title(\"input\")\n",
    "        axes[1].imshow(output[0, 0].cpu().detach().numpy())\n",
    "        axes[1].set_title(\"output c0\")\n",
    "        axes[2].imshow(output[0, 1].cpu().detach().numpy())\n",
    "        axes[2].set_title(\"output c1\")\n",
    "        axes[3].imshow(output[0, 2].cpu().detach().numpy())\n",
    "        axes[3].set_title(\"output c2\")\n",
    "        axes[4].imshow(original_mask)\n",
    "        axes[4].set_title(\"original mask\")\n",
    "        axes[5].imshow(output[0, 0].cpu().detach().numpy() > out_threshold)\n",
    "        axes[5].set_title(\"output c0 > 1\")\n",
    "        axes[6].imshow(watershed_mask)\n",
    "        axes[6].set_title(\"watershed mask\")\n",
    "        plt.show()\n",
    "    return output, watershed_mask\n",
    "\n",
    "selected_sc_list = [single_cells_by_time[2][12], single_cells_by_time[2][13]]\n",
    "for i, sc in enumerate(selected_sc_list):\n",
    "    viz_ou_sc_outputs(sc, model, input_transforms, padding_pixels=50, dtype=float, remove_bg=True, one_object=True, scale=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sc in enumerate(selected_sc_list):\n",
    "    viz_ou_sc_outputs(sc, model, input_transforms, padding_pixels=50, dtype=float, remove_bg=False, one_object=True, scale=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sc in enumerate(selected_sc_list):\n",
    "    viz_ou_sc_outputs(sc, model, input_transforms, padding_pixels=50, dtype=float, remove_bg=False, one_object=False, scale=0.1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[TODO] judge if a case is oversegmentation\n",
    "inputs:\n",
    "    an input mask with other cells included\n",
    "    a corected label mask\n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply correction CNN to fix cells from two time frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from livecell_tracker.segment.utils import compute_match_label_map\n",
    "from livecell_tracker.core.parallel import parallelize\n",
    "\n",
    "times = sorted(mask_dataset.times)\n",
    "inputs = []\n",
    "for idx in times_by_interval:\n",
    "    t1 = idx\n",
    "    if t1+1 in times:\n",
    "        t2 = t1+1\n",
    "    else: \n",
    "        continue\n",
    "    inputs.append((t1, t2, mask_dataset))\n",
    "label_match_outputs = parallelize(compute_match_label_map, inputs, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(label_match_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_maps = []\n",
    "for t1, t2, label_map in label_match_outputs:\n",
    "    for label in label_map:\n",
    "        if len(label_map[label]) > 1:\n",
    "            # print(t1, t2, label, label_map[label])\n",
    "            multiple_maps.append((t1, t2, label, label_map[label]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1, t2, label, label_map = multiple_maps[4]\n",
    "figsize = (10, 5)\n",
    "\n",
    "sc1 = None\n",
    "for sc in single_cells_by_time[t1]:\n",
    "    if sc.meta[\"label_in_mask\"] == label:\n",
    "        sc1 = sc\n",
    "        sc.show_panel(figsize=figsize)\n",
    "\n",
    "sc2, sc3 = None, None\n",
    "t2_labels = list(label_map.keys())\n",
    "for sc in single_cells_by_time[t2]:\n",
    "    if sc.meta[\"label_in_mask\"] == t2_labels[0]:\n",
    "        sc2 = sc\n",
    "        sc.show_panel(figsize=figsize)\n",
    "    if sc.meta[\"label_in_mask\"] == t2_labels[1]:\n",
    "        sc3 = sc\n",
    "        sc.show_panel(figsize=figsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_ou_sc_outputs(sc1, model, input_transforms, padding_pixels=50, dtype=float, remove_bg=False, one_object=True, scale=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time2label2sc = {}\n",
    "for sc in single_cells:\n",
    "    if sc.timeframe not in time2label2sc:\n",
    "        time2label2sc[sc.timeframe] = {}\n",
    "    label = sc.meta[\"label_in_mask\"]\n",
    "    time2label2sc[sc.timeframe][label] = sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc2, sc3\n",
    "\n",
    "def combine_two_scs(sc1, sc2, padding=0):\n",
    "    mask1 = sc1.get_mask_crop(padding=padding, dtype=int)\n",
    "    mask2 = sc2.get_mask_crop(padding=padding, dtype=int)\n",
    "    mask2[mask2 > 0] += mask1.max()\n",
    "    mask = mask1 + mask2\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(\">\" * 80)\n",
    "    rand_map_idx = np.random.randint(len(multiple_maps))\n",
    "    t1, t2, label, label_map = multiple_maps[rand_map_idx]\n",
    "    sc1 = time2label2sc[t1][label]\n",
    "    sc2_label = list(label_map)[0]\n",
    "    sc2 = time2label2sc[t2][sc2_label]\n",
    "    sc3_label = list(label_map)[1]\n",
    "    sc3 = time2label2sc[t2][sc3_label]\n",
    "    sc1.show_panel()\n",
    "    sc2.show_panel()\n",
    "    sc3.show_panel()\n",
    "    padding_pixels = 0\n",
    "    one_object = True\n",
    "    out_threshold=3\n",
    "    viz_ou_sc_outputs(sc1, model, input_transforms, padding_pixels=padding_pixels, remove_bg=False, out_threshold=out_threshold, one_object=one_object)\n",
    "\n",
    "    bbox = sc1.get_bbox()\n",
    "    sc2_input = create_ou_input_from_sc(sc2, padding_pixels=padding_pixels, dtype=float, remove_bg=False, one_object=one_object, scale=0, bbox=bbox)\n",
    "    sc3_input = create_ou_input_from_sc(sc3, padding_pixels=padding_pixels, dtype=float, remove_bg=False, one_object=one_object, scale=0, bbox=bbox)\n",
    "    combined_input = np.maximum(sc2_input, sc3_input)\n",
    "    print(\"shape of combined input:\", combined_input.shape)\n",
    "    # plt.imshow(combined_input)\n",
    "    print(\">\" * 5, \"outputs of sc2 and sc3\")\n",
    "    viz_ou_outputs(combined_input, sc3.get_mask_crop(bbox=bbox), model, input_transforms, out_threshold=out_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_underseg(sc, show=True, remove_bg=False, min_area=500, out_threshold=1, padding_pixels=50, one_object=True):\n",
    "    ou_input = create_ou_input_from_sc(sc, padding_pixels=padding_pixels, dtype=int, remove_bg=remove_bg, one_object=one_object, scale=0)\n",
    "    output, watershed_mask = viz_ou_outputs(ou_input, sc.get_sc_mask(), model, input_transforms, out_threshold=out_threshold, show=show)\n",
    "    out_seg = output.cpu().detach().numpy()[0, 0]\n",
    "    out_seg = out_seg.astype(int)\n",
    "    regions = regionprops(out_seg)\n",
    "    # filter regions by area\n",
    "    regions = [r for r in regions if r.area > min_area]\n",
    "    return len(regions) > 1\n",
    "\n",
    "# is_underseg(sc1, show=True, remove_bg=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly select 1000 cells\n",
    "rand_single_cells = random.choices(single_cells, k=100)\n",
    "min_area=500\n",
    "for sc in rand_single_cells:\n",
    "    viz_ou_sc_outputs(sc, model, input_transforms, padding_pixels=50, dtype=float, remove_bg=False, one_object=True, scale=0)\n",
    "    res = is_underseg(sc, remove_bg=False, show=False, min_area=min_area)\n",
    "    if res:\n",
    "        is_underseg(sc, remove_bg=False, show=True, min_area=min_area)\n",
    "    print(\"is underseg?\", res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d9c7226d793827cd27273ad20fbb4775c3cb91053ab9378a09de5f8c6f258919"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
