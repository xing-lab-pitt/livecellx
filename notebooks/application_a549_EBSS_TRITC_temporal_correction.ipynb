{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from cellpose import models\n",
    "from cellpose.io import imread\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from PIL import Image, ImageSequence\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import os.path\n",
    "from livecellx import segment\n",
    "from livecellx import core\n",
    "from livecellx.core import datasets\n",
    "from livecellx.core.datasets import LiveCellImageDataset\n",
    "from skimage import measure\n",
    "from livecellx.core import SingleCellTrajectory, SingleCellStatic\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "import cv2\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from livecellx.segment.detectron_utils import gen_cfg\n",
    "\n",
    "from livecellx.segment.detectron_utils import (\n",
    "    segment_detectron_wrapper,\n",
    "    segment_images_by_detectron,\n",
    "    convert_detectron_instance_pred_masks_to_binary_masks,\n",
    "    convert_detectron_instances_to_label_masks,\n",
    ")\n",
    "from livecellx.segment.detectron_utils import (\n",
    "    convert_detectron_instance_pred_masks_to_binary_masks,\n",
    "    convert_detectron_instances_to_label_masks,\n",
    "    segment_images_by_detectron,\n",
    "    segment_single_img_by_detectron_wrapper,\n",
    ")\n",
    "\n",
    "\n",
    "dataset_dir_path = Path(\n",
    "    \"../datasets/test_data_STAV-A549/DIC_data\"\n",
    ")\n",
    "\n",
    "mask_dataset_path = Path(\"../datasets/test_data_STAV-A549/mask_data\")\n",
    "mask_dataset = LiveCellImageDataset(mask_dataset_path, ext=\"png\")\n",
    "dic_dataset = LiveCellImageDataset(dataset_dir_path, ext=\"tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir_path = Path(\n",
    "    \"../datasets/EBSS_Starvation/tif_STAV-A549_VIM_24hours_NoTreat_NA_YL_Ti2e_2022-12-21/XY16/\"\n",
    ")\n",
    "\n",
    "mask_dataset_path = Path(\"../datasets/EBSS_Starvation/tif_STAV-A549_VIM_24hours_NoTreat_NA_YL_Ti2e_2022-12-21/out/XY16/seg\")\n",
    "\n",
    "mask_dataset = LiveCellImageDataset(mask_dataset_path, ext=\"png\")\n",
    "time2url = sorted(glob.glob(str((Path(dataset_dir_path) / Path(\"*_DIC.tif\")))))\n",
    "time2url = {i: path for i, path in enumerate(time2url)}\n",
    "dic_dataset = LiveCellImageDataset(time2url=time2url, ext=\"tif\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert label masks to single objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from livecellx.core.io_sc import process_scs_from_label_mask, prep_scs_from_mask_dataset\n",
    "\n",
    "single_cells = prep_scs_from_mask_dataset(mask_dataset, dic_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for testing\n",
    "# single_cells = single_cells[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(single_cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_cells_by_time = {}\n",
    "for cell in single_cells:\n",
    "    if cell.timeframe not in single_cells_by_time:\n",
    "        single_cells_by_time[cell.timeframe] = []\n",
    "    single_cells_by_time[cell.timeframe].append(cell)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize one single cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = single_cells[0]\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(10, 5))\n",
    "sc.show(ax=axes[0])\n",
    "sc.show_mask(ax=axes[1])\n",
    "sc.show_contour_img(ax=axes[2])\n",
    "sc.show_contour_mask(ax=axes[3])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate overlap between two single cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.show_mask(padding=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.show_contour_mask(padding=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc1 = single_cells_by_time[0][0]\n",
    "sc2 = single_cells_by_time[0][1]\n",
    "\n",
    "def compute_overlap_bf(sc1, sc2):\n",
    "    # calculate overlap\n",
    "    img_shape = sc1.get_img().shape\n",
    "    # TODO: add a helper function in single_cell to returna mask with only the current cell in it.\n",
    "    mask1 = sc1.get_contour_mask(padding=np.max(img_shape)).astype(bool)\n",
    "    mask2 = sc2.get_contour_mask(padding=np.max(img_shape)).astype(bool)\n",
    "\n",
    "    overlap_area = np.logical_and(mask1, mask2).sum()\n",
    "    iou = overlap_area / (mask1 | mask2).sum()\n",
    "    return overlap_area, iou\n",
    "\n",
    "def bbox_overlap(bbox1, bbox2):\n",
    "    # calculate overlap\n",
    "    x1_min, y1_min, x1_max, y1_max = bbox1\n",
    "    x2_min, y2_min, x2_max, y2_max = bbox2\n",
    "    x_overlap = max(0, min(x1_max, x2_max) - max(x1_min, x2_min))\n",
    "    y_overlap = max(0, min(y1_max, y2_max) - max(y1_min, y2_min))\n",
    "    overlap_area = x_overlap * y_overlap\n",
    "    bbox1_area = (x1_max - x1_min) * (y1_max - y1_min)\n",
    "    bbox2_area = (x2_max - x2_min) * (y2_max - y2_min)\n",
    "    iou = overlap_area / (bbox1_area + bbox2_area - overlap_area)\n",
    "    return overlap_area, iou\n",
    "\n",
    "def compute_overlap(sc1: SingleCellStatic, sc2: SingleCellStatic):\n",
    "    bbox1, bbox2 = sc1.get_bbox(), sc2.get_bbox()\n",
    "    bbox_overlap_area, bbox_iou = bbox_overlap(bbox1, bbox2)\n",
    "    if bbox_iou <= 0:\n",
    "        return 0, 0\n",
    "\n",
    "    merged_bbox = (min(bbox1[0], bbox2[0]), min(bbox1[1], bbox2[1]), max(bbox1[2], bbox2[2]), max(bbox1[3], bbox2[3]))\n",
    "    # calculate overlap\n",
    "    # TODO: add a helper function in single_cell to returna mask with only the current cell in it.\n",
    "    mask1 = sc1.get_contour_mask(crop=False)[merged_bbox[0]:merged_bbox[2], merged_bbox[1]:merged_bbox[3]]\n",
    "    mask2 = sc2.get_contour_mask(crop=False)[merged_bbox[0]:merged_bbox[2], merged_bbox[1]:merged_bbox[3]]\n",
    "    overlap_area = np.logical_and(mask1, mask2).sum()\n",
    "    iou = overlap_area / (mask1 | mask2).sum()\n",
    "    return overlap_area, iou\n",
    "t1, t2 = 0, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_compute_overlap():\n",
    "    for sc in single_cells:\n",
    "        for sc_tmp in single_cells:\n",
    "            # compare two overlap algorithms\n",
    "            overlap_area, iou = compute_overlap(sc, sc_tmp)\n",
    "            overlap_area_bf, iou_bf = compute_overlap_bf(sc, sc_tmp)\n",
    "            # print(overlap_area, overlap_area_bf)\n",
    "            assert overlap_area == overlap_area_bf\n",
    "            assert iou == iou_bf\n",
    "# test_compute_overlap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "def compute_overlaps(sc_list1, sc_list2):\n",
    "    overlap_map = {}\n",
    "    for sc1 in tqdm.tqdm(sc_list1, desc=\"Computing overlaps\"):\n",
    "        for sc2 in sc_list2:\n",
    "            overlap_area, iou = compute_overlap(sc1, sc2)\n",
    "            overlap_map[(sc1, sc2)] = (overlap_area, iou)\n",
    "    # parallel version\n",
    "    return overlap_map\n",
    "\n",
    "overlap_map_by_time = {}\n",
    "times = set(sorted(list(single_cells_by_time.keys())))\n",
    "max_time = max(times)\n",
    "interval = 20\n",
    "times_by_interval = [i for i in range(0, max_time, interval)]\n",
    "times_by_interval = set(times_by_interval)\n",
    "print(\"selected times: \", times_by_interval)\n",
    "for time in times_by_interval:\n",
    "    if time + 1 not in times:\n",
    "        print(f\"Time {time} is the last time point, skipping\")\n",
    "        continue\n",
    "    overlap_map_by_time[time] = compute_overlaps(single_cells_by_time[time], single_cells_by_time[time + 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc1, sc2 = single_cells_by_time[0][0], single_cells_by_time[1][0]\n",
    "overlap_map_by_time[0][(sc1, sc2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(single_cells_by_time[2])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the cells visually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for time in overlap_map_by_time:\n",
    "#     overlap_map = overlap_map_by_time[time]\n",
    "#     for sc_tmp1, sc_tmp2 in overlap_map:\n",
    "#         if sc_tmp1 == sc_tmp2:\n",
    "#             continue\n",
    "#         if overlap_map[(sc_tmp1, sc_tmp2)][0] > 0:\n",
    "#             print(sc_tmp1.timeframe, sc_tmp2.timeframe, overlap_map[(sc_tmp1, sc_tmp2)])\n",
    "#             fig, axes = plt.subplots(1, 6, figsize=(15, 5))\n",
    "#             padding=50\n",
    "#             sc_tmp1.show_contour_mask(crop=False, ax = axes[0])\n",
    "#             sc_tmp2.show_contour_mask(crop=False, ax = axes[1])\n",
    "#             sc_tmp1.show(crop=True, ax = axes[2], padding=padding)\n",
    "#             sc_tmp2.show(crop=True, ax = axes[3], padding=padding)\n",
    "#             sc_tmp1.show_contour_mask(crop=True, ax = axes[4], padding=padding)\n",
    "#             sc_tmp2.show_contour_mask(crop=True, ax = axes[5], padding=padding)\n",
    "#             plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(sc1.mask_dataset.get_img_by_time(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(sc1.mask_dataset.get_img_by_time(1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "sc.datasets[\"img\"]\n",
    "sc.datasets[\"mask\"]\n",
    "sc.datasets[\"label\"]\n",
    "sc.datasets[\"TRITC\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from livecellx.segment.utils import match_mask_labels_by_iou\n",
    "match_mask_labels_by_iou(sc1.mask_dataset.get_img_by_time(2), sc1.mask_dataset.get_img_by_time(1), return_all=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply correction CNN to fix single time-frame case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from livecellx.model_zoo.segmentation.sc_correction import CorrectSegNet\n",
    "# ckpt = r\"/home/ken67/LiveCellTracker-dev/notebooks/lightning_logs/version_real-02/checkpoints/epoch=3720-test_loss=0.0085.ckpt\"\n",
    "# ckpt = r\"/home/ken67/LiveCellTracker-dev/notebooks/lightning_logs/version_802/checkpoints/epoch=2570-test_out_matched_num_gt_iou_0.5_percent_real_underseg_cases=0.8548.ckpt\"\n",
    "# ckpt = r\"/home/ken67/LiveCellTracker-dev/notebooks/lightning_logs/version_v10_02/checkpoints/epoch=2999-global_step=0.ckpt\"\n",
    "ckpt = r\"/home/ken67/LiveCellTracker-dev/notebooks/lightning_logs/version_v10_02/checkpoints/epoch=5999-global_step=0.ckpt\"\n",
    "\n",
    "model = CorrectSegNet.load_from_checkpoint(ckpt)\n",
    "model = model.cuda()\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from livecellx.segment.ou_utils import create_ou_input_from_sc\n",
    "from torchvision import transforms\n",
    "from livecellx.preprocess.utils import normalize_img_to_uint8, enhance_contrast\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from scipy import ndimage\n",
    "from skimage.segmentation import watershed\n",
    "from skimage.feature import peak_local_max\n",
    "from scipy import ndimage as ndi\n",
    "import skimage\n",
    "from skimage.morphology import local_maxima, h_maxima\n",
    "from skimage.measure import regionprops, label\n",
    "\n",
    "\n",
    "input_transforms = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize(size=(412, 412)),\n",
    "        ]\n",
    ")\n",
    "from livecellx.preprocess.utils import dilate_or_erode_mask\n",
    "\n",
    "def create_ou_input_from_sc(sc: SingleCellStatic, padding_pixels: int = 0, dtype=float, remove_bg=True, one_object=True, scale=0, bbox=None):\n",
    "    if bbox is None:\n",
    "        bbox = sc.get_bbox()\n",
    "    if remove_bg:\n",
    "        img_crop = sc.get_contour_img(padding=padding_pixels, bbox=bbox).astype(dtype)\n",
    "    else:\n",
    "        img_crop = sc.get_img_crop(padding=padding_pixels, bbox=bbox).astype(dtype)\n",
    "    img_crop = normalize_img_to_uint8(img_crop).astype(dtype)\n",
    "    if one_object:\n",
    "        sc_mask = sc.get_contour_mask(padding=padding_pixels, bbox=bbox)\n",
    "        sc_mask = dilate_or_erode_mask(sc_mask.astype(np.uint8), scale_factor=scale).astype(bool)\n",
    "        img_crop[~sc_mask] *= -1\n",
    "    else:\n",
    "        img_crop[sc.get_mask_crop(padding=padding_pixels, bbox=bbox) == 0] *= -1\n",
    "    return img_crop\n",
    "\n",
    "def viz_ou_sc_outputs(sc: SingleCellStatic, model, transforms, padding_pixels: int = 0, dtype=float, remove_bg=True, one_object=True, scale=0, out_threshold=1, save_path=None, show=True):\n",
    "    ou_input = create_ou_input_from_sc(sc, padding_pixels=padding_pixels, dtype=dtype, remove_bg=remove_bg, one_object=one_object, scale=scale)\n",
    "    viz_ou_outputs(ou_input, sc.get_sc_mask(padding=padding_pixels, dtype=int), model, transforms, out_threshold=out_threshold, original_img=sc.get_img_crop(padding=padding_pixels), save_path=save_path, show=show)\n",
    "\n",
    "\n",
    "def viz_ou_outputs(ou_input, original_mask, model, input_transforms, out_threshold, show=True, original_img=None, save_path=None):\n",
    "    original_shape = ou_input.shape\n",
    "    original_ou_input = ou_input.copy()\n",
    "    ou_input = input_transforms(torch.tensor([ou_input]))\n",
    "    ou_input = torch.stack([ou_input, ou_input, ou_input], dim=1)\n",
    "    ou_input = ou_input.float().cuda()\n",
    "    output = model(ou_input)\n",
    "\n",
    "    # transform (resize) output to original shape\n",
    "    back_transforms = transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize(size=(original_shape[0], original_shape[1])),\n",
    "            ]\n",
    "    )\n",
    "    output = back_transforms(output)\n",
    "\n",
    "    # perform watershed on output\n",
    "    marker_method = \"hmax\"\n",
    "    h_threshold = 20\n",
    "\n",
    "    # marker_method = \"local\"\n",
    "    # peak_distance = 50\n",
    "    markers = None\n",
    "    edt_distance = output.cpu().detach().numpy()[0, 0]\n",
    "    \n",
    "    if markers is None and marker_method == \"hmax\":\n",
    "        # local_hmax = h_maxima(raw_crop, h_threshold)\n",
    "        local_hmax = h_maxima(edt_distance, h_threshold)\n",
    "        markers = skimage.measure.label(local_hmax, connectivity=1)\n",
    "    elif markers is None and marker_method == \"local\":\n",
    "        # use local peak as default markers\n",
    "        coords = peak_local_max(edt_distance, min_distance=peak_distance, footprint=np.ones((3, 3)))\n",
    "        mask = np.zeros(edt_distance.shape, dtype=bool)\n",
    "        mask[tuple(coords.T)] = True\n",
    "        markers, _ = ndi.label(mask)\n",
    "\n",
    "    # labels = watershed(edt_distance, markers, mask=contour_mask)\n",
    "    if show:\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(8, 2))\n",
    "        axes[0].imshow(markers)\n",
    "        axes[0].set_title(\"markers\")\n",
    "        axes[1].imshow(edt_distance)\n",
    "        axes[1].set_title(\"edt_distance\")\n",
    "        plt.show()\n",
    "\n",
    "    # watershed_mask = watershed(-edt_distance, markers, mask=original_mask)\n",
    "    watershed_mask = watershed(-edt_distance, markers, mask=edt_distance > out_threshold)\n",
    "    \n",
    "    # visualize the input and all 3 output channels\n",
    "    if show or (save_path is not None):\n",
    "        if original_img is not None:\n",
    "            num_figures = 8\n",
    "        else:\n",
    "            num_figures = 7\n",
    "        fig, axes = plt.subplots(1, num_figures, figsize=(15, 5))\n",
    "        axes[0].imshow(original_ou_input)\n",
    "        axes[0].set_title(\"input\")\n",
    "        axes[1].imshow(output[0, 0].cpu().detach().numpy())\n",
    "        axes[1].set_title(\"output c0\")\n",
    "        axes[2].imshow(output[0, 1].cpu().detach().numpy())\n",
    "        axes[2].set_title(\"output c1\")\n",
    "        axes[3].imshow(output[0, 2].cpu().detach().numpy())\n",
    "        axes[3].set_title(\"output c2\")\n",
    "        axes[4].imshow(original_mask)\n",
    "        axes[4].set_title(\"original mask\")\n",
    "        axes[5].imshow(output[0, 0].cpu().detach().numpy() > out_threshold)\n",
    "        axes[5].set_title(\"output c0 > 1\")\n",
    "        axes[6].imshow(watershed_mask)\n",
    "        axes[6].set_title(\"watershed mask\")\n",
    "        if original_img is not None:\n",
    "            axes[7].imshow(enhance_contrast(normalize_img_to_uint8(original_img)))\n",
    "            axes[7].set_title(\"original img\")\n",
    "    if show:\n",
    "        plt.show()\n",
    "    if save_path is not None:\n",
    "        plt.savefig(save_path)\n",
    "\n",
    "    return output, watershed_mask\n",
    "\n",
    "selected_sc_list = [single_cells_by_time[2][12], single_cells_by_time[2][13]]\n",
    "for i, sc in enumerate(selected_sc_list):\n",
    "    viz_ou_sc_outputs(sc, model, input_transforms, padding_pixels=50, dtype=float, remove_bg=True, one_object=True, scale=0, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sc in enumerate(selected_sc_list):\n",
    "    viz_ou_sc_outputs(sc, model, input_transforms, padding_pixels=50, dtype=float, remove_bg=False, one_object=True, scale=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sc in enumerate(selected_sc_list):\n",
    "    viz_ou_sc_outputs(sc, model, input_transforms, padding_pixels=50, dtype=float, remove_bg=False, one_object=False, scale=0.1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[TODO] judge if a case is oversegmentation\n",
    "inputs:\n",
    "    an input mask with other cells included\n",
    "    a corected label mask\n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply correction CNN to fix cells from two time frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from livecellx.segment.utils import compute_match_label_map\n",
    "from livecellx.core.parallel import parallelize\n",
    "\n",
    "times = sorted(mask_dataset.times)\n",
    "inputs = []\n",
    "for idx in times_by_interval:\n",
    "    t1 = idx\n",
    "    if t1+1 in times:\n",
    "        t2 = t1+1\n",
    "    else: \n",
    "        continue\n",
    "    inputs.append((t1, t2, mask_dataset))\n",
    "label_match_outputs = parallelize(compute_match_label_map, inputs, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(label_match_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_maps = []\n",
    "for t1, t2, label_map in label_match_outputs:\n",
    "    for label in label_map:\n",
    "        if len(label_map[label]) > 1:\n",
    "            # print(t1, t2, label, label_map[label])\n",
    "            multiple_maps.append((t1, t2, label, label_map[label]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1, t2, label, label_map = multiple_maps[4]\n",
    "figsize = (10, 5)\n",
    "\n",
    "sc1 = None\n",
    "for sc in single_cells_by_time[t1]:\n",
    "    if sc.meta[\"label_in_mask\"] == label:\n",
    "        sc1 = sc\n",
    "        sc.show_panel(figsize=figsize)\n",
    "\n",
    "sc2, sc3 = None, None\n",
    "t2_labels = list(label_map.keys())\n",
    "for sc in single_cells_by_time[t2]:\n",
    "    if sc.meta[\"label_in_mask\"] == t2_labels[0]:\n",
    "        sc2 = sc\n",
    "        sc.show_panel(figsize=figsize)\n",
    "    if sc.meta[\"label_in_mask\"] == t2_labels[1]:\n",
    "        sc3 = sc\n",
    "        sc.show_panel(figsize=figsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_ou_sc_outputs(sc1, model, input_transforms, padding_pixels=50, dtype=float, remove_bg=False, one_object=True, scale=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time2label2sc = {}\n",
    "for sc in single_cells:\n",
    "    if sc.timeframe not in time2label2sc:\n",
    "        time2label2sc[sc.timeframe] = {}\n",
    "    label = sc.meta[\"label_in_mask\"]\n",
    "    time2label2sc[sc.timeframe][label] = sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_and_create_ou_input_from_scs(scs, bbox, create_ou_kwargs={\n",
    "    \"padding_pixels\": 0,\n",
    "    \"dtype\": float,\n",
    "    \"remove_bg\": False,\n",
    "    \"one_object\": True,\n",
    "    \"scale\": 0\n",
    "}):\n",
    "    assert len(scs) > 1\n",
    "    create_ou_kwargs.update({\"bbox\": bbox})\n",
    "    res_inputs =  create_ou_input_from_sc(scs[0], **create_ou_kwargs)\n",
    "    for sc in scs[1:]:\n",
    "        sc_input = create_ou_input_from_sc(sc, **create_ou_kwargs)\n",
    "        res_inputs = np.maximum(res_inputs, sc_input)\n",
    "    return res_inputs\n",
    "\n",
    "for i in range(10):\n",
    "    print(\">\" * 80)\n",
    "    rand_map_idx = np.random.randint(len(multiple_maps))\n",
    "    t1, t2, label, label_map = multiple_maps[rand_map_idx]\n",
    "    sc1 = time2label2sc[t1][label]\n",
    "    sc2_label = list(label_map)[0]\n",
    "    sc2 = time2label2sc[t2][sc2_label]\n",
    "    sc3_label = list(label_map)[1]\n",
    "    sc3 = time2label2sc[t2][sc3_label]\n",
    "    sc1.show_panel()\n",
    "    sc2.show_panel()\n",
    "    sc3.show_panel()\n",
    "    padding_pixels = 0\n",
    "    one_object = True\n",
    "    out_threshold=3\n",
    "    remove_bg = False\n",
    "    viz_ou_sc_outputs(sc1, model, input_transforms, padding_pixels=padding_pixels, remove_bg=remove_bg, out_threshold=out_threshold, one_object=one_object)\n",
    "\n",
    "    bbox = sc1.get_bbox()\n",
    "    create_ou_kwargs = {\n",
    "        \"padding_pixels\": padding_pixels,\n",
    "        \"dtype\": float,\n",
    "        \"remove_bg\": remove_bg,\n",
    "        \"one_object\": one_object,\n",
    "        \"scale\": 0\n",
    "    }\n",
    "    combined_input = combine_and_create_ou_input_from_scs([sc2, sc3], bbox=bbox)\n",
    "    print(\"shape of combined input:\", combined_input.shape)\n",
    "    # plt.imshow(combined_input)\n",
    "    print(\">\" * 5, \"outputs of sc2 and sc3\")\n",
    "    viz_ou_outputs(combined_input, sc3.get_mask_crop(bbox=bbox), model, input_transforms, out_threshold=out_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_underseg(sc, show=True, remove_bg=False, min_area=500, out_threshold=1, padding_pixels=50, one_object=True):\n",
    "    ou_input = create_ou_input_from_sc(sc, padding_pixels=padding_pixels, dtype=int, remove_bg=remove_bg, one_object=one_object, scale=0)\n",
    "    output, watershed_mask = viz_ou_outputs(ou_input, sc.get_sc_mask(), model, input_transforms, out_threshold=out_threshold, show=show, original_img = sc.get_sc_img())\n",
    "    out_seg = output.cpu().detach().numpy()[0, 0]\n",
    "    out_seg = out_seg.astype(int)\n",
    "    regions = regionprops(out_seg)\n",
    "    # filter regions by area\n",
    "    regions = [r for r in regions if r.area > min_area]\n",
    "    return len(regions) > 1\n",
    "\n",
    "# is_underseg(sc1, show=True, remove_bg=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly select 1000 cells\n",
    "rand_single_cells = random.sample(single_cells, k=6000)\n",
    "min_area=100\n",
    "os.makedirs(\"./notebook_results/ou_sc_pred_figures\", exist_ok=True)\n",
    "\n",
    "for i, sc in enumerate(rand_single_cells):\n",
    "    viz_ou_sc_outputs(sc, model, input_transforms, padding_pixels=50, dtype=float, remove_bg=False, one_object=True, scale=0, save_path=\"./notebook_results/ou_sc_pred_figures/{}.png\".format(i), show=False)\n",
    "    plt.clf()\n",
    "    # res = is_underseg(sc, remove_bg=False, show=False, min_area=min_area)\n",
    "    # if res:\n",
    "    #     is_underseg(sc, remove_bg=False, show=True, min_area=min_area)\n",
    "    # print(\"is underseg?\", res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d9c7226d793827cd27273ad20fbb4775c3cb91053ab9378a09de5f8c6f258919"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
