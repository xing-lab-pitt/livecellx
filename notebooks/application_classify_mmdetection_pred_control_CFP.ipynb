{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# from cellpose import models\n",
    "from cellpose.io import imread\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from PIL import Image, ImageSequence\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import os.path\n",
    "# from livecell_tracker import segment\n",
    "from livecell_tracker import core\n",
    "from livecell_tracker.core import datasets\n",
    "from livecell_tracker.core.datasets import LiveCellImageDataset, SingleImageDataset\n",
    "from skimage import measure\n",
    "from livecell_tracker.core import SingleCellTrajectory, SingleCellStatic\n",
    "# import detectron2\n",
    "# from detectron2.utils.logger import setup_logger\n",
    "\n",
    "# setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "import cv2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate single cells from a mask dataset and write single cell json data to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = \"XY10\"\n",
    "dic_dir = \"/home/ken67/LiveCellTracker-dev/datasets/tifs_CFP_A549_VIM_120hr_NoTreat_NA_YL_Ti2e_2023-03-22/XY10/DIC\"\n",
    "dic_dataset = LiveCellImageDataset(dir_path=dic_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# dataset_dir_path = Path(\n",
    "#     f\"../datasets/EBSS_Starvation/tif_STAV-A549_VIM_24hours_NoTreat_NA_YL_Ti2e_2022-12-21/{pos}/\"\n",
    "# )\n",
    "\n",
    "# mask_dataset_path = Path(f\"../datasets/EBSS_Starvation/tif_STAV-A549_VIM_24hours_NoTreat_NA_YL_Ti2e_2022-12-21/out/{pos}/seg\")\n",
    "\n",
    "# mask_dataset = LiveCellImageDataset(mask_dataset_path, ext=\"png\")\n",
    "# time2url = sorted(glob.glob(str((Path(dataset_dir_path) / Path(\"*_DIC.tif\")))))\n",
    "# time2url = {i: path for i, path in enumerate(time2url)}\n",
    "# dic_dataset = LiveCellImageDataset(time2url=time2url, ext=\"tif\")\n",
    "\n",
    "# from livecell_tracker.segment.utils import prep_scs_from_mask_dataset\n",
    "# single_cells = prep_scs_from_mask_dataset(mask_dataset, dic_dataset)\n",
    "\n",
    "# scs_write_path = f\"./datasets/test_scs_EBSS_starvation/{pos}/scs.json\"\n",
    "# dataset_dir = Path(f\"./datasets/test_scs_EBSS_starvation/{pos}/datasets\")\n",
    "# SingleCellStatic.write_single_cells_json(single_cells, scs_write_path, dataset_dir=dataset_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "# model_dir = Path(r\"./scripts/mmdetection_classify/work_dirs/tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb-v6-combined-clipL=2-CLIP_NUM=4/\")\n",
    "# model_dir = Path(r\"./scripts/mmdetection_classify/work_dirs/tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb-v8-combined-clipLen=2-trainClipNum=3-valClipNum=3\")\n",
    "# model_dir = Path(r\"./scripts/mmdetection_classify/work_dirs/tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb-v8-combined-clipLen=1-trainClipNum=3-valClipNum=3\")\n",
    "# path = r\"./scripts/mmdetection_classify/work_dirs/tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb-v6-combined-clipL=2/best_acc_top1_epoch_28.pth\"\n",
    "# model = torch.load(path)\n",
    "# model_dir = Path(r\"./scripts/mmdetection_classify/work_dirs/tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb-v9-combined-clipLen=3-trainClipNum=3-valClipNum=3\")\n",
    "# model_dir = Path(r\"./scripts/mmdetection_classify/work_dirs/tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb-v10-st-combined-clipLen=3-trainClipNum=3-valClipNum=3\")\n",
    "# model_dir = Path(r\"./scripts/mmdetection_classify/work_dirs/tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb-v10-drop-div-combined-clipLen=2-trainClipNum=3-valClipNum=3\")\n",
    "model_dir = Path(r\"./scripts/mmdetection_classify/work_dirs/tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb-v10-st-combined-clipLen=2-trainClipNum=3-valClipNum=3\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read a trained MMAction model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmengine.config import Config, DictAction\n",
    "from mmaction.registry import MODELS\n",
    "config_file = str(model_dir / \"tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb.py\")\n",
    "# checkpoint_file = str(model_dir / \"best_acc_top1_epoch_5.pth\")\n",
    "# checkpoint_file = str(model_dir / \"epoch_52.pth\")\n",
    "# checkpoint_file = str(model_dir / \"best_acc_top1_epoch_126.pth\")\n",
    "# checkpoint_file = str(model_dir / \"epoch_250.pth\")\n",
    "checkpoint_file = str(model_dir / \"epoch_59.pth\")\n",
    "cfg = Config.fromfile(config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = MODELS.build()\n",
    "import mmcv\n",
    "from mmaction.apis import init_recognizer, inference_recognizer\n",
    "\n",
    "DEVICE = 'cuda:0' # or 'cpu', based on your device\n",
    "model = init_recognizer(config_file, checkpoint_file, device=DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cellpose.models \n",
    "pretrained_model_path = \"/home/ken67/LiveCellTracker-dev/notebooks/notebook_results/cellpose/cellpose_A549_cyto2_cellbody/models/cellpose_residual_on_style_on_concatenation_off_cellpose_A549_cyto2_cellbody_2023_04_17_21_49_50.313712\"\n",
    "cp_model = cellpose.models.CellposeModel(pretrained_model=pretrained_model_path, gpu=True) #, model_type=\"cyto2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "preliminary check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: move to pkg\n",
    "\n",
    "from livecell_tracker.preprocess.utils import enhance_contrast, standard_preprocess\n",
    "from livecell_tracker.segment.cellpose_utils import segment_single_images_by_cellpose, segment_single_image_by_cellpose\n",
    "import random\n",
    "\n",
    "num_img_to_viz = 5\n",
    "times = dic_dataset.times\n",
    "diameters = [30, 50, 80, 100]\n",
    "for i in range(0, num_img_to_viz):\n",
    "    # randomly sample a time from the dataset\n",
    "    img = dic_dataset[times[random.randint(0, len(times) - 1)]]\n",
    "    # img = normalize_img_to_uint8(img)\n",
    "    img = standard_preprocess(img)\n",
    "    masks = []\n",
    "    for diameter in diameters:\n",
    "        mask = segment_single_image_by_cellpose(img, cp_model, channels=[[0, 0]], diameter=diameter)\n",
    "        masks.append(mask)\n",
    "\n",
    "    # visualize\n",
    "    fig_num = 1 + len(diameters)\n",
    "    fig, axes = plt.subplots(1, fig_num, figsize=(fig_num * 5, 5))\n",
    "    axes[0].imshow(enhance_contrast(img))\n",
    "    axes[0].set_title(\"raw image\")\n",
    "    for i, mask in enumerate(masks):\n",
    "        axes[i + 1].imshow(mask)\n",
    "        axes[i + 1].set_title(\"diameter: {}\".format(diameters[i]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from livecell_tracker.core.io_utils import save_png\n",
    "# import tqdm\n",
    "selected_diameter = 80\n",
    "out_dir = Path(os.path.join('./notebook_results', f'CFP_{pos}_diameter={selected_diameter}'))\n",
    "# mask_out_dir = out_dir / 'masks'\n",
    "# mask_out_dir.mkdir(parents=True, exist_ok=True)\n",
    "# filename = \"mask_time-{}.png\"\n",
    "# times = dic_dataset.times\n",
    "# for i in tqdm(range(0, len(dic_dataset))):\n",
    "#     # randomly sample a time from the dataset\n",
    "#     time = times[i]\n",
    "#     img = dic_dataset[time]\n",
    "#     # img = normalize_img_to_uint8(img)\n",
    "#     img = standard_preprocess(img)\n",
    "#     for diameter in diameters:\n",
    "#         mask = segment_single_image_by_cellpose(img, cp_model, channels=[[0, 0]], diameter=diameter)\n",
    "#         # save the mask\n",
    "#         save_png(os.path.join(mask_out_dir, filename.format(int(time))), mask)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_dataset_path = r\"/home/ken67/LiveCellTracker-dev/notebooks/notebook_results/CFP_XY10_diameter=80/masks\"\n",
    "mask_dataset = LiveCellImageDataset(dir_path=mask_dataset_path, ext=\"png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from livecell_tracker.segment.ou_simulator import find_contours_opencv\n",
    "test_mask = mask_dataset.get_img_by_time(31) == 1\n",
    "plt.imshow(test_mask)\n",
    "find_contours_opencv(test_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import livecell_tracker.core.io_sc\n",
    "from livecell_tracker.core.io_sc import prep_scs_from_mask_dataset\n",
    "import importlib\n",
    "importlib.reload(livecell_tracker.core.io_sc)\n",
    "scs = livecell_tracker.core.io_sc.prep_scs_from_mask_dataset(mask_dataset=mask_dataset, img_dataset=dic_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(livecell_tracker.core.single_cell)\n",
    "scs_json_path = out_dir / \"cellpose_raw_scs.json\"\n",
    "livecell_tracker.core.single_cell.SingleCellStatic.write_single_cells_json(scs, scs_json_path, dataset_dir=out_dir/\"dataset\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read single cell object data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from livecell_tracker.core.single_cell import SingleCellTrajectoryCollection, SingleCellStatic\n",
    "from livecell_tracker.track.sort_tracker_utils import (\n",
    "    track_SORT_bbox_from_scs\n",
    ")\n",
    "\n",
    "# all_scs_json_path = \"./datasets/test_scs_EBSS_starvation/tmp_corrected_scs.json\"\n",
    "# all_scs_json_path = f\"./datasets/test_scs_EBSS_starvation/{pos}/scs.json\"\n",
    "# all_scs = SingleCellStatic.load_single_cells_json(all_scs_json_path)\n",
    "all_scs = SingleCellStatic.load_single_cells_json(scs_json_path)\n",
    "sctc = track_SORT_bbox_from_scs(all_scs, raw_imgs=all_scs[0].img_dataset, min_hits=3, max_age=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from livecell_tracker.core.sc_video_utils import gen_mp4_from_frames, gen_class2sample_samples, gen_samples_mp4s\n",
    "\n",
    "# importlib reload import above\n",
    "import importlib\n",
    "importlib.reload(core.sc_video_utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_classify_output_dir = Path(f\"./notebook_results/tmp_CFP_data_{pos}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from livecell_tracker.track.classify_utils import gen_one_sc_samples_by_window, gen_inference_sctc_sample_videos\n",
    "sc_samples = []\n",
    "samples_info_list = []\n",
    "\n",
    "\n",
    "tid2samples = gen_one_sc_samples_by_window(sctc, window_size=7)\n",
    "for tid, samples in tid2samples.items():\n",
    "    for i, sample in enumerate(samples):\n",
    "        sc_samples.append(sample)\n",
    "        samples_info_list.append({\"tid\": tid, \"sample_idx\": i})\n",
    "\n",
    "saved_sample_info_df = gen_inference_sctc_sample_videos(sctc, padding_pixels=[20, 50, 100], out_dir=video_classify_output_dir, prefix=f\"{pos}\", fps=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_sample_info_df.to_csv(video_classify_output_dir / \"sample_info.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read `saved_sample_info_df` if processed earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "saved_sample_info_dir = video_classify_output_dir / \"sample_info.csv\"\n",
    "saved_sample_info_df = pd.read_csv(saved_sample_info_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_classify_output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_sample_info_df[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mitosis_tids = set()\n",
    "mitosis_rows = []\n",
    "for i, row in tqdm(saved_sample_info_df.iterrows()):\n",
    "    video_path = row[\"path\"]\n",
    "    video_path = str(video_classify_output_dir / \"videos\" / video_path)\n",
    "    results = inference_recognizer(model, video_path)\n",
    "    predicted_label = results.pred_labels.item.cpu().numpy()[0]\n",
    "    if predicted_label == 0:\n",
    "        print(\"mitosis found:\", row[\"path\"])\n",
    "        mitosis_rows.append(row)\n",
    "        mitosis_tids.add(row[\"track_id\"])\n",
    "\n",
    "mitosis_tids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mitosis_rows[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy videos from paths from mitosis rows to a subfolder\n",
    "import shutil\n",
    "mitosis_video_dir = Path(\"notebook_results/tmp_mitosis_videos\")\n",
    "mitosis_video_dir.mkdir(exist_ok=True, parents=True)\n",
    "for i, row in tqdm(enumerate(mitosis_rows)):\n",
    "    filename = row[\"path\"]\n",
    "    video_path = str(video_classify_output_dir / \"videos\" / filename)\n",
    "    shutil.copy(video_path, mitosis_video_dir / filename)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmcv.video.io import VideoReader\n",
    "import tempfile\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from livecell_tracker.track.classify_utils import video_frames_and_masks_from_sample, combine_video_frames_and_masks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize mitosis cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from livecell_tracker.core.sct_operator import create_scts_operator_viewer\n",
    "\n",
    "# mitosis_tids = [7, 4, 1, 16] # EBSS less than 24h, xy1, by <tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb-v6-combined-clipL=2>\n",
    "mitosis_tids = [tid for tid in track_id_to_sample_results if 0 in track_id_to_sample_results[tid]]\n",
    "mitosis_tids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from livecell_tracker.core.sct_operator import create_scts_operator_viewer, create_scs_edit_viewer\n",
    "\n",
    "# scts_operator = create_scs_edit_viewer(single_cells, img_dataset = dic_dataset, time_span=(145, 155))\n",
    "# # If you would like to start from sctc, you can use the following code\n",
    "# scts_operator = create_scts_operator_viewer(sctc, img_dataset = dic_dataset) #, time_span=(1, 2))\n",
    "# scts_operator = create_scts_operator_viewer(sctc.subset(mitosis_tids), img_dataset = dic_dataset) #, time_span=(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = inference_recognizer(model, r\"D:\\LiveCellTracker-dev\\notebooks\\notebook_results\\mmaction_train_data_v5\\videos\\mitosis_2_combined_padding-40.mp4\")\n",
    "# results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load test dataframe and evaluate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# video_dir = r\"./notebook_results/mmaction_train_data_v5/videos\"\n",
    "# mmaction_data_tsv = r\"./notebook_results/mmaction_train_data_v6/test_data_combined.txt\"\n",
    "# video_dir = r\"./notebook_results/mmaction_train_data_v8/videos\"\n",
    "# mmaction_data_tsv = r\"./notebook_results/mmaction_train_data_v8/mmaction_test_data_combined.txt\"\n",
    "# mmaction_data_tsv = r\"./notebook_results/mmaction_train_data_v8/mmaction_train_data_combined.txt\"\n",
    "# video_dir = r\"./notebook_results/mmaction_train_data_v9/videos\"\n",
    "# mmaction_data_tsv = r\"./notebook_results/mmaction_train_data_v9/mmaction_test_data_combined.txt\"\n",
    "# video_dir = r\"./notebook_results/mmaction_train_data_v10-st/videos\"\n",
    "# mmaction_data_tsv = r\"./notebook_results/mmaction_train_data_v10-st/mmaction_test_data_combined.txt\"\n",
    "video_dir = r\"./notebook_results/mmaction_train_data_v10-drop-div/videos\"\n",
    "mmaction_data_tsv = r\"./notebook_results/mmaction_train_data_v10-drop-div/mmaction_test_data_combined.txt\"\n",
    "\n",
    "# df columns are path and label\n",
    "mmaction_data_df = pd.read_csv(mmaction_data_tsv, sep=\" \", header=None)\n",
    "mmaction_data_df.columns = [\"path\", \"label\"]\n",
    "mmaction_data_df[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "# test on all video in the df\n",
    "video_paths = []\n",
    "gt_labels = []\n",
    "for i, row in tqdm(mmaction_data_df.iterrows()):\n",
    "    video_path = os.path.join(video_dir, row[\"path\"])\n",
    "    video_paths.append(video_path)\n",
    "    gt_labels.append(row[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt2total = {}\n",
    "gt2correct = {}\n",
    "for i, video_path in tqdm(enumerate(video_paths)):\n",
    "    results = inference_recognizer(model, video_path)\n",
    "    predicted_label = results.pred_labels.item.cpu().numpy()[0]\n",
    "    gt_label = gt_labels[i]\n",
    "    if gt_label not in gt2total:\n",
    "        gt2total[gt_label] = 0\n",
    "        gt2correct[gt_label] = 0\n",
    "    gt2total[gt_label] += 1\n",
    "    if predicted_label != gt_labels[i]:\n",
    "        print(\"wrong prediction:\", video_path, \"predicted_label:\", predicted_label, \"gt_label:\", gt_labels[i])\n",
    "    else:\n",
    "        gt2correct[gt_label] += 1\n",
    "\n",
    "for gt_label, total in gt2total.items():\n",
    "    correct = gt2correct[gt_label]\n",
    "    print(\"gt_label:\", gt_label, \"total:\", total, \"correct:\", correct, \"acc:\", correct / total)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "livecell-work",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
