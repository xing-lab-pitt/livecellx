{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from cellpose import models\n",
    "from cellpose.io import imread\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from PIL import Image, ImageSequence\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import os.path\n",
    "# from livecell_tracker import segment\n",
    "from livecell_tracker import core\n",
    "from livecell_tracker.core import datasets\n",
    "from livecell_tracker.core.datasets import LiveCellImageDataset, SingleImageDataset\n",
    "from skimage import measure\n",
    "from livecell_tracker.core import SingleCellTrajectory, SingleCellStatic\n",
    "# import detectron2\n",
    "# from detectron2.utils.logger import setup_logger\n",
    "\n",
    "# setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "import cv2\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "# from detectron2 import model_zoo\n",
    "# from detectron2.engine import DefaultPredictor\n",
    "# from detectron2.config import get_cfg\n",
    "# from detectron2.utils.visualizer import Visualizer\n",
    "# from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "# from livecell_tracker.segment.detectron_utils import gen_cfg\n",
    "\n",
    "# from livecell_tracker.segment.detectron_utils import (\n",
    "#     segment_detectron_wrapper,\n",
    "#     segment_images_by_detectron,\n",
    "#     convert_detectron_instance_pred_masks_to_binary_masks,\n",
    "#     convert_detectron_instances_to_label_masks,\n",
    "# )\n",
    "# from livecell_tracker.segment.detectron_utils import (\n",
    "#     convert_detectron_instance_pred_masks_to_binary_masks,\n",
    "#     convert_detectron_instances_to_label_masks,\n",
    "#     segment_images_by_detectron,\n",
    "#     segment_single_img_by_detectron_wrapper,\n",
    "# )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading single cells from existing mask files"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```LiveCellImageDataset, SingleCellImageDataset``` from livecell_tracker.core.datasets allow users to load images with ease, without reading directly into memories.  \n",
    "In `mask_dataset_path` please make sure that the sorted (alphabetically) file names correspond to the order of times.\n",
    " Note that the sorted mechanism provided is simply sort the url (file name) list according to string value. Please note that without proper left trailing zeroes, the order of final times may be incorrect. E.g. string  `T10` (10th file) is less than string `T2`. If you have your customized file patterns, please provide `LiveCellImageDataset` with a `time2url` dictionary to provide necessary time information mapped to file locations for reading time-lapsed data.\n",
    "`SingleCellImageDataset` takes a single image from the memory and makes it a single time point dataset, which can be handy when you would like to process imaging datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir_path = Path(\n",
    "    \"../datasets/test_data_STAV-A549/DIC_data\"\n",
    ")\n",
    "\n",
    "mask_dataset_path = Path(\"../datasets/test_data_STAV-A549/mask_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_dataset = LiveCellImageDataset(mask_dataset_path, ext=\"png\")\n",
    "mask_dataset.time2url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_dataset = LiveCellImageDataset(dataset_dir_path, ext=\"tif\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if the `time2url` mapping is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_dataset.time2url"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert label masks to single objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.measure import regionprops\n",
    "from livecell_tracker.segment.utils import prep_scs_from_mask_dataset\n",
    "single_cells = prep_scs_from_mask_dataset(mask_dataset, dic_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sc in single_cells:\n",
    "    assert sc.mask_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for testing\n",
    "# single_cells = single_cells[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(single_cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_cells_by_time = {}\n",
    "for cell in single_cells:\n",
    "    if cell.timeframe not in single_cells_by_time:\n",
    "        single_cells_by_time[cell.timeframe] = []\n",
    "    single_cells_by_time[cell.timeframe].append(cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for time in single_cells_by_time:\n",
    "    print(time, len(single_cells_by_time[time]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize one single cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = single_cells[0]\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(10, 5))\n",
    "sc.show(ax=axes[0])\n",
    "sc.show_mask(ax=axes[1])\n",
    "sc.show_contour_img(ax=axes[2])\n",
    "sc.show_contour_mask(ax=axes[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.show_panel(figsize=(15, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc1 = single_cells[1]\n",
    "sc2 = single_cells[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from livecell_tracker.trajectory.feature_extractors import compute_skimage_regionprops, compute_haralick_features\n",
    "\n",
    "skimage_features = compute_skimage_regionprops(sc1)\n",
    "sc1.add_feature(\"skimage\", skimage_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# haralick_features = compute_haralick_features(sc1)\n",
    "# sc1.add_feature(\"haralick\", haralick_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc1.get_feature_pd_series()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate overlap between two single cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc1.compute_iou(sc2), sc1.compute_overlap_percent(sc2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracking based on single cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from livecell_tracker.track.sort_tracker_utils import (\n",
    "    gen_SORT_detections_input_from_contours,\n",
    "    update_traj_collection_by_SORT_tracker_detection,\n",
    "    track_SORT_bbox_from_contours,\n",
    "    track_SORT_bbox_from_scs\n",
    ")\n",
    "\n",
    "\n",
    "traj_collection = track_SORT_bbox_from_scs(single_cells, dic_dataset, mask_dataset=mask_dataset, max_age=1, min_hits=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from livecell_tracker.track.movie import generate_single_trajectory_movie\n",
    "\n",
    "# for track_id, traj in traj_collection:\n",
    "#     generate_single_trajectory_movie(traj, save_path=f\"./notebook_results/general_tutorial/track_movies/track_{track_id}.gif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_collection.histogram_traj_length()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for track_id, traj in traj_collection:\n",
    "#     print(\"track_id=\", track_id)\n",
    "#     traj.timeframe_to_single_cell[list(traj.timeframe_to_single_cell.keys())[0]].show_panel(figsize=(20, 5))\n",
    "#     plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%gui qt\n",
    "from livecell_tracker.core.napari_visualizer import NapariVisualizer\n",
    "import napari\n",
    "from skimage import data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of all_shapes 38 length of track_ids 38 length of all_scs 38 length of all_scts 0\n"
     ]
    }
   ],
   "source": [
    "from livecell_tracker.core.single_cell import SingleCellStatic, SingleCellTrajectory, SingleCellTrajectoryCollection\n",
    "import numpy as np\n",
    "from napari.viewer import Viewer\n",
    "from livecell_tracker.core.visualizer import Visualizer\n",
    "\n",
    "from livecell_tracker.core.single_cell import SingleCellStatic, SingleCellTrajectory, SingleCellTrajectoryCollection\n",
    "import numpy as np\n",
    "from napari.viewer import Viewer\n",
    "from livecell_tracker.core.visualizer import Visualizer\n",
    "\n",
    "\n",
    "class NapariVisualizer:\n",
    "    def viz_traj(traj: SingleCellTrajectory, viewer: Viewer, viewer_kwargs=None):\n",
    "        if viewer_kwargs is None:\n",
    "            viewer_kwargs = dict()\n",
    "        shapes = traj.get_scs_napari_shapes()\n",
    "        shape_layer = viewer.add_shapes(shapes, **viewer_kwargs)\n",
    "        return shape_layer\n",
    "\n",
    "    @staticmethod\n",
    "    def map_colors(values, cmap=\"viridis\"):\n",
    "        import matplotlib\n",
    "        import matplotlib.cm as cm\n",
    "\n",
    "        minima = min(values)\n",
    "        maxima = max(values)\n",
    "\n",
    "        norm = matplotlib.colors.Normalize(vmin=minima, vmax=maxima, clip=True)\n",
    "        mapper = cm.ScalarMappable(norm=norm, cmap=cmap)\n",
    "        res_colors = [mapper.to_rgba(v) for v in values]\n",
    "        return res_colors\n",
    "\n",
    "    def viz_trajectories(\n",
    "        trajectories: SingleCellTrajectoryCollection,\n",
    "        viewer: Viewer,\n",
    "        bbox=False,\n",
    "        contour_sample_num=100,\n",
    "        viewer_kwargs=None,\n",
    "        text_parameters={\n",
    "            \"string\": \"track_id: {track_id}\\n\",\n",
    "            \"size\": 12,\n",
    "            \"color\": \"white\",\n",
    "            \"anchor\": \"upper_left\",\n",
    "            \"translation\": [-2, 0],\n",
    "        },\n",
    "    ):\n",
    "        if viewer_kwargs is None:\n",
    "            viewer_kwargs = dict()\n",
    "        all_shapes = []\n",
    "        track_ids = []\n",
    "        all_scs = []\n",
    "        all_scts = []\n",
    "        for track_id, traj in trajectories:\n",
    "            traj_shapes, scs = traj.get_scs_napari_shapes(bbox=bbox, contour_sample_num=contour_sample_num, return_scs=True)\n",
    "            all_shapes.extend(traj_shapes)\n",
    "            track_ids.extend([int(track_id)] * len(traj_shapes))\n",
    "            all_scs.extend(scs)\n",
    "        print(\"length of all_shapes\", len(all_shapes), \"length of track_ids\", len(track_ids), \"length of all_scs\", len(all_scs), \"length of all_scts\", len(all_scts))\n",
    "        properties = {\"track_id\": track_ids, \"sc\": all_scs}\n",
    "        shape_layer = viewer.add_shapes(\n",
    "            all_shapes,\n",
    "            properties=properties,\n",
    "            face_color=NapariVisualizer.map_colors(properties[\"track_id\"]),\n",
    "            face_colormap=\"viridis\",\n",
    "            shape_type=\"polygon\",\n",
    "            text=text_parameters,\n",
    "            name=\"trajectories\",\n",
    "            **viewer_kwargs\n",
    "        )\n",
    "        return shape_layer\n",
    "\n",
    "\n",
    "viewer = napari.view_image(dic_dataset.to_dask(), name='dic_image', cache=True)\n",
    "shape_layer = NapariVisualizer.viz_trajectories(traj_collection, viewer, contour_sample_num=20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [TODO] Connect two trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.select_prior_shape(event)>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current shape layer shape properties:  Event\n",
      "{'track_id': array([13]), 'sc': array([<livecell_tracker.core.single_cell.SingleCellStatic object at 0x00000267F862FDC0>],\n",
      "      dtype=object)}\n",
      "setting face color of selected shape...\n",
      "current shape layer shape properties:  Event\n",
      "{'track_id': array([13]), 'sc': array([<livecell_tracker.core.single_cell.SingleCellStatic object at 0x00000267F862FDC0>],\n",
      "      dtype=object)}\n",
      "setting face color of selected shape...\n",
      "current shape layer shape properties:  Event\n",
      "{'track_id': array([12]), 'sc': array([<livecell_tracker.core.single_cell.SingleCellStatic object at 0x00000267F862FE50>],\n",
      "      dtype=object)}\n",
      "setting face color of selected shape...\n",
      "current shape layer shape properties:  Event\n",
      "{'track_id': array([12]), 'sc': array([<livecell_tracker.core.single_cell.SingleCellStatic object at 0x00000267F862FE50>],\n",
      "      dtype=object)}\n",
      "setting face color of selected shape...\n",
      "current shape layer shape properties:  Event\n",
      "{'track_id': array([10]), 'sc': array([<livecell_tracker.core.single_cell.SingleCellStatic object at 0x00000267F862FEB0>],\n",
      "      dtype=object)}\n",
      "setting face color of selected shape...\n",
      "current shape layer shape properties:  Event\n",
      "{'track_id': array([10]), 'sc': array([<livecell_tracker.core.single_cell.SingleCellStatic object at 0x00000267F862FEB0>],\n",
      "      dtype=object)}\n",
      "setting face color of selected shape...\n",
      "current shape layer shape properties:  Event\n",
      "{'track_id': array([8]), 'sc': array([<livecell_tracker.core.single_cell.SingleCellStatic object at 0x00000267F862FF10>],\n",
      "      dtype=object)}\n",
      "setting face color of selected shape...\n",
      "current shape layer shape properties:  Event\n",
      "{'track_id': array([8]), 'sc': array([<livecell_tracker.core.single_cell.SingleCellStatic object at 0x00000267F862FF10>],\n",
      "      dtype=object)}\n",
      "setting face color of selected shape...\n",
      "current shape layer shape properties:  Event\n",
      "{'track_id': array([9]), 'sc': array([<livecell_tracker.core.single_cell.SingleCellStatic object at 0x00000267F862FEE0>],\n",
      "      dtype=object)}\n",
      "setting face color of selected shape...\n",
      "current shape layer shape properties:  Event\n",
      "{'track_id': array([7]), 'sc': array([<livecell_tracker.core.single_cell.SingleCellStatic object at 0x00000267F862FF40>],\n",
      "      dtype=object)}\n",
      "setting face color of selected shape...\n",
      "current shape layer shape properties:  Event\n",
      "{'track_id': array([7]), 'sc': array([<livecell_tracker.core.single_cell.SingleCellStatic object at 0x00000267F862FF40>],\n",
      "      dtype=object)}\n",
      "setting face color of selected shape...\n",
      "current shape layer shape properties:  Event\n",
      "{'track_id': array([11]), 'sc': array([<livecell_tracker.core.single_cell.SingleCellStatic object at 0x00000267F862FE80>],\n",
      "      dtype=object)}\n",
      "setting face color of selected shape...\n",
      "current shape layer shape properties:  Event\n",
      "{'track_id': array([11]), 'sc': array([<livecell_tracker.core.single_cell.SingleCellStatic object at 0x00000267F862FE80>],\n",
      "      dtype=object)}\n",
      "setting face color of selected shape...\n"
     ]
    }
   ],
   "source": [
    "def select_prior_shape(event):\n",
    "    print(\"current shape layer shape properties: \", event)\n",
    "    current_properties = shape_layer.current_properties\n",
    "    assert len(current_properties[\"sc\"]) == 1 and len(current_properties[\"track_id\"]) == 1\n",
    "    if len(shape_layer.selected_data) > 1:\n",
    "        print(\"Please select only one shape at a time for connecting trajectories\")\n",
    "        return\n",
    "    if len(shape_layer.selected_data) == 0:\n",
    "        print(\"No shape selected, please select a shape to connect trajectories\")\n",
    "        return\n",
    "    selected_shape_index = list(shape_layer.selected_data)[0]\n",
    "    cur_sc = current_properties[\"sc\"][0]\n",
    "    cur_track_id = current_properties[\"track_id\"][0]\n",
    "    cur_sct = traj_collection[cur_track_id]\n",
    "    \n",
    "    print(\"setting face color of selected shape...\")\n",
    "    face_colors = list(shape_layer.face_color)\n",
    "    face_colors[selected_shape_index] = (1, 0, 0, 1) \n",
    "    shape_layer.face_color = face_colors\n",
    "    shape = shape_layer.data[selected_shape_index]\n",
    "\n",
    "    # print(shape_layer.data)\n",
    "    # time = viewer.dims.current_step[0]\n",
    "    return cur_sct, cur_sc, selected_shape_index\n",
    "\n",
    "viewer = napari.view_image(dic_dataset.to_dask(), name='dic_image', cache=True)\n",
    "shape_layer = NapariVisualizer.viz_trajectories(traj_collection, viewer, contour_sample_num=20)\n",
    "shape_layer.events.current_properties.connect(select_prior_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = shape_layer.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_layer.face_color = [(0, 0, 0, 1)] * len(shape_layer.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# viewer.layers.selection.events.active.connect(lambda x: print(dir(x)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "livecell-work",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "255678bf1dfb9ba523bc95259de6240bcf8a006858e5b3039c84beb7773ff68c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
