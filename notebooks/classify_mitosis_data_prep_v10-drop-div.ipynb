{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare mitosis time series data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from cellpose import models\n",
    "from cellpose.io import imread\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from PIL import Image, ImageSequence\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import os.path\n",
    "# from livecell_tracker import segment\n",
    "from livecell_tracker import core\n",
    "from livecell_tracker.core import datasets\n",
    "from livecell_tracker.core.datasets import LiveCellImageDataset, SingleImageDataset\n",
    "from skimage import measure\n",
    "from livecell_tracker.core import SingleCellTrajectory, SingleCellStatic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_json_dir = Path(\"./EBSS_starvation_24h_xy16_annotation\")\n",
    "\n",
    "sample_json_dirs = [Path(r\"./datasets/test_scs_EBSS_starvation/XY1/annotations\"), Path(r\"./datasets/test_scs_EBSS_starvation/XY16/annotations\")]\n",
    "\n",
    "def load_class2samples_from_json_dir(sample_json_dir: Path, class_subfolders = [\"mitosis\", \"apoptosis\", \"normal\"]) -> dict:\n",
    "    # sample_paths = glob.glob(str(sample_json_dir / \"*.json\"))\n",
    "    class2samples = {}\n",
    "    for subfolder in class_subfolders:\n",
    "        class2samples[subfolder] = []\n",
    "        sample_paths = glob.glob(str(sample_json_dir / subfolder / \"*.json\"))\n",
    "        for sample_path in sample_paths:\n",
    "            sample = SingleCellStatic.load_single_cells_json(sample_path)\n",
    "            class2samples[subfolder].append(sample)\n",
    "    return class2samples\n",
    "\n",
    "\n",
    "all_class2samples = None\n",
    "all_class2sample_extra_info = {}\n",
    "for sample_json_dir in sample_json_dirs:\n",
    "    _class2samples = load_class2samples_from_json_dir(sample_json_dir)\n",
    "    print(_class2samples)\n",
    "    for class_name in _class2samples:\n",
    "        # report how many samples loaded from the sample json dir\n",
    "        print(f\"Loaded {len(_class2samples[class_name])} annotated samples from {sample_json_dir / class_name}\")\n",
    "\n",
    "    if all_class2samples is None:\n",
    "        all_class2samples = _class2samples\n",
    "    for class_name in _class2samples:\n",
    "\n",
    "        all_class2samples[class_name] += _class2samples[class_name]\n",
    "        _extra_info =  [{\"src_dir\": sample_json_dir} for _ in range(len(_class2samples[class_name]))]\n",
    "        if class_name not in all_class2sample_extra_info:\n",
    "            all_class2sample_extra_info[class_name] = _extra_info\n",
    "        else:\n",
    "            all_class2sample_extra_info[class_name] += _extra_info\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_class2sample_extra_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_class2samples[\"mitosis\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Automatically prepare normal samples\n",
    "\n",
    "require tracking done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all scs from class_samples not in normal class\n",
    "exclude_scs = []\n",
    "total_non_normal_samples = 0\n",
    "for class_name, samples in all_class2samples.items():\n",
    "    if class_name != \"normal\":\n",
    "        for sample in samples:\n",
    "            exclude_scs.extend(sample)\n",
    "            total_non_normal_samples += 1\n",
    "\n",
    "exclude_scs = set(exclude_scs)\n",
    "exclude_scs_ids = {str(sc.id) for sc in exclude_scs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from livecell_tracker.core.sct_operator import create_scs_edit_viewer\n",
    "# sct_operator = create_scs_edit_viewer(exclude_scs, img_dataset = list(exclude_scs)[0].img_dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load all scs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from livecell_tracker.core.single_cell import SingleCellTrajectoryCollection\n",
    "from livecell_tracker.track.sort_tracker_utils import (\n",
    "    track_SORT_bbox_from_scs\n",
    ")\n",
    "\n",
    "all_scs_json_path = [\"./datasets/test_scs_EBSS_starvation/XY1/single_cells.json\", \"./datasets/test_scs_EBSS_starvation/XY16/single_cells.json\"]\n",
    "# all_scs_json_path = \"./datasets/test_scs_EBSS_starvation/XY16/tmp_corrected_scs.json\"\n",
    "sctc = SingleCellTrajectoryCollection()\n",
    "for json_path in all_scs_json_path:\n",
    "    _scs = SingleCellStatic.load_single_cells_json(json_path)\n",
    "    tmp_sctc = track_SORT_bbox_from_scs(_scs, raw_imgs=_scs[0].img_dataset, min_hits=3, max_age=3)\n",
    "    tids = set(sctc.get_all_tids())\n",
    "    if len(tids) != 0:\n",
    "        max_tid = max(tids)\n",
    "    else:\n",
    "        max_tid = 0\n",
    "    for tid, traj in tmp_sctc:\n",
    "        traj.meta[\"src_dir\"] = json_path\n",
    "        traj.track_id = tid + max_tid + 1\n",
    "        sctc.add_trajectory(traj)\n",
    "        traj_scs = traj.get_all_scs()\n",
    "        for sc in traj_scs:\n",
    "            sc.meta[\"src_dir\"] = json_path\n",
    "    del tmp_sctc\n",
    "\n",
    "all_scs = SingleCellStatic.load_single_cells_jsons(all_scs_json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# with open(\"./EBSS_starvation_24h_xy16_annotation/single_cell_trajectory_collection.json\", \"r\") as file:\n",
    "#     json_dict = json.load(file)\n",
    "# sctc = SingleCellTrajectoryCollection().load_from_json_dict(json_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set numpy seed\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "\n",
    "objective_sample_num = total_non_normal_samples * 10\n",
    "\n",
    "normal_frame_len_range = (3, 10)\n",
    "counter = 0\n",
    "normal_samples = []\n",
    "normal_samples_extra_info = []\n",
    "max_trial_counter = 100000\n",
    "while counter < objective_sample_num and max_trial_counter > 0:\n",
    "    # randomly select a sct from sctc\n",
    "    # generate a list of scs\n",
    "    track_id = np.random.choice(list(sctc.track_id_to_trajectory.keys()))  \n",
    "    sct = sctc.get_trajectory(track_id)\n",
    "    # randomly select a length\n",
    "    frame_len = np.random.randint(*normal_frame_len_range)\n",
    "    # generate a sample\n",
    "    times = list(sct.timeframe_to_single_cell.keys())\n",
    "    times = sorted(times)\n",
    "    if len(times) <= frame_len:\n",
    "        continue\n",
    "    start_idx = np.random.randint(0, len(times) - frame_len)\n",
    "    start_time = times[start_idx]\n",
    "    end_time = times[start_idx + frame_len - 1]\n",
    "\n",
    "    sub_sct = sct.subsct(start_time, end_time)\n",
    "\n",
    "    is_some_sc_in_exclude_scs = False\n",
    "    for time, sc in sub_sct.timeframe_to_single_cell.items():\n",
    "        # print(\"sc.id:\", sc.id, type(sc.id))\n",
    "        if str(sc.id) in exclude_scs_ids:\n",
    "            is_some_sc_in_exclude_scs = True\n",
    "            break\n",
    "    if is_some_sc_in_exclude_scs:\n",
    "        print(\"some sc in exclude scs\")\n",
    "        continue\n",
    "    \n",
    "    new_sample = []\n",
    "    for time, sc in sub_sct.timeframe_to_single_cell.items():\n",
    "        new_sample.append(sc)\n",
    "    normal_samples.append(new_sample)\n",
    "    normal_samples_extra_info.append({\"src_dir\": sub_sct.get_all_scs()[0].meta[\"src_dir\"]})\n",
    "    counter += 1\n",
    "    max_trial_counter -= 1\n",
    "\n",
    "normal_samples[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_class2samples[\"normal\"].extend(normal_samples)\n",
    "all_class2sample_extra_info[\"normal\"].extend(normal_samples_extra_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_class2samples[\"normal\"]), len(all_class2sample_extra_info[\"normal\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare videos and annotations for MMDetection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = all_class2samples.keys()\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from livecell_tracker.core.utils import gray_img_to_rgb, rgb_img_to_gray\n",
    "from livecell_tracker.preprocess.utils import normalize_img_to_uint8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from livecell_tracker.track.classify_utils import video_frames_and_masks_from_sample, combine_video_frames_and_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from livecell_tracker.core.sc_video_utils import gen_mp4_from_frames, gen_samples_df, gen_samples_mp4s\n",
    "\n",
    "ver = \"10-drop-div\"\n",
    "# ver = \"-test\"\n",
    "DROP_MITOSIS_DIV = True\n",
    "\n",
    "data_dir = Path(f'notebook_results/mmaction_train_data_v{ver}')\n",
    "class_labels = ['mitosis', 'apoptosis', 'normal']\n",
    "class_label = \"mitosis\"\n",
    "frame_types = [\"video\", \"mask\", \"combined\"]\n",
    "fps = 3\n",
    "\n",
    "padding_pixels = [0, 20, 40, 50, 100, 200, 400]\n",
    "\n",
    "\n",
    "\n",
    "# split train and test data\n",
    "\n",
    "# get #samples from all_class2samples\n",
    "_split = 0.8\n",
    "\n",
    "train_class2samples = {}\n",
    "test_class2samples = {}\n",
    "train_class2sample_extra_info = {}\n",
    "test_class2sample_extra_info = {}\n",
    "\n",
    "# randomize train and test data\n",
    "\n",
    "\n",
    "for key in all_class2samples.keys():\n",
    "    randomized_indices = np.random.permutation(len(all_class2samples[key])).astype(int)\n",
    "    split_idx = int(len(all_class2samples[key]) * _split)\n",
    "    _train_indices = randomized_indices[:split_idx]\n",
    "    _test_indices = randomized_indices[split_idx:]\n",
    "    train_class2samples[key] = np.array(all_class2samples[key], dtype=object)[_train_indices]\n",
    "    test_class2samples[key] = np.array(all_class2samples[key], dtype=object)[_test_indices]\n",
    "\n",
    "    train_class2sample_extra_info[key] = np.array(all_class2sample_extra_info[key], dtype=object)[_train_indices]\n",
    "    test_class2sample_extra_info[key] = np.array(all_class2sample_extra_info[key], dtype=object)[_test_indices]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_class2samples[\"normal\"]), len(test_class2samples[\"normal\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_class2samples[\"mitosis\"]), len(test_class2samples[\"mitosis\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_frames_and_masks_from_sample(train_class2samples[\"normal\"][6])[0][0].shape\n",
    "# train_class2samples[\"normal\"][6][1].show_panel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import livecell_tracker\n",
    "importlib.reload(livecell_tracker.track.classify_utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_check = 6\n",
    "video_frames, video_frame_masks = video_frames_and_masks_from_sample(train_class2samples[\"normal\"][idx_to_check], padding_pixels=0)\n",
    "print(\"video frames dtype:\", video_frames[0].dtype)\n",
    "print(\"video frames shape:\", video_frames[0].shape)\n",
    "print(\"video frame masks dtype:\", video_frame_masks[0].dtype)\n",
    "print(\"video frame masks shape:\", video_frame_masks[0].shape)\n",
    "combined_frames = livecell_tracker.track.classify_utils.combine_video_frames_and_masks(video_frames, video_frame_masks, edt_transform=True)\n",
    "combined_frames = np.array(combined_frames).astype(np.uint8)\n",
    "# combined_frames = np.maximum(combined_frames - 1, 0).astype(np.uint8)\n",
    "print(\"combined_frames shape: \", combined_frames[0].shape)\n",
    "gen_mp4_from_frames(combined_frames, \"./test_video_output.mp4\", fps=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visually check the generated frames' values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# channel = 2\n",
    "# plt.imshow(combined_frames[0][..., channel])\n",
    "# combined_frames[1][..., channel].max(), combined_frames[1][..., 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(combined_frames).flatten().min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop the cell divison part for easier inference durign testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_div_keys = [\"mitosis\"]\n",
    "\n",
    "def drop_sample_div(sample: List[SingleCellStatic]):\n",
    "    \"\"\"remove scs in samples where at the same timepoint, there are >=2 scs\"\"\"\n",
    "    sc_by_time = {}\n",
    "    for sc in sample:\n",
    "        if sc.timeframe not in sc_by_time:\n",
    "            sc_by_time[sc.timeframe] = []\n",
    "        sc_by_time[sc.timeframe].append(sc)\n",
    "\n",
    "    new_sample = []\n",
    "    for time, scs in sc_by_time.items():\n",
    "        if len(scs) == 1:\n",
    "            new_sample.append(scs[0])\n",
    "    return new_sample\n",
    "\n",
    "def check_one_sc_at_time(sample: List[SingleCellStatic]):\n",
    "    \"\"\"check if there is only one sc at each timepoint\"\"\"\n",
    "    times = set()\n",
    "    for sc in sample:\n",
    "        if sc.timeframe in times:\n",
    "            return False\n",
    "        times.add(sc.timeframe)\n",
    "    return True\n",
    "\n",
    "if DROP_MITOSIS_DIV:\n",
    "    def drop_div_keys(class2samples, tar_keys=[\"mitosis\"]):\n",
    "        class2samples = class2samples.copy()\n",
    "        for key in tar_keys:\n",
    "            tmp_samples = []\n",
    "            key_samples = class2samples[key]\n",
    "            for sample in key_samples:\n",
    "                tmp_samples.append(drop_sample_div(sample))\n",
    "            class2samples[key] = tmp_samples\n",
    "            assert all([check_one_sc_at_time(sample) for sample in class2samples[key]]), \"there is more than one sc at the same timepoint\"\n",
    "        return class2samples\n",
    "    train_class2samples = drop_div_keys(train_class2samples)\n",
    "    test_class2samples = drop_div_keys(test_class2samples)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/22 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:41<00:00,  1.86s/it]\n",
      "100%|██████████| 22/22 [00:19<00:00,  1.10it/s]\n",
      "100%|██████████| 22/22 [00:21<00:00,  1.02it/s]\n",
      "100%|██████████| 22/22 [00:23<00:00,  1.06s/it]\n",
      "100%|██████████| 22/22 [00:22<00:00,  1.01s/it]\n",
      "100%|██████████| 22/22 [00:26<00:00,  1.22s/it]\n",
      "100%|██████████| 22/22 [00:39<00:00,  1.80s/it]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 224/224 [01:13<00:00,  3.06it/s]\n",
      "100%|██████████| 224/224 [00:36<00:00,  6.17it/s]\n",
      "100%|██████████| 224/224 [00:38<00:00,  5.83it/s]\n",
      "100%|██████████| 224/224 [00:39<00:00,  5.65it/s]\n",
      "100%|██████████| 224/224 [00:49<00:00,  4.53it/s]\n",
      "100%|██████████| 224/224 [01:22<00:00,  2.72it/s]\n",
      "100%|██████████| 224/224 [03:11<00:00,  1.17it/s]\n",
      "100%|██████████| 6/6 [00:18<00:00,  3.14s/it]\n",
      "100%|██████████| 6/6 [00:09<00:00,  1.52s/it]\n",
      "100%|██████████| 6/6 [00:09<00:00,  1.59s/it]\n",
      "100%|██████████| 6/6 [00:09<00:00,  1.62s/it]\n",
      "100%|██████████| 6/6 [00:10<00:00,  1.77s/it]\n",
      "100%|██████████| 6/6 [00:13<00:00,  2.32s/it]\n",
      "100%|██████████| 6/6 [00:18<00:00,  3.11s/it]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 56/56 [00:29<00:00,  1.87it/s]\n",
      "100%|██████████| 56/56 [00:24<00:00,  2.28it/s]\n",
      "100%|██████████| 56/56 [00:22<00:00,  2.47it/s]\n",
      "100%|██████████| 56/56 [00:26<00:00,  2.10it/s]\n",
      "100%|██████████| 56/56 [00:24<00:00,  2.25it/s]\n",
      "100%|██████████| 56/56 [00:33<00:00,  1.67it/s]\n",
      "100%|██████████| 56/56 [00:57<00:00,  1.03s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# # for debug\n",
    "# train_class2samples = {key: value[:5] for key, value in all_class2samples.items()}\n",
    "# test_class2samples = {key: value[:5] for key, value in all_class2samples.items()}\n",
    "# padding_pixels = [20]\n",
    "\n",
    "\n",
    "train_sample_info_df = gen_samples_df(train_class2samples, train_class2sample_extra_info, data_dir, class_labels, padding_pixels, frame_types, fps, prefix=\"train\")\n",
    "test_sample_info_df = gen_samples_df(test_class2samples, test_class2sample_extra_info, data_dir, class_labels, padding_pixels, frame_types, fps, prefix=\"test\")\n",
    "\n",
    "train_sample_info_df.to_csv(data_dir/f'train_data.txt', index=False, header=False, sep=' ', )\n",
    "test_sample_info_df.to_csv(data_dir/f'test_data.txt', index=False, header=False, sep=' ', )\n",
    "\n",
    "for selected_frame_type in frame_types:\n",
    "    train_df_path = data_dir/f'mmaction_train_data_{selected_frame_type}.txt'\n",
    "    train_selected_frame_type_df = train_sample_info_df[train_sample_info_df[\"frame_type\"] == selected_frame_type]\n",
    "    train_selected_frame_type_df = train_selected_frame_type_df.reset_index(drop=True)\n",
    "    train_selected_frame_type_df = train_selected_frame_type_df[[\"path\", \"label_index\"]]\n",
    "    train_selected_frame_type_df.to_csv(train_df_path, index=False, header=False, sep=' ')\n",
    "    \n",
    "    test_df_path = data_dir/f'mmaction_test_data_{selected_frame_type}.txt'\n",
    "    test_selected_frame_type_df = test_sample_info_df[test_sample_info_df[\"frame_type\"] == selected_frame_type]\n",
    "    test_selected_frame_type_df = test_selected_frame_type_df[[\"path\", \"label_index\"]]\n",
    "    test_selected_frame_type_df = test_selected_frame_type_df.reset_index(drop=True)\n",
    "    test_selected_frame_type_df.to_csv(test_df_path, index=False, header=False, sep=' ')\n",
    "\n",
    "\n",
    "# # the follwing code generates v1-v7 test data. The issue is that some of test data shows up in train data, through different padding values.\n",
    "# data_df_path = data_dir/'all_data.txt'\n",
    "# sample_df = gen_samples_df(data_dir, class_labels, padding_pixels, frame_types, fps)\n",
    "# sample_df.to_csv(data_df_path, index=False, header=False, sep=' ')\n",
    "# for selected_frame_type in frame_types:\n",
    "#     selected_frame_type_df = sample_df[sample_df[\"frame_type\"] == selected_frame_type]\n",
    "#     selected_frame_type_df = selected_frame_type_df.reset_index(drop=True)\n",
    "#     train_df_path = data_dir/f'train_data_{selected_frame_type}.txt'\n",
    "#     test_df_path = data_dir/f'test_data_{selected_frame_type}.txt'\n",
    "#     train_df = selected_frame_type_df.sample(frac=0.8, random_state=0, replace=False)\n",
    "#     test_df = selected_frame_type_df.drop(train_df.index, inplace=False)\n",
    "\n",
    "#     # only keep the path and label_index columns\n",
    "#     train_df = train_df[[\"path\", \"label_index\"]]\n",
    "#     test_df = test_df[[\"path\", \"label_index\"]]\n",
    "\n",
    "#     train_df.to_csv(train_df_path, index=False, header=False, sep=' ')\n",
    "#     test_df.to_csv(test_df_path, index=False, header=False, sep=' ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_class2samples"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "video_paths = list(Path(data_dir/'videos').glob('*.mp4'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to a `decord` package [issue](https://github.com/dmlc/decord/issues/150), to use mmaction2 we must check if the videos can be loaded by `decord` correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "invalid video for decord (https://github.com/dmlc/decord/issues/150):  notebook_results\\mmaction_train_data_v10-drop-div\\videos\\train_normal_212_combined_padding-0.mp4\n",
      "invalid video for decord (https://github.com/dmlc/decord/issues/150):  notebook_results\\mmaction_train_data_v10-drop-div\\videos\\train_normal_212_mask_padding-0.mp4\n",
      "invalid video for decord (https://github.com/dmlc/decord/issues/150):  notebook_results\\mmaction_train_data_v10-drop-div\\videos\\train_normal_212_raw_padding-0.mp4\n",
      "invalid video for decord (https://github.com/dmlc/decord/issues/150):  notebook_results\\mmaction_train_data_v10-drop-div\\videos\\train_normal_43_combined_padding-0.mp4\n",
      "invalid video for decord (https://github.com/dmlc/decord/issues/150):  notebook_results\\mmaction_train_data_v10-drop-div\\videos\\train_normal_43_mask_padding-0.mp4\n",
      "invalid video for decord (https://github.com/dmlc/decord/issues/150):  notebook_results\\mmaction_train_data_v10-drop-div\\videos\\train_normal_43_raw_padding-0.mp4\n"
     ]
    }
   ],
   "source": [
    "import decord\n",
    "for path in video_paths:\n",
    "# for path in [\"./notebook_results/train_normal_6_raw_padding-0.mp4\"]:\n",
    "# for path in [\"./test_video_output.mp4\"]:\n",
    "    reader = decord.VideoReader(str(path))\n",
    "    reader.seek(0)\n",
    "    imgs = list()\n",
    "    frame_inds = range(0, len(reader))\n",
    "    for idx in frame_inds:\n",
    "        reader.seek(idx)\n",
    "        frame = reader.next()\n",
    "        imgs.append(frame.asnumpy())\n",
    "        frame = frame.asnumpy()\n",
    "\n",
    "        num_channels = frame.shape[-1]\n",
    "        if num_channels != 3:\n",
    "            print(\"invalid video for decord (https://github.com/dmlc/decord/issues/150): \", path)\n",
    "            break\n",
    "        # fig, axes = plt.subplots(1, num_channels, figsize=(20, 10))\n",
    "        # for i in range(num_channels):\n",
    "        #     axes[i].imshow(frame[:, :, i])\n",
    "        # plt.show()\n",
    "    del reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decord.__version__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check if videos can be loaded by cv2 correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(\"./test_video_output.mp4\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    assert frame.shape[-1] == 3, \"frame should be in RGB format\"\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# train_df_path = data_dir/'train_data.csv'\n",
    "# test_df_path = data_dir/'test_data.csv'\n",
    "\n",
    "# # split train and test from df\n",
    "# train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "# train_df.to_csv(train_df_path, index=False, header=False, sep=' ')\n",
    "# test_df.to_csv(test_df_path, index=False, header=False, sep=' ')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "livecell",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
