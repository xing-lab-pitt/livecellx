{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "from livecell_tracker.core import (\n",
    "    SingleCellTrajectory,\n",
    "    SingleCellStatic,\n",
    "    SingleCellTrajectoryCollection,\n",
    ")\n",
    "from livecell_tracker.segment.detectron_utils import (\n",
    "    convert_detectron_instance_pred_masks_to_binary_masks,\n",
    "    convert_detectron_instances_to_label_masks,\n",
    "    segment_images_by_detectron,\n",
    "    segment_single_img_by_detectron_wrapper,\n",
    ")\n",
    "from livecell_tracker.core.datasets import LiveCellImageDataset\n",
    "from livecell_tracker.preprocess.utils import (\n",
    "    overlay,\n",
    "    enhance_contrast,\n",
    "    normalize_img_to_uint8,\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Labelme Json to COCO Json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run the following code once for generating coco json\n",
    "```\n",
    "import livecell_tracker.segment\n",
    "import livecell_tracker.annotation\n",
    "import livecell_tracker.annotation.labelme2coco\n",
    "import os\n",
    "labelme_json_folder = r\"\"\"../datasets/a549_ccnn/annotation_data\"\"\"\n",
    "dataset_folder_path = r\"\"\"../datasets/a549_ccnn/original_data\"\"\"\n",
    "export_dir = \"./notebook_results/correction_cnn_v0.0.0/\"\n",
    "os.makedirs(export_dir, exist_ok=True)\n",
    "livecell_tracker.annotation.labelme2coco.convert(\n",
    "    labelme_json_folder,\n",
    "    export_dir,\n",
    "    train_split_rate=0.9,\n",
    "    dataset_folder_path=dataset_folder_path,\n",
    "    # is_image_in_json_folder=True,\n",
    "    image_file_ext=\"tif\",\n",
    "    # image_file_ext=\"png\",\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load COCO into SingleCell Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycocotools.coco import COCO\n",
    "\n",
    "coco_data = COCO(\"../datasets/a549_ccnn/a549_ccnn_coco_v0.0.0/train.json\")\n",
    "out_dir = Path(\"./notebook_results/a549_ccp_vim/train_data_v5/\")\n",
    "\n",
    "coco_data.anns.keys(), coco_data.anns[1].keys(), coco_data.anns[1][\"segmentation\"][0][\n",
    "    :5\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_data.imgs.keys(), coco_data.imgs[1].keys(), coco_data.imgs[1][\"file_name\"],\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from livecell_tracker.annotation.coco_utils import coco_to_sc\n",
    "\n",
    "single_cells = coco_to_sc(coco_data)\n",
    "\n",
    "\n",
    "# for testing\n",
    "# single_cells = single_cells[:20]\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(10, 5))\n",
    "cell_id = 10\n",
    "axes[0].imshow(single_cells[cell_id].get_img_crop(padding=100))\n",
    "axes[1].imshow(single_cells[cell_id].get_contour_mask_closed_form(padding=100))\n",
    "axes[2].imshow(single_cells[cell_id].get_contour_mask(padding=100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(single_cells)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save a list of single cell objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SingleCellStatic.write_single_cells_json(\n",
    "    single_cells, \"../datasets/a549_ccnn/single_cells.json\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contour_mask = single_cells[cell_id].get_contour_mask(padding=100)\n",
    "contour_mask.astype(np.uint8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "from livecell_tracker.preprocess.utils import dilate_or_erode_mask\n",
    "\n",
    "plt.imshow(dilate_or_erode_mask(contour_mask.astype(np.uint8), 1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute similarity between manually segmented cell and segmentation results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will take sample_sc as an example to show how to compute IOU based similarity between manually segmented cell and segmentation results from machine learning models.  \n",
    "Instead, this part may be done by a human annotator by clicking the corresponding cell in the segmentation results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sc = single_cells[cell_id]\n",
    "sample_sc.meta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "raw_img_dataset = sample_sc.img_dataset\n",
    "seg_data_dir = \"../datasets/a549_ccnn/seg_tiles_CCP_A549-VIM_lessThan24hr_Calcein_1mg-ml_DP_Ti2e_2022-9-11\"\n",
    "seg_paths = glob.glob(os.path.join(seg_data_dir, \"*.png\"))\n",
    "print(\"sample seg paths:\", seg_paths[:2])\n",
    "matched_time2seg = {}\n",
    "# for time, img_path in raw_img_dataset.time2url.items():\n",
    "#     substr = os.path.basename(img_path).split(\".\")[0]\n",
    "#     print(\"substr:\", substr)\n",
    "#     for seg_path\n",
    "#     break\n",
    "corrected_indices = []\n",
    "for seg_path in seg_paths:\n",
    "    substr = os.path.basename(seg_path).split(\".\")[0] # get rid of extension\n",
    "    substr = substr[4:]  # get rid of seg_ prefix\n",
    "    img, path, index = raw_img_dataset.get_img_by_url(\n",
    "        substr, return_path_and_time=True, ignore_missing=True\n",
    "    )\n",
    "    if path is None:\n",
    "        print(\"skip due to substr not found:\", substr)\n",
    "        continue\n",
    "    matched_time2seg[index] = seg_path\n",
    "\n",
    "seg_data = LiveCellImageDataset(time2url=matched_time2seg, ext=\"png\")\n",
    "sample_sc.mask_dataset = seg_data\n",
    "assert len(seg_data) == len(raw_img_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 4, figsize=(10, 5))\n",
    "axes[0].imshow(sample_sc.get_img_crop(padding=10))\n",
    "axes[1].imshow(sample_sc.get_contour_mask(padding=10))\n",
    "axes[2].imshow(sample_sc.get_contour_mask_closed_form(padding=10))\n",
    "axes[3].imshow(sample_sc.get_mask_crop())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show a sample whole image with code below\n",
    "\n",
    "```\n",
    "fig, ax = plt.subplots(1, 1, figsize=(20, 20))\n",
    "ax.imshow(sample_sc.get_img())\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_mask = seg_data.get_img_by_url(\n",
    "    os.path.basename(sample_sc.meta[\"path\"]).split(\".\")[0], substr=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(seg_mask.flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axes[0].imshow(seg_mask)\n",
    "axes[1].imshow(sample_sc.get_contour_img(crop=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_seg_mask = SingleCellStatic.gen_skimage_bbox_img_crop(sample_sc.bbox, seg_mask)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 10))\n",
    "axes[0].imshow(\n",
    "    overlay(sample_sc.get_img_crop(), cropped_seg_mask, img_channel_rgb_val_factor=1)\n",
    ")\n",
    "axes[0].set_title(\"over-segmentation from ML model\")\n",
    "axes[1].imshow(\n",
    "    overlay(\n",
    "        sample_sc.get_img_crop(),\n",
    "        sample_sc.get_contour_img(),\n",
    "        img_channel_rgb_val_factor=1,\n",
    "    )\n",
    ")\n",
    "axes[1].set_title(\"ground truth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from livecell_tracker.segment.utils import match_mask_labels_by_iou\n",
    "\n",
    "match_mask_labels_by_iou(cropped_seg_mask, sample_sc.get_contour_mask())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(sample_sc.get_contour_mask(crop=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(10, 10))\n",
    "axes[0].imshow(\n",
    "    overlay(\n",
    "        enhance_contrast(normalize_img_to_uint8(sample_sc.get_img()), factor=0.5),\n",
    "        sample_sc.get_contour_mask(crop=False),\n",
    "        img_channel_rgb_val_factor=2,\n",
    "    )\n",
    ")\n",
    "axes[0].set_title(\"some gt cell annotation overlay\")\n",
    "axes[1].imshow(\n",
    "    overlay(\n",
    "        enhance_contrast(normalize_img_to_uint8(sample_sc.get_img()), factor=0.9),\n",
    "        seg_mask,\n",
    "        img_channel_rgb_val_factor=2,\n",
    "    )\n",
    ")\n",
    "axes[1].set_title(\"T07 XY4 TILE7 seg overlay\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sc.get_contour_mask()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_seg_mask_label(mask: np.array, sc: SingleCellStatic):\n",
    "    \"\"\"match a single cell's label in a mask. sc must contain its contour information.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    mask : np.array\n",
    "        _description_\n",
    "    sc : \n",
    "        _description_\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    a dict with keys \"seg_label\" and \"iou\"\n",
    "    \"\"\"    \n",
    "    cropped_seg_mask = SingleCellStatic.gen_skimage_bbox_img_crop(sc.bbox, seg_mask)\n",
    "    match_res = match_mask_labels_by_iou(cropped_seg_mask, sc.get_contour_mask())\n",
    "    assert len(match_res) == 1, \"Either sc's get contour mask returns a mask with more than 1 gt, or there is some bug in match_mask_labels_by_iou\"\n",
    "    match_res = list(match_res.values())[0]\n",
    "    return match_res\n",
    "\n",
    "# example usage\n",
    "seg_label = match_seg_mask_label(seg_mask, sample_sc)[\"seg_label\"]\n",
    "seg_label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute similarity for all cells and get the mapping between single cells and its corresponding label in the segmentation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sc in tqdm(single_cells):\n",
    "    sc_img_path_substr = os.path.basename(sc.meta[\"path\"]).split(\".\")[0]\n",
    "    seg_mask = seg_data.get_img_by_url(sc_img_path_substr, substr=True)\n",
    "    sc.meta[\"seg_label\"] = match_seg_mask_label(seg_mask, sc)[\"seg_label\"]\n",
    "    sc.mask_dataset = seg_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "sample_sc.show_mask()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate dilated and eroded masks for each cell\n",
    "Create an augmented dataset.\n",
    "Save results via single cell data structure\n",
    "```\n",
    "Single Cell Json metadata\n",
    "{\n",
    "    seg_label: 13,\n",
    "    img_id: 1,\n",
    "}\n",
    "```\n",
    "\n",
    "We pad the each cell mask with a defined background value (0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(seg_data), len(sample_sc.img_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sc = single_cells[-1]\n",
    "sample_sc.meta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Undersegmentation case: create mapping from seg label id to gt id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_cells[-1].meta, single_cells[-2].meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sc.meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg2scs = {}\n",
    "for sc in single_cells:\n",
    "    seg_label = sc.meta[\"seg_label\"]\n",
    "    img_id = sc.meta[\"img_id\"]\n",
    "    key = (img_id, seg_label)\n",
    "    if key not in seg2scs:\n",
    "        seg2scs[key] = []\n",
    "    seg2scs[key].append(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count how many simple undersegmentation there are in our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "underseg_cases = {key: val for key, val in seg2scs.items() if len(val) > 1}\n",
    "len(underseg_cases)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize one such undersegmentation case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose any case\n",
    "underseg_case = list(underseg_cases.items())[2]\n",
    "underseg_case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 4, figsize=(10, 5))\n",
    "underseg_scs = underseg_case[1]\n",
    "padding = 30\n",
    "axes[0].imshow(underseg_scs[0].get_mask_crop(padding=padding))\n",
    "axes[1].imshow(underseg_scs[0].get_contour_img(padding=padding))\n",
    "axes[2].imshow(underseg_scs[1].get_mask_crop(padding=padding))\n",
    "axes[3].imshow(underseg_scs[1].get_contour_img(padding=padding))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augment undersegmentation case  \n",
    "sc.mask_dataset, sc.get_mask(): from seg_mask  \n",
    "sc.bbox, sc.contour, sc.get_contour(): from gt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "from skimage.measure import regionprops\n",
    "import pandas as pd\n",
    "from livecell_tracker.core.io_utils import save_tiff\n",
    "\n",
    "\n",
    "def underseg_overlay_gt_masks(\n",
    "    seg_label: int, scs: SingleCellStatic, padding_scale=1.5, seg_mask=None\n",
    ") -> Tuple[np.array, np.array, np.array]:\n",
    "    \"\"\"Overlay segmentation masks and ground truth masks for under-segmentation cases.\n",
    "    Specifically, for a segmentation label, if there are multiple ground truth masks matched to it,\n",
    "    then we overlay ground truths masks in the same kmask\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    seg_label : int\n",
    "        _description_\n",
    "    scs : SingleCellStatic\n",
    "        _description_\n",
    "    padding_scale : float, optional\n",
    "        _description_, by default 1.5\n",
    "    mask :\n",
    "        if not None, use the mask, otherwise inferred from other args, by default None\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Tuple[np.array, np.array, np.array]\n",
    "        (img_crop, seg_crop, combined ground-truth mask)\n",
    "    \"\"\"\n",
    "    if len(scs) == 0:\n",
    "        print(\"no scs for this seg_label\")\n",
    "        return None, None, None\n",
    "\n",
    "    if seg_mask is None:\n",
    "        seg_mask = scs[0].get_mask()\n",
    "\n",
    "    seg_mask[seg_mask != seg_label] = 0\n",
    "    props_list = regionprops(seg_mask)\n",
    "\n",
    "    if len(props_list) != 1:\n",
    "        print(\n",
    "            \"[WARNING] skip: (%d, %d) due to more than one region found in seg mask or NO region found in seg mask\"\n",
    "            % (img_id, seg_label)\n",
    "        )\n",
    "        return\n",
    "    # obtain segmentation bbox from segmentation mask\n",
    "    seg_props = props_list[0]\n",
    "    seg_bbox = seg_props.bbox\n",
    "    xmin, ymin, xmax, ymax = seg_bbox\n",
    "\n",
    "    # compute padding based on scale\n",
    "    padding_pixels = np.array((padding_scale - 1) * max(xmax - xmin, ymax - ymin))\n",
    "    padding_pixels = padding_pixels.astype(int)\n",
    "\n",
    "    # get seg mask's crop with single cell's get_mask_crop implementation for consistency\n",
    "    tmp = np.array(scs[0].bbox)\n",
    "    scs[0].bbox = seg_bbox\n",
    "    seg_crop = scs[0].get_mask_crop(padding=padding_pixels)\n",
    "    scs[0].bbox = np.array(tmp)\n",
    "\n",
    "    # clear other seg labels\n",
    "    seg_crop[seg_crop != seg_label] = 0\n",
    "    seg_crop[seg_crop > 0] = 1\n",
    "\n",
    "    combined_gt_mask = np.zeros(seg_crop.shape)\n",
    "    img_crop = None\n",
    "    for idx, sc in enumerate(scs):\n",
    "        sc.meta[\"seg_label\"] = None\n",
    "        tmp = np.array(sc.bbox)\n",
    "        sc.bbox = seg_bbox\n",
    "        combined_gt_mask += (idx + 1) * sc.get_contour_mask(padding=padding_pixels)\n",
    "        img_crop = sc.get_img_crop(padding=padding_pixels) if img_crop is None else img_crop  # set img_crop once\n",
    "        sc.bbox = tmp\n",
    "    return (img_crop, seg_crop, combined_gt_mask)\n",
    "\n",
    "\n",
    "def gen_aug_diff_mask(aug_mask: np.array, combined_gt_mask: np.array) -> np.array:\n",
    "    \"\"\"generate a mask based on the difference between the augmented mask and the combined gt mask\n",
    "    0: no difference\n",
    "    -1: augmented mask is 0, combined gt mask is 1 -> over-segmentation\n",
    "    1: augmented mask is 1, combined gt mask is 0 -> under-segmentation\n",
    "    Note: special care for uint8 case when calculating difference mask if we use cv2 related functions\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    aug_mask : np.array\n",
    "        _description_\n",
    "    combined_gt_mask : np.array\n",
    "        _description_\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.array\n",
    "        _description_\n",
    "    \"\"\"\n",
    "    aug_mask = aug_mask.astype(int)  # prevent uint8 overflow (-1 in diff case below)\n",
    "    combined_gt_mask[combined_gt_mask > 0] = 1\n",
    "    combined_gt_mask = combined_gt_mask.astype(int)\n",
    "    diff_mask = aug_mask - combined_gt_mask  # should only contain 0 and 1\n",
    "    assert len(np.unique(diff_mask)) <= 3\n",
    "\n",
    "    return diff_mask\n",
    "\n",
    "\n",
    "underseg_seg2scs = underseg_cases\n",
    "\n",
    "raw_out_dir = out_dir / \"raw\"\n",
    "seg_out_dir = out_dir / \"seg\"\n",
    "gt_out_dir = out_dir / \"gt\"\n",
    "gt_label_out_dir = out_dir / \"gt_label_mask\"\n",
    "augmented_seg_dir = out_dir / \"augmented_seg\"\n",
    "raw_transformed_img_dir = out_dir / \"raw_transformed_img\"\n",
    "augmented_diff_seg_dir = out_dir / \"augmented_diff_seg\"\n",
    "\n",
    "os.makedirs(raw_out_dir, exist_ok=True)\n",
    "os.makedirs(seg_out_dir, exist_ok=True)\n",
    "os.makedirs(gt_out_dir, exist_ok=True)\n",
    "os.makedirs(augmented_seg_dir, exist_ok=True)\n",
    "os.makedirs(gt_label_out_dir, exist_ok=True)\n",
    "os.makedirs(raw_transformed_img_dir, exist_ok=True)\n",
    "os.makedirs(augmented_diff_seg_dir, exist_ok=True)\n",
    "\n",
    "scale_factors = np.linspace(0, 0.3, 10)\n",
    "\n",
    "train_path_tuples = []\n",
    "augmented_data = []\n",
    "\n",
    "def csn_augment_helper(\n",
    "    img_crop,\n",
    "    seg_crop,\n",
    "    combined_gt_label_mask,\n",
    "    scale_factors: list,\n",
    "    train_path_tuples: list,\n",
    "    augmented_data: list,\n",
    "    img_id,\n",
    "    seg_label,\n",
    "    gt_label,\n",
    "    raw_img_path,\n",
    "    seg_img_path,\n",
    "    gt_img_path,\n",
    "    gt_label_img_path,\n",
    "    augmented_seg_dir,\n",
    "    augmented_diff_seg_dir,\n",
    "    filename_pattern=\"img-%d_seg-%d_aug-%d.tif\",\n",
    "):\n",
    "\n",
    "    combined_gt_mask = combined_gt_label_mask > 0\n",
    "    combined_gt_mask = combined_gt_mask.astype(np.uint8)\n",
    "\n",
    "    save_tiff(img_crop, raw_img_path, mode=\"I\")  # save to 32-bit depth signed integer\n",
    "    save_tiff(seg_crop, seg_img_path)\n",
    "    save_tiff(combined_gt_mask, gt_img_path)\n",
    "    save_tiff(combined_gt_label_mask, gt_label_img_path)\n",
    "\n",
    "    # dilate or erode segmentation mask\n",
    "    for idx, scale in enumerate(scale_factors):\n",
    "        augmented_seg_path = augmented_seg_dir / (\"img-%d_seg-%d_aug-%d.tif\" % (img_id, seg_label, idx))\n",
    "        augmented_diff_seg_path = augmented_diff_seg_dir / (\"img-%d_seg-%d_aug-%d.tif\" % (img_id, seg_label, idx))\n",
    "\n",
    "        if np.unique(seg_crop).shape[0] > 256:\n",
    "            print(\"[WARNING] skip: (%d, %d) due to more than 256 unique seg labels\" % (img_id, seg_label))\n",
    "            continue\n",
    "        seg_crop = seg_crop.astype(np.uint8)\n",
    "\n",
    "        # seg_crop should only contains one label\n",
    "        # TODO: the condition commented above should be a postcondition of underseg_overlay_gt_masks\n",
    "        seg_crop[seg_crop > 0] = 1\n",
    "        aug_seg_crop = dilate_or_erode_mask(seg_crop, scale_factor=scale)\n",
    "        aug_values = np.unique(aug_seg_crop)\n",
    "        assert len(aug_values) <= 2, \"only two values should be present in aug masks\"\n",
    "        aug_seg_crop[aug_seg_crop > 0] = 1\n",
    "        aug_seg_crop[aug_seg_crop < 0] = 0  # not necessary, check math\n",
    "        save_tiff(aug_seg_crop, augmented_seg_path)\n",
    "\n",
    "        aug_diff_mask = gen_aug_diff_mask(aug_seg_crop, combined_gt_mask)\n",
    "        save_tiff(aug_diff_mask, augmented_diff_seg_path, mode=\"I\")\n",
    "\n",
    "        raw_transformed_img_path = raw_transformed_img_dir / (\"img-%d_seg-%d_aug-%d.tif\" % (img_id, seg_label, idx))\n",
    "        raw_transformed_img_crop = img_crop.copy().astype(int)\n",
    "        raw_transformed_img_crop[aug_seg_crop == 0] *= -1\n",
    "        save_tiff(raw_transformed_img_crop, raw_transformed_img_path, mode=\"I\")\n",
    "\n",
    "        train_path_tuples.append(\n",
    "            (\n",
    "                raw_img_path.as_posix(),\n",
    "                augmented_seg_path.as_posix(),\n",
    "                gt_img_path.as_posix(),\n",
    "                seg_img_path.as_posix(),\n",
    "                scale,\n",
    "                augmented_diff_seg_path.as_posix(),\n",
    "                gt_label_img_path.as_posix(),\n",
    "                raw_transformed_img_path.as_posix(),\n",
    "            )\n",
    "        )\n",
    "\n",
    "        augmented_data.append({\n",
    "            \"img_id\": img_id,\n",
    "            \"img_crop\": img_crop,\n",
    "            \"seg_crop\": seg_crop,\n",
    "            \"seg_label\": seg_label,\n",
    "            \"gt_label\": gt_label,\n",
    "            \"combined_gt_mask\": combined_gt_mask,\n",
    "            \"aug_seg_crop\": aug_seg_crop,\n",
    "            \"aug_diff_mask\": aug_diff_mask,\n",
    "            \"combined_gt_label_mask\": combined_gt_label_mask,\n",
    "            \"raw_transformed_img_crop\": raw_transformed_img_crop,\n",
    "        })\n",
    "        # augmented_data[(img_id, seg_label)].append(\n",
    "        #     (\n",
    "        #         img_crop,\n",
    "        #         seg_crop,\n",
    "        #         combined_gt_mask,\n",
    "        #         aug_seg_crop,\n",
    "        #         aug_diff_mask,\n",
    "        #         combined_gt_label_mask,\n",
    "        #         raw_transformed_img_crop,\n",
    "        #     )\n",
    "        # )\n",
    "\n",
    "\n",
    "for img_id, seg_label in tqdm(underseg_seg2scs):\n",
    "    scs = underseg_seg2scs[(img_id, seg_label)]\n",
    "    assert len(scs) > 0, \"the list of single cells should not be empty\"\n",
    "    \n",
    "    (img_crop, seg_crop, combined_gt_label_mask) = underseg_overlay_gt_masks(seg_label, scs, padding_scale=2)\n",
    "    raw_img_path = raw_out_dir / (\"img-%d_seg-%d.tif\" % (img_id, seg_label))\n",
    "    seg_img_path = seg_out_dir / (\"img-%d_seg-%d.tif\" % (img_id, seg_label))\n",
    "    gt_img_path = gt_out_dir / (\"img-%d_seg-%d.tif\" % (img_id, seg_label))\n",
    "    gt_label_img_path = gt_label_out_dir / (\"img-%d_seg-%d.tif\" % (img_id, seg_label))\n",
    "\n",
    "    # call csn augment helper\n",
    "    csn_augment_helper(img_crop=img_crop, \n",
    "        seg_crop=seg_crop, \n",
    "        combined_gt_label_mask=combined_gt_label_mask,\n",
    "        scale_factors=scale_factors,\n",
    "        train_path_tuples=train_path_tuples,\n",
    "        augmented_data=augmented_data,\n",
    "        img_id=img_id,\n",
    "        seg_label=seg_label,\n",
    "        gt_label=None,\n",
    "        raw_img_path=raw_img_path,\n",
    "        seg_img_path=seg_img_path,\n",
    "        gt_img_path=gt_img_path,\n",
    "        gt_label_img_path=gt_label_img_path,\n",
    "        augmented_seg_dir=augmented_seg_dir,\n",
    "        augmented_diff_seg_dir=augmented_diff_seg_dir,\n",
    "    )\n",
    "\n",
    "\n",
    "pd.DataFrame(\n",
    "    train_path_tuples,\n",
    "    columns=[\"raw\", \"seg\", \"gt\", \"raw_seg\", \"scale\", \"aug_diff_mask\", \"gt_label_mask\", \"raw_transformed_img\"],\n",
    ").to_csv(out_dir / \"data.csv\", index=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate oversegmentation cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BackgroundSimulator:\n",
    "    pass\n",
    "\n",
    "class OverSegSimulator:\n",
    "    pass\n",
    "\n",
    "class UnderSegSimulator:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1, 2], [3, 4]])\n",
    "a[(1,1), (0,0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import random\n",
    "from livecell_tracker.trajectory.contour_utils import get_cellTool_contour_points, viz_contours\n",
    "\n",
    "def get_line_pixels(pt1, pt2, thickness=2, max_x=float(\"inf\"), max_y=float(\"inf\")):\n",
    "    \"\"\"get all pixel coordinates between two points\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    pt1 : _type_\n",
    "        _description_\n",
    "    pt2 : _type_\n",
    "        _description_\n",
    "    thickness : int, optional\n",
    "        _description_, by default 3\n",
    "    max_x : _type_, optional\n",
    "        _description_, by default float(\"inf\")\n",
    "    max_y : _type_, optional\n",
    "        _description_, by default float(\"inf\")\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    _type_\n",
    "        _description_\n",
    "    \"\"\"\n",
    "    def _get_line_pixels_xy(x1, y1, x2, y2, max_x, max_y):\n",
    "        # get the line equation\n",
    "        if x1 == x2:\n",
    "            m = 0\n",
    "        else:\n",
    "            m = (y2 - y1) / (x2 - x1)\n",
    "        b = y1 - m * x1\n",
    "        # get the pixels\n",
    "        pixels = set()\n",
    "\n",
    "        def add_xy(x, y):\n",
    "            if y < max_y:\n",
    "                pixels.add((x, y))\n",
    "            # simple thickening\n",
    "            sx, sy = x - thickness, y - thickness\n",
    "            for nx in range(sx, sx + thickness * 2):\n",
    "                for ny in range(sy, sy + thickness * 2):\n",
    "                    # if nx ny in bound\n",
    "                    if nx >= 0 and ny >= 0 and nx < max_x and ny < max_y:\n",
    "                        pixels.add((nx, ny))\n",
    "        # exclude x2 purposely to follow skimage bbox conventions\n",
    "        for x in range(x1, x2): \n",
    "            y = int(m * x + b)\n",
    "            add_xy(x, y)\n",
    "            y = int(m * x + b) + 1\n",
    "            add_xy(x, y)\n",
    "        return pixels\n",
    "    x1, y1 = pt1\n",
    "    x2, y2 = pt2\n",
    "    x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "    if x1 > x2:\n",
    "        pt1, pt2 = pt2, pt1\n",
    "        x1, y1, x2, y2 = x2, y2, x1, y1\n",
    "    pixel_set1 = _get_line_pixels_xy(x1, y1, x2, y2, max_x, max_y)\n",
    "\n",
    "    if y1 > y2:\n",
    "        x1, y1, x2, y2 = x2, y2, x1, y1\n",
    "    _pixel_set2 = _get_line_pixels_xy(y1, x1, y2, x2, max_y, max_x)\n",
    "    pixel_set2 = set()\n",
    "    for coord in _pixel_set2:\n",
    "        pixel_set2.add((coord[1], coord[0]))\n",
    "    return pixel_set1.union(pixel_set2)\n",
    "\n",
    "\n",
    "def divide_single_cell_brute_force(sample_sc: SingleCellStatic, seg_crop, sampled_points=None):\n",
    "    \n",
    "    # get the contour points\n",
    "    contour_points = sample_sc.get_contour_coords_on_img_crop()\n",
    "    assert len(contour_points) >= 2, \"need more than 2 contour points to divide a cell\"\n",
    "    if sampled_points is None:\n",
    "        sampled_points = random.choices(contour_points, k=2)\n",
    "        print(\"sampled_points:\", sampled_points)\n",
    "\n",
    "    pt1 = sampled_points[0]\n",
    "    pt2 = sampled_points[1]\n",
    "\n",
    "    # TODO remove the resample code below\n",
    "    # # resample if the points are on the same vertical line\n",
    "    # while pt1[0] == pt2[0] or pt1[1] == pt2[1]:\n",
    "    #     sampled_points = random.choices(contour_points, k=2)\n",
    "    #     pt1 = sampled_points[0]\n",
    "    #     pt2 = sampled_points[1]\n",
    "\n",
    "    line_pixels = np.array(list(get_line_pixels(pt1, pt2, max_x=seg_crop.shape[0], max_y=seg_crop.shape[1])), dtype=int)\n",
    "\n",
    "    if len(line_pixels) == 0:\n",
    "        print(\"[WARN] the sampled line pixels is empty, skipping division process...\")\n",
    "        return\n",
    "\n",
    "    seg_crop[line_pixels[:, 0], line_pixels[:, 1]] = 0\n",
    "    # get the center of mass of the contour\n",
    "    center_of_mass = sample_sc\n",
    "    \n",
    "    # TODO: remove deepcopy because it creates underlying dataset objects holding paths as well\n",
    "    new_sc = deepcopy(sample_sc)\n",
    "    sample_sc.get_contour_img()\n",
    "\n",
    "\n",
    "sampled_sc = single_cells[0]\n",
    "# contour_points = sampled_sc.contour\n",
    "# sampled_contour_points = contour_points[::3]\n",
    "sc_img_path_substr = os.path.basename(sampled_sc.meta[\"path\"]).split(\".\")[0]\n",
    "seg_mask = seg_data.get_img_by_url(sc_img_path_substr, substr=True)\n",
    "seg_crop = sampled_sc.gen_skimage_bbox_img_crop(sampled_sc.bbox, seg_mask)\n",
    "\n",
    "sampled_sc.show_contour_mask()\n",
    "plt.show()\n",
    "# plt.imshow(seg_crop[:10, :])\n",
    "# plt.show()\n",
    "\n",
    "# print(\"contour points:\", sampled_sc.get_contour_coords_on_img_crop())\n",
    "\n",
    "# two test cases\n",
    "sampled_points = [[ 85., 66.], [ 73., 0]]\n",
    "# sampled_points = [[ 3., 50.], [ 3., 96.0]]\n",
    "# sample_points = [[ 37., 120.], [54., 12.]]\n",
    "\n",
    "contour_img = sampled_sc.get_contour_img()\n",
    "divide_single_cell_brute_force(sampled_sc, seg_crop=contour_img, sampled_points=sampled_points)\n",
    "# divide_single_cell_brute_force(sampled_sc, seg_crop=contour_img, sampled_points=None)\n",
    "# get_line_pixels([1, 5], [10, 10])\n",
    "# plt.imshow(seg_crop)\n",
    "plt.imshow(contour_img)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qualitatively generate and test bf more thoroughly..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_divide_bf():\n",
    "    contour_img = sc.get_contour_img()\n",
    "    divide_single_cell_brute_force(sc, seg_crop=contour_img, sampled_points=None)\n",
    "    plt.imshow(contour_img)\n",
    "    plt.show()\n",
    "\n",
    "# for i in range(100):\n",
    "#     test_divide_bf(sampled_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import ndimage\n",
    "from skimage.segmentation import watershed\n",
    "from skimage.feature import peak_local_max\n",
    "from scipy import ndimage as ndi\n",
    "from skimage.morphology import local_maxima, h_maxima\n",
    "from skimage.measure import regionprops, label\n",
    "import scipy.stats\n",
    "import livecell_tracker\n",
    "\n",
    "def add_random_gauss_to_img(contour_mask, raw_crop, square_len, gauss_center_val=200, gauss_std=8, inplace=False, pos=None):\n",
    "    # add random gaussian noise to the raw image\n",
    "    # randomly choose a point inside the contour\n",
    "    if not inplace:\n",
    "        raw_crop = raw_crop.copy()\n",
    "    np.where(contour_mask > 0)\n",
    "    cell_points =np.where(contour_mask > 0)\n",
    "\n",
    "    # # double check: viz cell points from np\n",
    "    # temp = np.zeros(contour_mask.shape)\n",
    "    # temp[cell_points] = 1\n",
    "    # plt.imshow(temp)\n",
    "    # plt.title(\"temp\")\n",
    "    # plt.show()\n",
    "    if pos is not None:\n",
    "        rand_pt = pos\n",
    "    else:\n",
    "        rand_idx = np.random.randint(0, len(cell_points[0]))\n",
    "        rand_pt = np.array([cell_points[0][rand_idx], cell_points[1][rand_idx]])\n",
    "\n",
    "    # the mesh grid is the square around the random point\n",
    "    x_min, x_max = max(rand_pt[0] - square_len, 0), min(rand_pt[0] + square_len, contour_mask.shape[0])\n",
    "    y_min, y_max = max(rand_pt[1] - square_len, 0), min(rand_pt[1] + square_len, contour_mask.shape[1])\n",
    "    grid = np.meshgrid(np.arange(x_min, x_max), np.arange(y_min, y_max))\n",
    "    grid = np.stack(grid, axis=-1)\n",
    "\n",
    "\n",
    "    # compute the distance between the random point and the mesh grid\n",
    "    dist_to_center = np.linalg.norm(grid - rand_pt, axis=-1)\n",
    "\n",
    "\n",
    "    # calculate the gaussian cdf  based on dist to center\n",
    "    gaussian_cdf = scipy.stats.norm.cdf(-dist_to_center, loc=0, scale=gauss_std)\n",
    "\n",
    "    # add gaussian noise to seg_crop\n",
    "    raw_crop[x_min:x_max, y_min:y_max] += gaussian_cdf.T * gauss_center_val\n",
    "\n",
    "    # print(\"cell_points:\", cell_points)\n",
    "    # print(\"cell_points len:\", len(cell_points[0]))\n",
    "    # print(\"contour mask sum:\", contour_mask.sum())\n",
    "    # print(\"square_len:\", square_len)\n",
    "    # print(\"grid shape:\", grid.shape)\n",
    "    # print(\"dist_to_center shape:\", dist_to_center.shape)\n",
    "    # print(\"dist_to_center mean:\", np.mean(dist_to_center))\n",
    "    # print(\"gaussian noise shape:\", gaussian_cdf.shape)\n",
    "    # print(\"gaussian mean:\", np.mean(gaussian_cdf))\n",
    "    return raw_crop, rand_pt\n",
    "\n",
    "\n",
    "\n",
    "def divide_single_cell_watershed(sample_sc: SingleCellStatic, raw_crop=None, peak_distance=20, markers=None, marker_method=\"hmax\", h_threshold=1, normalize=True, normalize_edt=True, gauss_center_val=200, edt_gauss_center_val=1, gauss_std=8, num_gauss_areas=2, return_all=False):\n",
    "    contour_points = sample_sc.get_contour_coords_on_img_crop()\n",
    "    contour_mask = sample_sc.get_contour_mask()\n",
    "    \n",
    "    if raw_crop is None:\n",
    "        raw_crop = sample_sc.get_contour_img()\n",
    "    else:\n",
    "        raw_crop = raw_crop.copy()\n",
    "\n",
    "    # normalize seg_crop\n",
    "    if normalize:\n",
    "        raw_crop = livecell_tracker.preprocess.utils.normalize_img_to_uint8(raw_crop)\n",
    "        raw_crop = raw_crop.astype(float)\n",
    "\n",
    "    # # print statistics of seg_crop\n",
    "    # print(\"seg_crop shape:\", raw_crop.shape)\n",
    "    # print(\"seg_crop unique:\", np.unique(raw_crop))\n",
    "    # print(\"seg_crop mean:\", np.mean(raw_crop))\n",
    "    # print(\"cell area:\", prop.area)\n",
    "    # print(\"cell axis_major_length:\", prop.major_axis_length)\n",
    "    # print(\"cell axis_minor_length:\", prop.minor_axis_length)\n",
    "\n",
    "    # edt transform\n",
    "    edt_distance = ndimage.distance_transform_edt(contour_mask)\n",
    "    if normalize_edt:\n",
    "        edt_flattened = edt_distance.flatten()\n",
    "        edt_distance = (edt_distance - np.min(edt_flattened)) / (np.max(edt_flattened) - np.min(edt_flattened))\n",
    "    # print stats of edt_distance\n",
    "    print(\"edt_distance shape:\", edt_distance.shape)\n",
    "    print(\"edt max:\", np.max(edt_distance))\n",
    "    print(\"edt min:\", np.min(edt_distance))\n",
    "    print(\"edt mean:\", np.mean(edt_distance))\n",
    "    # TODO: add gaussian noise\n",
    "\n",
    "    # determin the area of noise (new labeled region for oversegmentation)\n",
    "    assert len(np.unique(contour_mask)) == 2, \"seg_crop should only contain one label\"\n",
    "    props = regionprops(label_image=contour_mask.astype(int), intensity_image=raw_crop)\n",
    "    assert len(props) == 1, \"seg_crop should only contain one label\"\n",
    "    prop = props[0]\n",
    "    \n",
    "    square_len = int(np.sqrt(prop.area))\n",
    "    for _ in range(num_gauss_areas):\n",
    "        _, rand_pos = add_random_gauss_to_img(contour_mask, raw_crop, square_len, gauss_center_val=gauss_center_val, gauss_std=gauss_std, inplace=True)\n",
    "        add_random_gauss_to_img(contour_mask, edt_distance, square_len, gauss_center_val=edt_gauss_center_val, gauss_std=gauss_std, inplace=True, pos=rand_pos)\n",
    "\n",
    "    # # show edt_distance\n",
    "    # plt.imshow(edt_distance)\n",
    "    # plt.title(\"edt_distance\")\n",
    "    # plt.show()\n",
    "    # watershed segmentation\n",
    "    if markers is None and marker_method == \"hmax\":\n",
    "        # local_hmax = h_maxima(raw_crop, h_threshold)\n",
    "        local_hmax = h_maxima(edt_distance, h_threshold)\n",
    "        markers = label(local_hmax, connectivity=1)\n",
    "    elif markers is None and marker_method == \"local\":\n",
    "        # use local peak as default markers\n",
    "        coords = peak_local_max(edt_distance, min_distance=peak_distance, footprint=np.ones((3, 3)))\n",
    "        mask = np.zeros(edt_distance.shape, dtype=bool)\n",
    "        mask[tuple(coords.T)] = True\n",
    "        markers, _ = ndi.label(mask)\n",
    "\n",
    "    # labels = watershed(edt_distance, markers, mask=contour_mask)\n",
    "    label_mask = watershed(-edt_distance, markers, mask=contour_mask)\n",
    "\n",
    "    # # print shapes\n",
    "    # print(\"markers shape:\", markers.shape)\n",
    "    # print(\"markers unique values:\", np.unique(markers))\n",
    "    # print(np.where(markers > 0))\n",
    "    \n",
    "    # print(\"labels shape:\", label_mask.shape)\n",
    "    # print(\"labels unique values:\", np.unique(label_mask))\n",
    "    # plt.clf()\n",
    "    # plt.imshow(label_mask)\n",
    "    # plt.title(\"labels\")\n",
    "    # plt.show()\n",
    "    if return_all:\n",
    "        return raw_crop, label_mask, edt_distance, markers\n",
    "    return label_mask\n",
    "\n",
    "\n",
    "raw_crop = sampled_sc.get_contour_img()\n",
    "# new_img, label_mask = divide_single_cell_watershed(sampled_sc, peak_distance=20, num_gauss_areas=4, marker_method=\"local\", gauss_center_val=150)\n",
    "\n",
    "new_raw_crop, label_mask, edt_distance, markers = divide_single_cell_watershed(sampled_sc, num_gauss_areas=3, marker_method=\"hmax\", edt_gauss_center_val=10, gauss_std=16, h_threshold=1, return_all=True)\n",
    "\n",
    "fig, axes = plt.subplots(1, 5, figsize=(30, 10))\n",
    "ax = axes[0]\n",
    "ax.imshow(raw_crop)\n",
    "ax.set_title(\"raw_img\")\n",
    "ax = axes[1]\n",
    "ax.imshow(new_raw_crop)\n",
    "ax.set_title(\"new_img\")\n",
    "ax = axes[2]\n",
    "ax.imshow(label_mask)\n",
    "ax.set_title(\"label_mask\")\n",
    "ax = axes[3]\n",
    "ax.imshow(edt_distance)\n",
    "ax.set_title(\"edt_distance\")\n",
    "ax = axes[4]\n",
    "ax.imshow(markers)\n",
    "ax.set_title(\"markers\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate synthetic data by watershed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_synthetic_overseg(sc, num_samples=10, max_try=20, **kwargs):\n",
    "    res_label_masks_and_params = []\n",
    "    num_gauss_area = kwargs[\"num_gauss_areas\"]\n",
    "    for _ in range(num_samples):\n",
    "        counter = 0\n",
    "        num_segs = -1\n",
    "        while num_segs < num_gauss_area and counter < max_try:\n",
    "            label_mask = divide_single_cell_watershed(sc, **kwargs)\n",
    "            num_segs = len(np.unique(label_mask)) - 1\n",
    "            counter += 1\n",
    "        if num_segs < num_gauss_area:\n",
    "            print(\"fail to generate enough segs\")\n",
    "            continue\n",
    "        kwargs[\"num_segs\"] = num_segs\n",
    "        res_label_masks_and_params.append((label_mask, kwargs))\n",
    "    return res_label_masks_and_params\n",
    "\n",
    "overseg_uns_key = \"overseg_imgs\"\n",
    "num_gauss_areas = np.arange(3, 4)\n",
    "num_samples = 1\n",
    "for sc in tqdm(single_cells):\n",
    "    sc.uns[overseg_uns_key] = []\n",
    "    for num_gauss_area in num_gauss_areas:\n",
    "        label_masks_and_params = gen_synthetic_overseg(sc, num_samples=num_samples, peak_distance=10, num_gauss_areas=num_gauss_area, marker_method=\"local\", gauss_center_val=150)\n",
    "        sc.uns[overseg_uns_key].extend(label_masks_and_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    sc = single_cells[i]\n",
    "    plt.imshow(sc.uns[overseg_uns_key][0][0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subdir = Path(\"synthetic_overseg\")\n",
    "overseg_out_dir = out_dir / subdir\n",
    "raw_out_dir = overseg_out_dir / \"raw\"\n",
    "seg_out_dir = overseg_out_dir / \"seg\"\n",
    "gt_out_dir = overseg_out_dir / \"gt\"\n",
    "gt_label_out_dir = overseg_out_dir / \"gt_label_mask\"\n",
    "augmented_seg_dir = overseg_out_dir / \"augmented_seg\"\n",
    "raw_transformed_img_dir = overseg_out_dir / \"raw_transformed_img\"\n",
    "augmented_diff_seg_dir = overseg_out_dir / \"augmented_diff_seg\"\n",
    "os.makedirs(raw_out_dir, exist_ok=True)\n",
    "os.makedirs(seg_out_dir, exist_ok=True)\n",
    "os.makedirs(gt_out_dir, exist_ok=True)\n",
    "os.makedirs(augmented_seg_dir, exist_ok=True)\n",
    "os.makedirs(gt_label_out_dir, exist_ok=True)\n",
    "os.makedirs(raw_transformed_img_dir, exist_ok=True)\n",
    "os.makedirs(augmented_diff_seg_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "overseg_train_path_tuples = []\n",
    "augmented_overseg_data = []\n",
    "filename_pattern = \"img-%d_syn-%d.tif\"\n",
    "for sc in tqdm(single_cells):\n",
    "    img_id = sc.timeframe\n",
    "    for syn_id, overseg_datarow in enumerate(sc.uns[overseg_uns_key]):\n",
    "        params = overseg_datarow[1]\n",
    "        img_crop = sc.get_contour_img()\n",
    "        seg_crop = overseg_datarow[0]\n",
    "        combined_gt_label_mask = sc.get_contour_mask()\n",
    "        assert img_crop.shape == seg_crop.shape == combined_gt_label_mask.shape\n",
    "        raw_img_path = raw_out_dir / (filename_pattern % (img_id, syn_id))\n",
    "        seg_img_path = seg_out_dir / (filename_pattern % (img_id, syn_id))\n",
    "        gt_img_path = gt_out_dir / (filename_pattern % (img_id, syn_id))\n",
    "        gt_label_img_path = gt_label_out_dir / (filename_pattern % (img_id, syn_id))\n",
    "\n",
    "        # call csn augment helper\n",
    "        csn_augment_helper(img_crop=img_crop, \n",
    "            seg_crop=seg_crop, \n",
    "            combined_gt_label_mask=combined_gt_label_mask,\n",
    "            scale_factors=scale_factors,\n",
    "            train_path_tuples=overseg_train_path_tuples,\n",
    "            augmented_data=augmented_overseg_data,\n",
    "            img_id=img_id,\n",
    "            seg_label=syn_id,\n",
    "            gt_label=sc.timeframe,\n",
    "            raw_img_path=raw_img_path,\n",
    "            seg_img_path=seg_img_path,\n",
    "            gt_img_path=gt_img_path,\n",
    "            gt_label_img_path=gt_label_img_path,\n",
    "            augmented_seg_dir=augmented_seg_dir,\n",
    "            augmented_diff_seg_dir=augmented_diff_seg_dir,\n",
    "            filename_pattern=filename_pattern,\n",
    "        )\n",
    "\n",
    "pd.DataFrame(\n",
    "    train_path_tuples,\n",
    "    columns=[\"raw\", \"seg\", \"gt\", \"raw_seg\", \"scale\", \"aug_diff_mask\", \"gt_label_mask\", \"raw_transformed_img\"],\n",
    ").to_csv(overseg_out_dir / \"data.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_overseg_mask_labels(mask: np.array, sc: SingleCellStatic, io_seg_threshold=0.6):\n",
    "    \"\"\"match a single cell's label in a mask. sc must contain its contour information.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    mask : np.array\n",
    "        _description_\n",
    "    sc : \n",
    "        _description_\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    a dict with keys \"seg_label\" and \"iou\"\n",
    "    \"\"\"    \n",
    "    cropped_seg_mask = SingleCellStatic.gen_skimage_bbox_img_crop(sc.bbox, seg_mask)\n",
    "\n",
    "    # Note the order of the arguments are reversed compared with underseg case\n",
    "    # because match_mask_labels_by_iou is designed to match one seg mask to several gt masks (select gt sc's best matching seg label)\n",
    "    # and in the oversegmentation case, we need to match one gt mask to several seg masks\n",
    "    _, seg2gt_info = match_mask_labels_by_iou(seg_mask=sc.get_contour_mask(), gt_mask=cropped_seg_mask, return_all=True)\n",
    "    matched_seg_labels = []\n",
    "    for info in seg2gt_info:\n",
    "        seg_label = info[\"seg_label\"]\n",
    "        iou = info[\"iou\"]\n",
    "        # Not the code below is not a bug: remember we reverse the order of the arguments\n",
    "        io_gt = info[\"io_seg\"]\n",
    "        io_seg = info[\"io_gt\"]\n",
    "        if io_seg > io_seg_threshold:\n",
    "            matched_seg_labels.append(seg_label)\n",
    "    return matched_seg_labels\n",
    "\n",
    "for sc in tqdm(single_cells):\n",
    "    sc_img_path_substr = os.path.basename(sc.meta[\"path\"]).split(\".\")[0]\n",
    "    seg_mask = seg_data.get_img_by_url(sc_img_path_substr, substr=True)\n",
    "    sc.meta[\"overseg_labels\"] = match_seg_mask_label(seg_mask, sc)[\"seg_label\"]\n",
    "    sc.mask_dataset = seg_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO Below: adapt to new code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(img_crop, seg_crop, combined_mask, aug_mask, aug_diff_mask, combined_gt_label_mask, raw_transformed_img_crop) = augmented_data[(1, 14)][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(combined_mask), np.unique(aug_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "\n",
    "mask_tuples = list(augmented_data.values())[0]\n",
    "nsamples = 10\n",
    "# nsamples = np.sum([len(v) for v in augmented_data.values()])\n",
    "ncol = 7\n",
    "fig, axes = plt.subplots(nsamples, ncol, figsize=(25, 5.5 * nsamples))\n",
    "fig.tight_layout()\n",
    "\n",
    "sample_counter = 0\n",
    "for key, mask_tuples in augmented_data.items():\n",
    "    for j in range(len(mask_tuples)):\n",
    "        i = sample_counter\n",
    "        axes[i, 0].imshow(mask_tuples[j][0])\n",
    "        axes[i, 0].set_title(\"raw mask\")\n",
    "        axes[i, 1].imshow(mask_tuples[j][1])\n",
    "        axes[i, 1].set_title(\"seg img\")\n",
    "        axes[i, 2].imshow(mask_tuples[j][2])\n",
    "        axes[i, 2].set_title(\"combined mask\")\n",
    "        axes[i, 3].imshow(mask_tuples[j][3])\n",
    "        axes[i, 3].set_title(\"augmented mask\")\n",
    "        im = axes[i, 4].imshow(mask_tuples[j][4])\n",
    "        axes[i, 4].set_title(\"augmented diff mask\")\n",
    "\n",
    "        values = np.unique(mask_tuples[j][4])\n",
    "        colors = [ im.cmap(im.norm(value)) for value in values]\n",
    "        patches = [ mpatches.Patch(color=colors[i], label=\"Level {l}\".format(l=values[i]) ) for i in range(len(values)) ]\n",
    "        axes[i, 4].legend(handles=patches, loc=2, borderaxespad=0. )\n",
    "\n",
    "        axes[i, 5].imshow(mask_tuples[j][5])\n",
    "        axes[i, 5].set_title(\"combined gt label mask\")\n",
    "\n",
    "        axes[i, 6].imshow(mask_tuples[j][6])\n",
    "        axes[i, 6].set_title(\"raw transformed img\")\n",
    "\n",
    "        sample_counter += 1\n",
    "        if sample_counter >= nsamples:\n",
    "            break\n",
    "    if sample_counter >= nsamples:\n",
    "        break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deprecated code for augmenting a single cell for CSN\n",
    "```\n",
    "from pathlib import Path\n",
    "from copy import deepcopy\n",
    "from PIL import Image, ImageSequence\n",
    "\n",
    "img_paths = []\n",
    "augment_dir = Path(\"../datasets/a549_ccnn/augmented_cells\")\n",
    "augmented_cells = []\n",
    "scale_factor = 0.01\n",
    "padding = 100\n",
    "\n",
    "def augment_single_cell_csn(sc: SingleCellStatic, augment_dir: Path, scale_factor=0.01, padding=40, show=False, bg_value=0):\n",
    "    mask = sc.get_mask_crop(padding=padding).astype(np.uint8)\n",
    "    mask_label = sc.meta[\"seg_label\"]\n",
    "    mask[mask!=mask_label] = bg_value\n",
    "\n",
    "    augmented_mask = dilate_or_erode_mask(mask, scale_factor=scale_factor)\n",
    "    augmentation_save_path = augment_dir / f\"{i}_mask.tif\"\n",
    "    save_png(augmented_mask, str(augmentation_save_path))\n",
    "\n",
    "    meta = {}\n",
    "    meta[\"original_path\"] = sc.meta[\"path\"]\n",
    "    meta[\"original_seg_label\"] = sc.meta[\"seg_label\"]\n",
    "    meta[\"path\"] = augmentation_save_path.as_posix()\n",
    "    meta[\"padding\"] = padding\n",
    "    meta[\"scale_factor\"] = scale_factor\n",
    "    meta[\"method\"] = \"dilate/erode\"\n",
    "\n",
    "    new_sc = SingleCellStatic(\n",
    "        img_dataset=sc.img_dataset,\n",
    "        mask_dataset=sc.mask_dataset,\n",
    "        contour = np.array(sc.contour),\n",
    "        meta=meta,\n",
    "    )\n",
    "\n",
    "    if show:\n",
    "        fig, axes = plt.subplots(1, 4, figsize=(10, 10))\n",
    "        # sc.show_mask(ax=axes[0])\n",
    "        sc.show(ax=axes[0])\n",
    "        axes[2].imshow(mask)\n",
    "        sc.show_contour_img(ax=axes[1])\n",
    "        axes[3].imshow(augmented_mask)\n",
    "\n",
    "        axes[0].set_title(\"original image crop\")\n",
    "        axes[2].set_title(\"seg mask\")\n",
    "        axes[1].set_title(\"gt contour mask\")\n",
    "        axes[3].set_title(\"augmented mask\")\n",
    "    return new_sc\n",
    "\n",
    "\n",
    "augmented_single_cells = []\n",
    "for i in tqdm(range(len(single_cells))):\n",
    "    sc = single_cells[i]\n",
    "    augmented_sc = augment_single_cell_csn(sc, augment_dir, scale_factor=scale_factor, padding=padding, show=False)\n",
    "    augmented_single_cells.append(augmented_sc)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Undersegmentation case:\n",
    "    overlay all the ground truth masks on the original image, and then use the result as the ground truth mask for the undersegmentation case.\n",
    "    Segmentation mask \n",
    "    gt mask\n",
    "\n",
    "OVERSEGMENTATION CASE:\n",
    "    # future work\n",
    "    Segmentation mask\n",
    "    gt mask\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Overlay segmentation mask and gt mask\n",
    "2. Shift the cells in the segmentation mask to the center of the cell\n",
    "3. Synthetic dataset\n",
    "\n",
    "thin_plate_spline?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "livecell",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d9c7226d793827cd27273ad20fbb4775c3cb91053ab9378a09de5f8c6f258919"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
