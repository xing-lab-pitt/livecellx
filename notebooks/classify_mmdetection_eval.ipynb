{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# from cellpose import models\n",
    "from cellpose.io import imread\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from PIL import Image, ImageSequence\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import os.path\n",
    "# from livecellx import segment\n",
    "from livecellx import core\n",
    "from livecellx.core import datasets\n",
    "from livecellx.core.datasets import LiveCellImageDataset, SingleImageDataset\n",
    "from skimage import measure\n",
    "from livecellx.core import SingleCellTrajectory, SingleCellStatic\n",
    "# import detectron2\n",
    "# from detectron2.utils.logger import setup_logger\n",
    "\n",
    "# setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "# model_dir = Path(r\"./scripts/mmdetection_classify/work_dirs/tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb-v6-combined-clipL=2-CLIP_NUM=4/\")\n",
    "# model_dir = Path(r\"./scripts/mmdetection_classify/work_dirs/tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb-v8-combined-clipLen=2-trainClipNum=3-valClipNum=3\")\n",
    "# model_dir = Path(r\"./scripts/mmdetection_classify/work_dirs/tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb-v8-combined-clipLen=1-trainClipNum=3-valClipNum=3\")\n",
    "# path = r\"./scripts/mmdetection_classify/work_dirs/tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb-v6-combined-clipL=2/best_acc_top1_epoch_28.pth\"\n",
    "# model = torch.load(path)\n",
    "# model_dir = Path(r\"./scripts/mmdetection_classify/work_dirs/tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb-v9-combined-clipLen=3-trainClipNum=3-valClipNum=3\")\n",
    "# model_dir = Path(r\"./scripts/mmdetection_classify/work_dirs/tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb-v10-st-combined-clipLen=3-trainClipNum=3-valClipNum=3\")\n",
    "# model_dir = Path(r\"./scripts/mmdetection_classify/work_dirs/tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb-v10-drop-div-combined-clipLen=2-trainClipNum=3-valClipNum=3\")\n",
    "# model_dir = Path(r\"./scripts/mmdetection_classify/work_dirs/tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb-v12-st-combined-clipLen=2-trainClipNum=3-valClipNum=3/\")\n",
    "# out_dir = Path(r\"./scripts/mmdetection_classify/work_dirs/test_results/v12-st-combined-clipLen=2-trainClipNum=3\")\n",
    "\n",
    "# model_dir = Path(r\"./scripts/mmdetection_classify/work_dirs/tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb-v12-st-combined-clipLen=2-trainClipNum=3-valClipNum=3/\")\n",
    "# out_dir = Path(r\"./scripts/mmdetection_classify/work_dirs/test_results/v12-st-combined-clipLen=2-trainClipNum=3\")\n",
    "model_dir = Path(r\"./scripts/mmdetection_classify/work_dirs/tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb-v12-st-video-clipLen=2-trainClipNum=3-valClipNum=3/\")\n",
    "out_dir = Path(r\"./scripts/mmdetection_classify/work_dirs/test_results/v12-st-video-clipLen=2-trainClipNum=3-epoch=18\")\n",
    "\n",
    "out_dir.mkdir(parents=True, exist_ok=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read a trained MMAction model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmengine.config import Config, DictAction\n",
    "from mmaction.registry import MODELS\n",
    "# config_file = str(model_dir / \"tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb.py\")\n",
    "# config_file = str(model_dir / \"config_train_v12_st_cliplen=2_clipnum=3-combined.py\")\n",
    "config_file = str(model_dir / \"config_train_v12_st_cliplen=2_clipnum=3-video.py\")\n",
    "# checkpoint_file = str(model_dir / \"best_acc_top1_epoch_5.pth\")\n",
    "# checkpoint_file = str(model_dir / \"epoch_52.pth\")\n",
    "# checkpoint_file = str(model_dir / \"best_acc_top1_epoch_126.pth\")\n",
    "# checkpoint_file = str(model_dir / \"epoch_250.pth\")\n",
    "# checkpoint_file = str(model_dir / \"best_acc_top1_epoch_448.pth\")\n",
    "# checkpoint_file = str(model_dir / \"epoch_450.pth\")\n",
    "checkpoint_file = str(model_dir / \"best_acc_top1_epoch_18.pth\")\n",
    "\n",
    "cfg = Config.fromfile(config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = MODELS.build()\n",
    "import mmcv\n",
    "from mmaction.apis import init_recognizer, inference_recognizer\n",
    "\n",
    "DEVICE = 'cuda:0' # or 'cpu', based on your device\n",
    "model = init_recognizer(config_file, checkpoint_file, device=DEVICE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load test dataframe and evaluate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# video_dir = r\"./notebook_results/mmaction_train_data_v5/videos\"\n",
    "# mmaction_data_tsv = r\"./notebook_results/mmaction_train_data_v6/test_data_combined.txt\"\n",
    "# video_dir = r\"./notebook_results/mmaction_train_data_v8/videos\"\n",
    "# mmaction_data_tsv = r\"./notebook_results/mmaction_train_data_v8/mmaction_test_data_combined.txt\"\n",
    "# mmaction_data_tsv = r\"./notebook_results/mmaction_train_data_v8/mmaction_train_data_combined.txt\"\n",
    "# video_dir = r\"./notebook_results/mmaction_train_data_v9/videos\"\n",
    "# mmaction_data_tsv = r\"./notebook_results/mmaction_train_data_v9/mmaction_test_data_combined.txt\"\n",
    "# video_dir = r\"./notebook_results/mmaction_train_data_v10-st/videos\"\n",
    "# mmaction_data_tsv = r\"./notebook_results/mmaction_train_data_v10-st/mmaction_test_data_combined.txt\"\n",
    "# video_dir = r\"./notebook_results/mmaction_train_data_v10-drop-div/videos\"\n",
    "# mmaction_data_tsv = r\"./notebook_results/mmaction_train_data_v10-drop-div/mmaction_test_data_combined.txt\"\n",
    "\n",
    "video_dir = r\"./notebook_results/mmaction_train_data_v12-st/videos\"\n",
    "mmaction_data_tsv = r\"./notebook_results/mmaction_train_data_v12-st/mmaction_test_data_combined.txt\"\n",
    "test_data_meta_path = r\"./notebook_results/mmaction_train_data_v12-st/test_data.txt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test dataframe\n",
    "test_data_df = pd.read_csv(test_data_meta_path, sep=\" \")\n",
    "test_data_df = test_data_df.rename(columns={\"label_index\": \"label\"})\n",
    "print(test_data_df.shape)\n",
    "test_data_df[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mmaction df columns are path and label\n",
    "mmaction_data_df = pd.read_csv(mmaction_data_tsv, sep=\" \", header=None)\n",
    "mmaction_data_df.columns = [\"path\", \"label\"]\n",
    "print(mmaction_data_df.shape)\n",
    "mmaction_data_df[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "# # test on all video in the df\n",
    "# test_video_paths = []\n",
    "# test_gt_labels = []\n",
    "# for i, row in tqdm(test_data_df.iterrows()):\n",
    "#     video_path = os.path.join(video_dir, row[\"path\"])\n",
    "#     test_video_paths.append(video_path)\n",
    "#     test_gt_labels.append(row[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nclasses = 3\n",
    "gt2total = {class_idx: 0 for class_idx in range(nclasses)}\n",
    "gt2correct = {class_idx: 0 for class_idx in range(nclasses)}\n",
    "wrong_predictions = []\n",
    "all_predictions = []\n",
    "video_dir = Path(video_dir)\n",
    "for row_ in tqdm(test_data_df.iterrows()):\n",
    "    idx, row_series = row_\n",
    "    video_path = str(video_dir / row_series[\"path\"])\n",
    "    try:\n",
    "        results = inference_recognizer(model, video_path)\n",
    "    except Exception as e:\n",
    "        print(\"exception during prediction:\", e)\n",
    "        continue\n",
    "    predicted_label = results.pred_labels.item.cpu().numpy()[0]\n",
    "    test_gt_label = row_series[\"label\"]\n",
    "    if test_gt_label not in gt2total:\n",
    "        gt2total[test_gt_label] = 0\n",
    "        gt2correct[test_gt_label] = 0\n",
    "    gt2total[test_gt_label] += 1\n",
    "    row_series = row_series.copy()\n",
    "    row_series[\"predicted_label\"] = predicted_label\n",
    "    row_series[\"true_label\"] = test_gt_label\n",
    "    row_series[\"correct\"] = predicted_label == test_gt_label\n",
    "    all_predictions.append(row_series)\n",
    "    if predicted_label != test_gt_label:\n",
    "        print(\"wrong prediction:\", video_path, \"predicted_label:\", predicted_label, \"gt_label:\", test_gt_label)\n",
    "        wrong_predictions.append(row_series)\n",
    "    else:\n",
    "        gt2correct[test_gt_label] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_gt_label, total in gt2total.items():\n",
    "    correct = gt2correct[test_gt_label]\n",
    "    if total == 0:\n",
    "        print(\"no video for label:\", test_gt_label)\n",
    "        continue\n",
    "    print(\"gt_label:\", test_gt_label, \"total:\", total, \"correct:\", correct, \"acc:\", correct / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert all series in wrong_predictions to dataframe\n",
    "all_predictions_df = pd.DataFrame(all_predictions)\n",
    "wrong_predictions_df = pd.DataFrame(wrong_predictions)\n",
    "wrong_predictions_df[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, f1_score\n",
    "\n",
    "def report_classification_metrics(true_labels, predicted_labels):\n",
    "    # calculate the accuracy\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "\n",
    "    # calculate the precision\n",
    "    precision = precision_score(true_labels, predicted_labels, average=\"weighted\")\n",
    "\n",
    "    # calculate the F1 score\n",
    "    f1 = f1_score(true_labels, predicted_labels, average=\"weighted\")\n",
    "\n",
    "    # generate a classification report\n",
    "    report = classification_report(true_labels, predicted_labels)\n",
    "\n",
    "    # print the metrics and classification report\n",
    "    print(f\"Accuracy: {accuracy:.2f}\")\n",
    "    print(f\"Precision: {precision:.2f}\")\n",
    "    print(f\"F1 Score: {f1:.2f}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(report)\n",
    "report_classification_metrics(all_predictions_df[\"true_label\"], all_predictions_df[\"predicted_label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_predictions_df.to_csv(out_dir/\"all_predictions.csv\", index=False)\n",
    "# wrong_predictions_df.to_csv(out_dir/\"wrong_predictions.csv\", index=False)\n",
    "wrong_predictions_df = pd.read_csv(out_dir/\"wrong_predictions.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize wrong predictions according to three frame types: combined, raw and mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the last three levels of the src_dir path\n",
    "wrong_predictions_df['short_src_dir'] = wrong_predictions_df['src_dir'].str.split(r'\\\\|/').apply(lambda x: '/'.join(x[-3:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Set the font scale to 2\n",
    "sns.set(font_scale=2)\n",
    "\n",
    "# Unique frame types\n",
    "unique_frame_types = wrong_predictions_df['frame_type'].unique()\n",
    "\n",
    "# Create visualizations for each frame type\n",
    "for frame_type in unique_frame_types:\n",
    "    filtered_df = wrong_predictions_df[wrong_predictions_df['frame_type'] == frame_type]\n",
    "    \n",
    "    # Set up the figure and axes\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(18, 14))\n",
    "    fig.suptitle(f'Distribution of Wrong Predictions for Frame Type: {frame_type}', fontsize=40)\n",
    "\n",
    "    # Plotting the distribution of 'label'\n",
    "    sns.countplot(data=filtered_df, x='label', ax=axs[0, 0])\n",
    "    axs[0, 0].set_title('Label Distribution')\n",
    "\n",
    "    # Plotting the distribution of 'short_src_dir'\n",
    "    sns.countplot(data=filtered_df, y='short_src_dir', ax=axs[0, 1], order=filtered_df['short_src_dir'].value_counts().index)\n",
    "    axs[0, 1].set_title('Updated Source Directory Distribution (3 Levels)')\n",
    "    axs[0, 1].tick_params(axis='y', rotation=0)\n",
    "\n",
    "    # Plotting the distribution of 'padding_pixels'\n",
    "    sns.countplot(data=filtered_df, x='padding_pixels', ax=axs[1, 0])\n",
    "    axs[1, 0].set_title('Padding Pixels Distribution')\n",
    "\n",
    "    # Placeholder for potential other visualizations for different frame types\n",
    "    axs[1, 1].axis('off')\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "livecell-work",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
