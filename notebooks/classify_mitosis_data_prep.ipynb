{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare mitosis time series data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from cellpose import models\n",
    "from cellpose.io import imread\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from PIL import Image, ImageSequence\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import os.path\n",
    "# from livecell_tracker import segment\n",
    "from livecell_tracker import core\n",
    "from livecell_tracker.core import datasets\n",
    "from livecell_tracker.core.datasets import LiveCellImageDataset, SingleImageDataset\n",
    "from skimage import measure\n",
    "from livecell_tracker.core import SingleCellTrajectory, SingleCellStatic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_json_dir = Path(\"./EBSS_starvation_24h_xy16_annotation\")\n",
    "sample_dataset_dir = sample_json_dir / \"datasets\"\n",
    "class_subfolders = [\"mitosis\", \"apoptosis\", \"normal\"]\n",
    "# sample_paths = glob.glob(str(sample_json_dir / \"*.json\"))\n",
    "\n",
    "class_samples = {}\n",
    "for subfolder in class_subfolders:\n",
    "    class_samples[subfolder] = []\n",
    "    sample_paths = glob.glob(str(sample_json_dir / subfolder / \"*.json\"))\n",
    "    for sample_path in sample_paths:\n",
    "        sample = SingleCellStatic.load_single_cells_json(sample_path)\n",
    "        class_samples[subfolder].append(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Automatically prepare normal samples\n",
    "\n",
    "require tracking done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all scs from class_samples not in normal class\n",
    "exclude_scs = []\n",
    "total_non_normal_samples = 0\n",
    "for class_name, samples in class_samples.items():\n",
    "    if class_name != \"normal\":\n",
    "        for sample in samples:\n",
    "            exclude_scs.extend(sample)\n",
    "            total_non_normal_samples += 1\n",
    "\n",
    "exclude_scs = set(exclude_scs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load all scs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scs_json_path = \"./datasets/test_scs_EBSS_starvation/tmp_corrected_scs.json\"\n",
    "all_scs = SingleCellStatic.load_single_cells_json(all_scs_json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from livecell_tracker.core.single_cell import SingleCellTrajectoryCollection\n",
    "from livecell_tracker.track.sort_tracker_utils import (\n",
    "    track_SORT_bbox_from_scs\n",
    ")\n",
    "# with open(\"./EBSS_starvation_24h_xy16_annotation/single_cell_trajectory_collection.json\", \"r\") as file:\n",
    "#     json_dict = json.load(file)\n",
    "# sctc = SingleCellTrajectoryCollection().load_from_json_dict(json_dict)\n",
    "sctc = track_SORT_bbox_from_scs(all_scs, raw_imgs=all_scs[0].img_dataset, min_hits=3, max_age=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective_sample_num = total_non_normal_samples\n",
    "\n",
    "normal_frame_len_range = (3, 10)\n",
    "counter = 0\n",
    "normal_samples = []\n",
    "\n",
    "max_trial_counter = 100000\n",
    "\n",
    "while counter < objective_sample_num and max_trial_counter > 0:\n",
    "    # randomly select a sct from sctc\n",
    "    # generate a list of scs\n",
    "    track_id = np.random.choice(list(sctc.track_id_to_trajectory.keys()))\n",
    "    sct = sctc.get_trajectory(track_id)\n",
    "    # randomly select a length\n",
    "    frame_len = np.random.randint(*normal_frame_len_range)\n",
    "    # generate a sample\n",
    "    times = list(sct.timeframe_to_single_cell.keys())\n",
    "    times = sorted(times)\n",
    "    if len(times) <= frame_len:\n",
    "        continue\n",
    "    start_idx = np.random.randint(0, len(times) - frame_len)\n",
    "    start_time = times[start_idx]\n",
    "    end_time = times[start_idx + frame_len - 1]\n",
    "\n",
    "    sub_sct = sct.subsct(start_time, end_time)\n",
    "\n",
    "    is_some_sc_in_exclude_scs = False\n",
    "    for time, sc in sub_sct.timeframe_to_single_cell.items():\n",
    "        if sc in exclude_scs:\n",
    "            is_some_sc_in_exclude_scs = True\n",
    "            break\n",
    "    if is_some_sc_in_exclude_scs:\n",
    "        continue\n",
    "    \n",
    "    new_sample = []\n",
    "    for time, sc in sub_sct.timeframe_to_single_cell.items():\n",
    "        new_sample.append(sc)\n",
    "    normal_samples.append(new_sample)\n",
    "    counter += 1\n",
    "    max_trial_counter -= 1\n",
    "\n",
    "normal_samples[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_samples[\"normal\"].extend(normal_samples)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare videos and annotations for MMDetection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = class_samples.keys()\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from livecell_tracker.core.utils import gray_img_to_rgb\n",
    "from livecell_tracker.preprocess.utils import normalize_img_to_uint8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[len(sample) for sample in normal_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_frames_masks_from_sample(sample):\n",
    "    scs_by_time = {}\n",
    "    for sc in sample:\n",
    "        if sc.timeframe not in scs_by_time:\n",
    "            scs_by_time[sc.timeframe] = []\n",
    "        scs_by_time[sc.timeframe].append(sc)\n",
    "    sc_times = sorted(scs_by_time.keys())\n",
    "    sample_scs = []\n",
    "    for i in range(0, len(sc_times)):\n",
    "        time = sc_times[i]\n",
    "        scs_at_time = scs_by_time[time]\n",
    "        sample_scs.append(scs_at_time)\n",
    "\n",
    "    # get the largest bounding box\n",
    "    largest_bbox = [np.inf, np.inf, -np.inf, -np.inf]\n",
    "    for scs in sample_scs:\n",
    "        for sc in scs:\n",
    "            bbox = sc.bbox\n",
    "            if bbox[0] < largest_bbox[0]:\n",
    "                largest_bbox[0] = bbox[0]\n",
    "            if bbox[1] < largest_bbox[1]:\n",
    "                largest_bbox[1] = bbox[1]\n",
    "            if bbox[2] > largest_bbox[2]:\n",
    "                largest_bbox[2] = bbox[2]\n",
    "            if bbox[3] > largest_bbox[3]:\n",
    "                largest_bbox[3] = bbox[3]\n",
    "\n",
    "    # make largest_bbox coords integer\n",
    "    largest_bbox = [int(x) for x in largest_bbox]\n",
    "\n",
    "    video_frames = []\n",
    "    video_frame_masks = []\n",
    "    for scs in sample_scs:\n",
    "        merged_label_mask = np.zeros((largest_bbox[2] - largest_bbox[0], largest_bbox[3] - largest_bbox[1]), dtype=np.uint8)\n",
    "        tmp_img = scs[0].get_img_crop(bbox=largest_bbox)\n",
    "        tmp_img = normalize_img_to_uint8(tmp_img)\n",
    "        tmp_img = gray_img_to_rgb(tmp_img)\n",
    "        for idx, sc in enumerate(scs):\n",
    "            sc_label = idx + 1\n",
    "            sc.bbox = largest_bbox\n",
    "            sc_mask = sc.get_sc_mask(bbox=largest_bbox, dtype=int)\n",
    "\n",
    "            # Warning: simply add the label masks will cause overlapping cells to generate unexpected labels\n",
    "            _nonzero = sc_mask > 0\n",
    "            merged_label_mask[_nonzero] = sc_label\n",
    "\n",
    "            # # for debugging\n",
    "            # fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "            # axes[0].imshow(tmp_img)\n",
    "            # axes[1].imshow(merged_label_mask)\n",
    "            # plt.show()\n",
    "        video_frames.append(tmp_img)\n",
    "        video_frame_masks.append(gray_img_to_rgb(normalize_img_to_uint8(merged_label_mask)))\n",
    "    return video_frames, video_frame_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def gen_mp4_from_frames(video_frames, output_file, fps=5):\n",
    "    # Define the output video file name and properties\n",
    "    frame_size = video_frames[0].shape[:2][::-1]  # reverse the order of width and height\n",
    "\n",
    "    # Create a VideoWriter object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(str(output_file), fourcc, fps, frame_size)\n",
    "    # Write each frame to the output video\n",
    "    for frame in video_frames:\n",
    "        out.write(frame)\n",
    "    out.release()\n",
    "\n",
    "def gen_samples_mp4s(sc_samples: List[List[SingleCellStatic]], class_label, output_dir):\n",
    "    \n",
    "    res_paths = []\n",
    "    for i, sample in enumerate(sc_samples):\n",
    "        output_file = output_dir / (f'{class_label}_{i}.mp4')\n",
    "        mask_output_file = output_dir / (f'{class_label}_{i}_mask.mp4')\n",
    "        fps = 1\n",
    "        print(\"len sample: \", len(sample))\n",
    "        # record video file path and class label\n",
    "        video_frames, video_frame_masks = video_frames_masks_from_sample(sample)\n",
    "        print(\"len video_frames: \", len(video_frames))\n",
    "        print(\"len masks video: \", len(video_frame_masks))\n",
    "\n",
    "        gen_mp4_from_frames(video_frames, output_file, fps=fps)\n",
    "        gen_mp4_from_frames(video_frame_masks, mask_output_file, fps=fps)\n",
    "        res_paths.append(output_file)\n",
    "    return res_paths\n",
    "\n",
    "class_labels = ['mitosis', 'apoptosis', 'normal']\n",
    "\n",
    "class_label = \"mitosis\"\n",
    "\n",
    "csv_data_list = []\n",
    "for class_label in class_labels:\n",
    "    output_dir = Path('notebook_results/mmaction_train_data') / \"videos\"\n",
    "    output_dir.mkdir(exist_ok=True, parents=True)\n",
    "    video_frames_samples = class_samples[class_label]\n",
    "    res_paths = gen_samples_mp4s(video_frames_samples, class_label, output_dir)\n",
    "\n",
    "    # path, label_index\n",
    "    class_label_index = class_labels.index(class_label)\n",
    "    csv_data_list.extend([(str(path), class_label_index) for path in res_paths])\n",
    "\n",
    "df = pd.DataFrame(csv_data_list, columns=['video_path', 'label_index'])\n",
    "df.to_csv('notebook_results/mmaction_train_data/train_data.csv', index=False, header=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "livecell",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
