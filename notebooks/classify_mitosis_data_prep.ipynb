{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare mitosis time series data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from cellpose import models\n",
    "from cellpose.io import imread\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from PIL import Image, ImageSequence\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import os.path\n",
    "# from livecellx import segment\n",
    "from livecellx import core\n",
    "from livecellx.core import datasets\n",
    "from livecellx.core.datasets import LiveCellImageDataset, SingleImageDataset\n",
    "from skimage import measure\n",
    "from livecellx.core import SingleCellTrajectory, SingleCellStatic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from livecellx.track.classify_utils import load_class2samples_from_json_dir, load_all_json_dirs\n",
    "# sample_json_dir = Path(\"./EBSS_starvation_24h_xy16_annotation\")\n",
    "\n",
    "sample_json_dirs_v0 = [Path(r\"./datasets/test_scs_EBSS_starvation/XY1/annotations\"), Path(r\"./datasets/test_scs_EBSS_starvation/XY16/annotations\")]\n",
    "\n",
    "round1_json_dirs = sample_json_dirs_v0 + [\n",
    "    Path(r\"D:\\LiveCellTracker-dev\\datasets\\mitosis-annotations-2023\\shiman_XY01\\XY01\"),\n",
    "Path(r\"D:\\LiveCellTracker-dev\\datasets\\mitosis-annotations-2023\\shiman_XY09\\XY09\"),\n",
    "Path(r\"D:\\LiveCellTracker-dev\\datasets\\mitosis-annotations-2023\\shiman_XY10\\XY10\"),\n",
    "Path(r\"D:\\LiveCellTracker-dev\\datasets\\mitosis-annotations-2023\\Yajushi\\tifs_CFP_A549-VIM_lessThan24hr_NoTreat_NA_YL_Ti2e_2022-10-19\\XY1\\annotations\"),\n",
    "]\n",
    "\n",
    "round2_json_dirs = [\n",
    "Path(r\"../datasets/mitosis-annotations-2023/shiman_CXA_high_density/C0.5^4/\"),\n",
    "Path(r\"../datasets/mitosis-annotations-2023/shiman_CXA_high_density/C0.75^4/\"),\n",
    "Path(r\"../datasets/mitosis-annotations-2023/shiman_CXA_high_density/C10^3/\"),\n",
    "Path(r\"../datasets/mitosis-annotations-2023/shiman_CXA_high_density/C10^4/\")\n",
    "] + [\n",
    "    Path(f\"../datasets/mitosis-annotations-2023/Gaohan_tifs_CFP_A549-VIM_lessThan24hr_NoTreat_NA_YL_Ti2e_2022-10-19/XY{pos}/annotations\") for pos in range(4, 14)\n",
    "]\n",
    "\n",
    "sample_json_dirs = sample_json_dirs_v0 + round1_json_dirs + round2_json_dirs\n",
    "all_class2samples, all_class2sample_extra_info = load_all_json_dirs(sample_json_dirs)\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_class2samples, all_class2sample_extra_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_class2samples[\"mitosis\"]), len(all_class2samples[\"apoptosis\"]), len(all_class2samples[\"normal\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_zero_len_samples = 0\n",
    "for key in all_class2samples.keys():\n",
    "    for sample in all_class2samples[key]:\n",
    "        if len(sample) == 0:\n",
    "            num_zero_len_samples += 1\n",
    "print(\"num_zero_len_samples: \", num_zero_len_samples)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Automatically prepare normal samples\n",
    "\n",
    "require tracking done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all scs from class_samples not in normal class\n",
    "exclude_scs = []\n",
    "total_non_normal_samples = 0\n",
    "for class_name, samples in all_class2samples.items():\n",
    "    if class_name != \"normal\":\n",
    "        for sample in samples:\n",
    "            exclude_scs.extend(sample)\n",
    "            total_non_normal_samples += 1\n",
    "\n",
    "exclude_scs = set(exclude_scs)\n",
    "exclude_scs_ids = {str(sc.id) for sc in exclude_scs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from livecellx.core.sct_operator import create_scs_edit_viewer\n",
    "# sct_operator = create_scs_edit_viewer(exclude_scs, img_dataset = list(exclude_scs)[0].img_dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load all single cells, including mitosis and normal ones, for further generating normal samples automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from livecellx.core.single_cell import SingleCellTrajectoryCollection\n",
    "from livecellx.track.sort_tracker_utils import (\n",
    "    track_SORT_bbox_from_scs\n",
    ")\n",
    "\n",
    "all_scs_json_path = [\"./datasets/test_scs_EBSS_starvation/XY1/single_cells.json\", \"./datasets/test_scs_EBSS_starvation/XY16/single_cells.json\"]\n",
    "# all_scs_json_path = \"./datasets/test_scs_EBSS_starvation/XY16/tmp_corrected_scs.json\"\n",
    "sctc = SingleCellTrajectoryCollection()\n",
    "for json_path in all_scs_json_path:\n",
    "    print(\"json path:\", json_path)\n",
    "    _scs = SingleCellStatic.load_single_cells_json(json_path)\n",
    "    tmp_sctc = track_SORT_bbox_from_scs(_scs, raw_imgs=_scs[0].img_dataset, min_hits=3, max_age=3)\n",
    "    tids = set(sctc.get_all_tids())\n",
    "    if len(tids) != 0:\n",
    "        max_tid = max(tids)\n",
    "    else:\n",
    "        max_tid = 0\n",
    "    for tid, traj in tmp_sctc:\n",
    "        traj.meta[\"src_dir\"] = json_path\n",
    "        traj.track_id = tid + max_tid + 1\n",
    "        sctc.add_trajectory(traj)\n",
    "        traj_scs = traj.get_all_scs()\n",
    "        for sc in traj_scs:\n",
    "            sc.meta[\"src_dir\"] = json_path\n",
    "    del tmp_sctc\n",
    "\n",
    "all_scs = SingleCellStatic.load_single_cells_jsons(all_scs_json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# with open(\"./EBSS_starvation_24h_xy16_annotation/single_cell_trajectory_collection.json\", \"r\") as file:\n",
    "#     json_dict = json.load(file)\n",
    "# sctc = SingleCellTrajectoryCollection().load_from_json_dict(json_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set numpy seed\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "\n",
    "objective_sample_num = total_non_normal_samples * 10\n",
    "\n",
    "normal_frame_len_range = (3, 10)\n",
    "counter = 0\n",
    "normal_samples = []\n",
    "normal_samples_extra_info = []\n",
    "max_trial_counter = 100000\n",
    "while counter < objective_sample_num and max_trial_counter > 0:\n",
    "    # randomly select a sct from sctc\n",
    "    # generate a list of scs\n",
    "    track_id = np.random.choice(list(sctc.track_id_to_trajectory.keys()))  \n",
    "    sct = sctc.get_trajectory(track_id)\n",
    "    # randomly select a length\n",
    "    frame_len = np.random.randint(*normal_frame_len_range)\n",
    "    # generate a sample\n",
    "    times = list(sct.timeframe_to_single_cell.keys())\n",
    "    times = sorted(times)\n",
    "    if len(times) <= frame_len:\n",
    "        continue\n",
    "    start_idx = np.random.randint(0, len(times) - frame_len)\n",
    "    start_time = times[start_idx]\n",
    "    end_time = times[start_idx + frame_len - 1]\n",
    "\n",
    "    sub_sct = sct.subsct(start_time, end_time)\n",
    "\n",
    "    is_some_sc_in_exclude_scs = False\n",
    "    for time, sc in sub_sct.timeframe_to_single_cell.items():\n",
    "        # print(\"sc.id:\", sc.id, type(sc.id))\n",
    "        if str(sc.id) in exclude_scs_ids:\n",
    "            is_some_sc_in_exclude_scs = True\n",
    "            break\n",
    "    if is_some_sc_in_exclude_scs:\n",
    "        print(\"some sc in the exclude scs list\")\n",
    "        continue\n",
    "    \n",
    "    new_sample = []\n",
    "    for time, sc in sub_sct.timeframe_to_single_cell.items():\n",
    "        new_sample.append(sc)\n",
    "    normal_samples.append(new_sample)\n",
    "    normal_samples_extra_info.append({\"src_dir\": sub_sct.get_all_scs()[0].meta[\"src_dir\"]})\n",
    "    counter += 1\n",
    "    max_trial_counter -= 1\n",
    "\n",
    "normal_samples[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_class2samples[\"normal\"].extend(normal_samples)\n",
    "all_class2sample_extra_info[\"normal\"].extend(normal_samples_extra_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_class2samples[\"normal\"]), len(all_class2sample_extra_info[\"normal\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add start and end time to all_class2sample_extra_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for class_name, samples in all_class2samples.items():\n",
    "    print(class_name, len(samples))\n",
    "    class_extra_infos = all_class2sample_extra_info[class_name]\n",
    "    for sample_idx, sample in enumerate(samples):\n",
    "        if len(sample) == 0:\n",
    "            continue\n",
    "        sample_extra_info = class_extra_infos[sample_idx]\n",
    "        min_time = None\n",
    "        max_time = None\n",
    "        for sc in sample:\n",
    "            if min_time is None or sc.timeframe < min_time:\n",
    "                min_time = sc.timeframe\n",
    "            if max_time is None or sc.timeframe > max_time:\n",
    "                max_time = sc.timeframe\n",
    "        sample_extra_info[\"start_time\"] = min_time\n",
    "        sample_extra_info[\"end_time\"] = max_time\n",
    "        sample_extra_info[\"first_sc_id\"] = sample[0].id\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare videos and annotations for MMDetection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = all_class2samples.keys()\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from livecellx.core.utils import gray_img_to_rgb, rgb_img_to_gray\n",
    "from livecellx.preprocess.utils import normalize_img_to_uint8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from livecellx.track.classify_utils import video_frames_and_masks_from_sample, combine_video_frames_and_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from livecellx.core.sc_video_utils import gen_mp4_from_frames, gen_class2sample_samples, gen_samples_mp4s\n",
    "\n",
    "# ver = \"10-st\" # single trajectory ver\n",
    "# ver = \"test\" # single trajectory ver\n",
    "# ver = \"11-st-run0\"\n",
    "# MAKE_SINGLE_CELL_TRAJ_SAMPLES = True\n",
    "# DROP_MITOSIS_DIV = False\n",
    "\n",
    "# ver = \"10-drop-div\"\n",
    "# DROP_MITOSIS_DIV = True\n",
    "# ver = \"-test\"\n",
    "\n",
    "# ver = \"11-drop-div\"\n",
    "# MAKE_SINGLE_CELL_TRAJ_SAMPLES = False\n",
    "# DROP_MITOSIS_DIV = True\n",
    "\n",
    "# ver = \"12-st\"\n",
    "# MAKE_SINGLE_CELL_TRAJ_SAMPLES = True\n",
    "# DROP_MITOSIS_DIV = False\n",
    "\n",
    "# ver = \"12-drop-div\"\n",
    "# MAKE_SINGLE_CELL_TRAJ_SAMPLES = False\n",
    "# DROP_MITOSIS_DIV = True\n",
    "\n",
    "# ver = \"12-all\"\n",
    "# MAKE_SINGLE_CELL_TRAJ_SAMPLES = False\n",
    "# DROP_MITOSIS_DIV = False\n",
    "\n",
    "ver = \"test-all\"\n",
    "MAKE_SINGLE_CELL_TRAJ_SAMPLES = False\n",
    "DROP_MITOSIS_DIV = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_dir = Path(f'notebook_results/mmaction_train_data_v{ver}')\n",
    "class_labels = ['mitosis', 'apoptosis', 'normal']\n",
    "class_label = \"mitosis\"\n",
    "frame_types = [\"video\", \"mask\", \"combined\"]\n",
    "fps = 3\n",
    "\n",
    "# 1 instead of 0 to prevent the decord (used by mmdetection) python package error\n",
    "padding_pixels = [1, 20, 40, 50, 100, 200, 400]\n",
    "\n",
    "\n",
    "\n",
    "# split train and test data\n",
    "\n",
    "# get #samples from all_class2samples\n",
    "_split = 0.8\n",
    "\n",
    "train_class2samples = {}\n",
    "test_class2samples = {}\n",
    "train_class2sample_extra_info = {}\n",
    "test_class2sample_extra_info = {}\n",
    "\n",
    "# randomize train and test data\n",
    "\n",
    "\n",
    "for key in all_class2samples.keys():\n",
    "    randomized_indices = np.random.permutation(len(all_class2samples[key])).astype(int)\n",
    "    split_idx = int(len(all_class2samples[key]) * _split)\n",
    "    _train_indices = randomized_indices[:split_idx]\n",
    "    _test_indices = randomized_indices[split_idx:]\n",
    "    train_class2samples[key] = np.array(all_class2samples[key], dtype=object)[_train_indices]\n",
    "    test_class2samples[key] = np.array(all_class2samples[key], dtype=object)[_test_indices]\n",
    "\n",
    "    train_class2sample_extra_info[key] = np.array(all_class2sample_extra_info[key], dtype=object)[_train_indices]\n",
    "    test_class2sample_extra_info[key] = np.array(all_class2sample_extra_info[key], dtype=object)[_test_indices]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_class2samples[\"normal\"]), len(test_class2samples[\"normal\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_class2samples[\"mitosis\"]), len(test_class2samples[\"mitosis\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_frames_and_masks_from_sample(train_class2samples[\"normal\"][6])[0][0].shape\n",
    "# train_class2samples[\"normal\"][6][1].show_panel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import livecellx\n",
    "importlib.reload(livecellx.track.classify_utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_check = 6\n",
    "video_frames, video_frame_masks = video_frames_and_masks_from_sample(train_class2samples[\"normal\"][idx_to_check], padding_pixels=0)\n",
    "print(\"video frames dtype:\", video_frames[0].dtype)\n",
    "print(\"video frames shape:\", video_frames[0].shape)\n",
    "print(\"video frame masks dtype:\", video_frame_masks[0].dtype)\n",
    "print(\"video frame masks shape:\", video_frame_masks[0].shape)\n",
    "combined_frames = livecellx.track.classify_utils.combine_video_frames_and_masks(video_frames, video_frame_masks, edt_transform=True)\n",
    "combined_frames = np.array(combined_frames).astype(np.uint8)\n",
    "# combined_frames = np.maximum(combined_frames - 1, 0).astype(np.uint8)\n",
    "print(\"combined_frames shape: \", combined_frames[0].shape)\n",
    "gen_mp4_from_frames(combined_frames, \"./test_video_output.mp4\", fps=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visually check the generated frames' values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# channel = 2\n",
    "# plt.imshow(combined_frames[0][..., channel])\n",
    "# combined_frames[1][..., channel].max(), combined_frames[1][..., 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(combined_frames).flatten().min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make single cell trajectories only (ONE cell per time frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "from livecellx.track.data_prep_utils import check_one_sc_at_time\n",
    "from livecellx.track.data_prep_utils import make_one_cell_per_timeframe_for_class2samples, make_one_cell_per_timeframe_helper, make_one_cell_per_timeframe_samples\n",
    "\n",
    "\n",
    "\n",
    "sample = train_class2samples[\"mitosis\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[sc.timeframe for sc in sample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(make_one_cell_per_timeframe_samples(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MAKE_SINGLE_CELL_TRAJ_SAMPLES:\n",
    "    train_class2samples, train_class2sample_extra_info = make_one_cell_per_timeframe_for_class2samples(train_class2samples, train_class2sample_extra_info)\n",
    "    test_class2samples, test_class2sample_extra_info = make_one_cell_per_timeframe_for_class2samples(test_class2samples, test_class2sample_extra_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop the cell divison part for easier inference durign testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from livecellx.track.data_prep_utils import drop_multiple_cell_frames_in_samples\n",
    "\n",
    "if DROP_MITOSIS_DIV:\n",
    "    train_class2samples = drop_multiple_cell_frames_in_samples(train_class2samples)\n",
    "    test_class2samples = drop_multiple_cell_frames_in_samples(test_class2samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, val in train_class2samples.items():\n",
    "    assert len(val) == len(train_class2sample_extra_info[key]), f\"key: {key}, len(val): {len(val)}, len(train_class2sample_extra_info[key]): {len(train_class2sample_extra_info[key])}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_class2sample_extra_info[\"mitosis\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import livecellx\n",
    "import livecellx.core.sc_video_utils\n",
    "importlib.reload(livecellx.core.sc_video_utils)\n",
    "\n",
    "# # for debug\n",
    "# test_sample_num = 3\n",
    "# padding_pixels = [1, 20]\n",
    "# train_class2samples = {key: value[:test_sample_num] for key, value in all_class2samples.items()}\n",
    "# test_class2samples = {key: value[:test_sample_num] for key, value in all_class2samples.items()}\n",
    "# train_class2sample_extra_info = {key: value[:test_sample_num] for key, value in all_class2sample_extra_info.items()}\n",
    "# test_class2sample_extra_info = {key: value[:test_sample_num] for key, value in all_class2sample_extra_info.items()}\n",
    "\n",
    "# padding_pixels = [20]\n",
    "\n",
    "train_sample_info_df = livecellx.core.sc_video_utils.gen_class2sample_samples(\n",
    "    train_class2samples,\n",
    "    train_class2sample_extra_info,\n",
    "    data_dir,\n",
    "    class_labels,\n",
    "    padding_pixels=padding_pixels,\n",
    "    frame_types=frame_types,\n",
    "    fps=fps,\n",
    "    prefix=\"train\",\n",
    ")\n",
    "test_sample_info_df = livecellx.core.sc_video_utils.gen_class2sample_samples(\n",
    "    test_class2samples,\n",
    "    test_class2sample_extra_info,\n",
    "    data_dir,\n",
    "    class_labels,\n",
    "    padding_pixels=padding_pixels,\n",
    "    frame_types=frame_types,\n",
    "    fps=fps,\n",
    "    prefix=\"test\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample_info_df[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_sample_info_df.to_csv(\n",
    "    data_dir / f\"train_data.txt\",\n",
    "    index=False,\n",
    "    header=True,\n",
    "    sep=\" \",\n",
    ")\n",
    "test_sample_info_df.to_csv(\n",
    "    data_dir / f\"test_data.txt\",\n",
    "    index=False,\n",
    "    header=True,\n",
    "    sep=\" \",\n",
    ")\n",
    "\n",
    "mmaction_df_paths = []\n",
    "for selected_frame_type in frame_types:\n",
    "    train_df_path = data_dir / f\"mmaction_train_data_{selected_frame_type}.txt\"\n",
    "    train_selected_frame_type_df = train_sample_info_df[train_sample_info_df[\"frame_type\"] == selected_frame_type]\n",
    "    train_selected_frame_type_df = train_selected_frame_type_df.reset_index(drop=True)\n",
    "    train_selected_frame_type_df = train_selected_frame_type_df[[\"path\", \"label_index\"]]\n",
    "    train_selected_frame_type_df.to_csv(train_df_path, index=False, header=False, sep=\" \")\n",
    "\n",
    "    test_df_path = data_dir / f\"mmaction_test_data_{selected_frame_type}.txt\"\n",
    "    test_selected_frame_type_df = test_sample_info_df[test_sample_info_df[\"frame_type\"] == selected_frame_type]\n",
    "    test_selected_frame_type_df = test_selected_frame_type_df[[\"path\", \"label_index\"]]\n",
    "    test_selected_frame_type_df = test_selected_frame_type_df.reset_index(drop=True)\n",
    "    test_selected_frame_type_df.to_csv(test_df_path, index=False, header=False, sep=\" \")\n",
    "\n",
    "    mmaction_df_paths.append(train_df_path)\n",
    "    mmaction_df_paths.append(test_df_path)\n",
    "\n",
    "\n",
    "# # The follwing code generates v1-v7 test data. The issue is that some of test data shows up in train data, through different padding values.\n",
    "# data_df_path = data_dir/'all_data.txt'\n",
    "# sample_df = gen_samples_df(data_dir, class_labels, padding_pixels, frame_types, fps)\n",
    "# sample_df.to_csv(data_df_path, index=False, header=False, sep=' ')\n",
    "# for selected_frame_type in frame_types:\n",
    "#     selected_frame_type_df = sample_df[sample_df[\"frame_type\"] == selected_frame_type]\n",
    "#     selected_frame_type_df = selected_frame_type_df.reset_index(drop=True)\n",
    "#     train_df_path = data_dir/f'train_data_{selected_frame_type}.txt'\n",
    "#     test_df_path = data_dir/f'test_data_{selected_frame_type}.txt'\n",
    "#     train_df = selected_frame_type_df.sample(frac=0.8, random_state=0, replace=False)\n",
    "#     test_df = selected_frame_type_df.drop(train_df.index, inplace=False)\n",
    "\n",
    "#     # only keep the path and label_index columns\n",
    "#     train_df = train_df[[\"path\", \"label_index\"]]\n",
    "#     test_df = test_df[[\"path\", \"label_index\"]]\n",
    "\n",
    "#     train_df.to_csv(train_df_path, index=False, header=False, sep=' ')\n",
    "#     test_df.to_csv(test_df_path, index=False, header=False, sep=' ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_class2samples"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "video_paths = list(Path(data_dir/'videos').glob('*.mp4'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to a `decord` package [issue](https://github.com/dmlc/decord/issues/150), to use mmaction2 we must check if the videos can be loaded by `decord` correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import decord\n",
    "decord.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import decord\n",
    "invalid_decord_paths = []\n",
    "for path in video_paths:\n",
    "# for path in [\"./notebook_results/train_normal_6_raw_padding-0.mp4\"]:\n",
    "# for path in [\"./test_video_output.mp4\"]:\n",
    "    reader = decord.VideoReader(str(path))\n",
    "    reader.seek(0)\n",
    "    imgs = list()\n",
    "    frame_inds = range(0, len(reader))\n",
    "    for idx in frame_inds:\n",
    "        reader.seek(idx)\n",
    "        frame = reader.next()\n",
    "        imgs.append(frame.asnumpy())\n",
    "        frame = frame.asnumpy()\n",
    "\n",
    "        num_channels = frame.shape[-1]\n",
    "        if num_channels != 3:\n",
    "            print(\"invalid video for decord (https://github.com/dmlc/decord/issues/150): \", path)\n",
    "            invalid_decord_paths.append(path)\n",
    "            break\n",
    "        # fig, axes = plt.subplots(1, num_channels, figsize=(20, 10))\n",
    "        # for i in range(num_channels):\n",
    "        #     axes[i].imshow(frame[:, :, i])\n",
    "        # plt.show()\n",
    "    del reader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove \"invalid\" videos (cannot be read by decord) from mmdetection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract file names from invalid decord paths\n",
    "invalid_decord_filenames = set([os.path.basename(path) for path in invalid_decord_paths])\n",
    "\n",
    "for df_path in mmaction_df_paths:\n",
    "    _df = pd.read_csv(df_path, sep=\" \", header=None)\n",
    "    # remove all the rows with column \"path\" in invalid_decord_filenames\n",
    "    filtered_df = _df[~_df[0].isin(invalid_decord_filenames)]\n",
    "\n",
    "    df_filename = os.path.basename(df_path)\n",
    "    # summarize the number of samples for the file\n",
    "    print(f\"df_path: {df_filename}, #filtered: {_df.shape[0] - filtered_df.shape[0]}, original df shape: {_df.shape}, filtered df shape: {filtered_df.shape}\")\n",
    "\n",
    "    # save to the disk\n",
    "    filtered_df.to_csv(df_path, index=False, header=False, sep=\" \")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check if videos can be loaded by cv2 correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(\"./test_video_output.mp4\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    assert frame.shape[-1] == 3, \"frame should be in RGB format\"\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# train_df_path = data_dir/'train_data.csv'\n",
    "# test_df_path = data_dir/'test_data.csv'\n",
    "\n",
    "# # split train and test from df\n",
    "# train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "# train_df.to_csv(train_df_path, index=False, header=False, sep=' ')\n",
    "# test_df.to_csv(test_df_path, index=False, header=False, sep=' ')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "livecell",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
