{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare mitosis time series data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from cellpose import models\n",
    "from cellpose.io import imread\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from PIL import Image, ImageSequence\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import os.path\n",
    "# from livecell_tracker import segment\n",
    "from livecell_tracker import core\n",
    "from livecell_tracker.core import datasets\n",
    "from livecell_tracker.core.datasets import LiveCellImageDataset, SingleImageDataset\n",
    "from skimage import measure\n",
    "from livecell_tracker.core import SingleCellTrajectory, SingleCellStatic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_json_dir = Path(\"./EBSS_starvation_24h_xy16_annotation\")\n",
    "sample_dataset_dir = sample_json_dir / \"datasets\"\n",
    "class_subfolders = [\"mitosis\", \"apoptosis\", \"normal\"]\n",
    "# sample_paths = glob.glob(str(sample_json_dir / \"*.json\"))\n",
    "\n",
    "class_samples = {}\n",
    "for subfolder in class_subfolders:\n",
    "    class_samples[subfolder] = []\n",
    "    sample_paths = glob.glob(str(sample_json_dir / subfolder / \"*.json\"))\n",
    "    for sample_path in sample_paths:\n",
    "        sample = SingleCellStatic.load_single_cells_json(sample_path)\n",
    "        class_samples[subfolder].append(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Automatically prepare normal samples\n",
    "\n",
    "require tracking done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all scs from class_samples not in normal class\n",
    "exclude_scs = []\n",
    "total_non_normal_samples = 0\n",
    "for class_name, samples in class_samples.items():\n",
    "    if class_name != \"normal\":\n",
    "        for sample in samples:\n",
    "            exclude_scs.extend(sample)\n",
    "            total_non_normal_samples += 1\n",
    "\n",
    "exclude_scs = set(exclude_scs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load all scs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scs_json_path = \"./datasets/test_scs_EBSS_starvation/tmp_corrected_scs.json\"\n",
    "all_scs = SingleCellStatic.load_single_cells_json(all_scs_json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from livecell_tracker.core.single_cell import SingleCellTrajectoryCollection\n",
    "from livecell_tracker.track.sort_tracker_utils import (\n",
    "    track_SORT_bbox_from_scs\n",
    ")\n",
    "# with open(\"./EBSS_starvation_24h_xy16_annotation/single_cell_trajectory_collection.json\", \"r\") as file:\n",
    "#     json_dict = json.load(file)\n",
    "# sctc = SingleCellTrajectoryCollection().load_from_json_dict(json_dict)\n",
    "sctc = track_SORT_bbox_from_scs(all_scs, raw_imgs=all_scs[0].img_dataset, min_hits=3, max_age=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective_sample_num = total_non_normal_samples * 10\n",
    "\n",
    "normal_frame_len_range = (3, 10)\n",
    "counter = 0\n",
    "normal_samples = []\n",
    "max_trial_counter = 100000\n",
    "while counter < objective_sample_num and max_trial_counter > 0:\n",
    "    # randomly select a sct from sctc\n",
    "    # generate a list of scs\n",
    "    track_id = np.random.choice(list(sctc.track_id_to_trajectory.keys()))  \n",
    "    sct = sctc.get_trajectory(track_id)\n",
    "    # randomly select a length\n",
    "    frame_len = np.random.randint(*normal_frame_len_range)\n",
    "    # generate a sample\n",
    "    times = list(sct.timeframe_to_single_cell.keys())\n",
    "    times = sorted(times)\n",
    "    if len(times) <= frame_len:\n",
    "        continue\n",
    "    start_idx = np.random.randint(0, len(times) - frame_len)\n",
    "    start_time = times[start_idx]\n",
    "    end_time = times[start_idx + frame_len - 1]\n",
    "\n",
    "    sub_sct = sct.subsct(start_time, end_time)\n",
    "\n",
    "    is_some_sc_in_exclude_scs = False\n",
    "    for time, sc in sub_sct.timeframe_to_single_cell.items():\n",
    "        if sc in exclude_scs:\n",
    "            is_some_sc_in_exclude_scs = True\n",
    "            break\n",
    "    if is_some_sc_in_exclude_scs:\n",
    "        continue\n",
    "    \n",
    "    new_sample = []\n",
    "    for time, sc in sub_sct.timeframe_to_single_cell.items():\n",
    "        new_sample.append(sc)\n",
    "    normal_samples.append(new_sample)\n",
    "    counter += 1\n",
    "    max_trial_counter -= 1\n",
    "\n",
    "normal_samples[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_samples[\"normal\"].extend(normal_samples)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare videos and annotations for MMDetection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = class_samples.keys()\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from livecell_tracker.core.utils import gray_img_to_rgb, rgb_img_to_gray\n",
    "from livecell_tracker.preprocess.utils import normalize_img_to_uint8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[len(sample) for sample in normal_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from livecell_tracker.track.classify_utils import video_frames_and_masks_from_sample, combine_video_frames_and_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def gen_mp4_from_frames(video_frames, output_file, fps):\n",
    "    # Define the output video file name and properties\n",
    "    frame_size = video_frames[0].shape[:2][::-1]  # reverse the order of width and height\n",
    "\n",
    "    # Create a VideoWriter object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(str(output_file), fourcc, fps, frame_size)\n",
    "    # Write each frame to the output video\n",
    "    for frame in video_frames:\n",
    "        out.write(frame)\n",
    "    out.release()\n",
    "\n",
    "def gen_samples_mp4s(sc_samples: List[List[SingleCellStatic]], class_label, output_dir, fps = 1, padding_pixels=50):\n",
    "    \"\"\"\n",
    "    Generate mp4 videos and masks from a list of SingleCellStatic samples.\n",
    "    Args:\n",
    "        sc_samples: A list of SingleCellStatic samples.\n",
    "        class_label: A string representing the class label of the samples.\n",
    "        output_dir: A Path object representing the directory to save the generated videos and masks.\n",
    "        fps: An integer representing the frames per second of the generated videos.\n",
    "        padding_pixels: An integer representing the number of pixels to pad around the cells in the generated videos and masks.\n",
    "    Returns:\n",
    "        A dictionary containing the file paths of the generated videos, masks, and combined videos.\n",
    "    \"\"\"\n",
    "    res_paths = {\n",
    "        \"video\": [],\n",
    "        \"mask\": [],\n",
    "        \"combined\": []\n",
    "    }\n",
    "    for i, sample in enumerate(sc_samples):\n",
    "        output_file = output_dir / (f'{class_label}_{i}_raw_padding-{padding_pixels}.mp4')\n",
    "        mask_output_file = output_dir / (f'{class_label}_{i}_mask_padding-{padding_pixels}.mp4')\n",
    "        combined_output_file = output_dir / (f'{class_label}_{i}_combined_padding-{padding_pixels}.mp4')\n",
    "        \n",
    "        # record video file path and class label\n",
    "        video_frames, video_frame_masks = video_frames_and_masks_from_sample(sample, padding_pixels=padding_pixels)\n",
    "        combined_frames = combine_video_frames_and_masks(video_frames, video_frame_masks)\n",
    "\n",
    "        # # for debug\n",
    "        # print(\"len video_frames: \", len(video_frames))\n",
    "        # print(\"len masks video: \", len(video_frame_masks))\n",
    "        # print(\"len combined_frames: \", len(combined_frames))\n",
    "\n",
    "        gen_mp4_from_frames(video_frames, output_file, fps=fps)\n",
    "        gen_mp4_from_frames(video_frame_masks, mask_output_file, fps=fps)\n",
    "        gen_mp4_from_frames(combined_frames, combined_output_file, fps=fps)\n",
    "        res_paths[\"video\"].append(output_file)\n",
    "        res_paths[\"mask\"].append(mask_output_file)\n",
    "        res_paths[\"combined\"].append(combined_output_file)\n",
    "    return res_paths\n",
    "\n",
    "\n",
    "ver = 5\n",
    "data_dir = Path(f'notebook_results/mmaction_train_data_v{ver}')\n",
    "class_labels = ['mitosis', 'apoptosis', 'normal']\n",
    "class_label = \"mitosis\"\n",
    "frame_types = [\"video\", \"mask\", \"combined\"]\n",
    "selected_frame_type = \"video\" \n",
    "\n",
    "padding_pixels = [0, 20, 40, 50, 100, 200, 400]\n",
    "mmaction_df = pd.DataFrame(columns=[\"path\", \"label_index\", \"padding_pixels\", \"frame_type\"])\n",
    "for class_label in class_labels:\n",
    "    output_dir = Path(data_dir) / \"videos\"\n",
    "    output_dir.mkdir(exist_ok=True, parents=True)\n",
    "    video_frames_samples = class_samples[class_label]\n",
    "    for padding_pixel in padding_pixels:\n",
    "        res_paths = gen_samples_mp4s(video_frames_samples, class_label, output_dir, padding_pixels=padding_pixel)\n",
    "        for selected_frame_type in frame_types:\n",
    "            # mmaction_df = mmaction_df.append(pd.DataFrame([(str(path.name), class_labels.index(class_label), padding_pixel, selected_frame_type) for path in res_paths[selected_frame_type]], columns=[\"path\", \"label_index\", \"padding_pixels\", \"frame_type\"]), ignore_index=True)\n",
    "            mmaction_df = pd.concat([mmaction_df, pd.DataFrame([(str(path.name), class_labels.index(class_label), padding_pixel, selected_frame_type) for path in res_paths[selected_frame_type]], columns=[\"path\", \"label_index\", \"padding_pixels\", \"frame_type\"])])\n",
    "data_df_path = data_dir/'all_data.txt'\n",
    "mmaction_df.to_csv(data_df_path, index=False, header=False, sep=' ')\n",
    "\n",
    "\n",
    "for selected_frame_type in frame_types:\n",
    "    selected_frame_type_df = mmaction_df[mmaction_df[\"frame_type\"] == selected_frame_type]\n",
    "    selected_frame_type_df = selected_frame_type_df.reset_index(drop=True)\n",
    "    train_df_path = data_dir/f'train_data_{selected_frame_type}.txt'\n",
    "    test_df_path = data_dir/f'test_data_{selected_frame_type}.txt'\n",
    "    \n",
    "    train_df = selected_frame_type_df.sample(frac=0.8, random_state=0, replace=False)\n",
    "    test_df = selected_frame_type_df.drop(train_df.index, inplace=False)\n",
    "\n",
    "    # only keep the path and label_index columns\n",
    "    train_df = train_df[[\"path\", \"label_index\"]]\n",
    "    test_df = test_df[[\"path\", \"label_index\"]]\n",
    "\n",
    "    train_df.to_csv(train_df_path, index=False, header=False, sep=' ')\n",
    "    test_df.to_csv(test_df_path, index=False, header=False, sep=' ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# train_df_path = data_dir/'train_data.csv'\n",
    "# test_df_path = data_dir/'test_data.csv'\n",
    "\n",
    "# # split train and test from df\n",
    "# train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "# train_df.to_csv(train_df_path, index=False, header=False, sep=' ')\n",
    "# test_df.to_csv(test_df_path, index=False, header=False, sep=' ')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "livecell",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
