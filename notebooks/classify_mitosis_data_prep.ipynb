{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare mitosis time series data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from cellpose import models\n",
    "from cellpose.io import imread\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from PIL import Image, ImageSequence\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import os.path\n",
    "# from livecell_tracker import segment\n",
    "from livecell_tracker import core\n",
    "from livecell_tracker.core import datasets\n",
    "from livecell_tracker.core.datasets import LiveCellImageDataset, SingleImageDataset\n",
    "from skimage import measure\n",
    "from livecell_tracker.core import SingleCellTrajectory, SingleCellStatic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_json_dir = Path(\"./EBSS_starvation_24h_xy16_annotation\")\n",
    "\n",
    "sample_json_dirs = [Path(r\"./datasets/test_scs_EBSS_starvation/XY1/annotations\"), Path(r\"./datasets/test_scs_EBSS_starvation/XY16/annotations\")]\n",
    "\n",
    "def load_class2samples_from_json_dir(sample_json_dir: Path, class_subfolders = [\"mitosis\", \"apoptosis\", \"normal\"]) -> dict:\n",
    "    # sample_paths = glob.glob(str(sample_json_dir / \"*.json\"))\n",
    "    class2samples = {}\n",
    "    for subfolder in class_subfolders:\n",
    "        class2samples[subfolder] = []\n",
    "        sample_paths = glob.glob(str(sample_json_dir / subfolder / \"*.json\"))\n",
    "        for sample_path in sample_paths:\n",
    "            sample = SingleCellStatic.load_single_cells_json(sample_path)\n",
    "            class2samples[subfolder].append(sample)\n",
    "    return class2samples\n",
    "\n",
    "\n",
    "all_class2samples = None\n",
    "all_class2sample_extra_info = {}\n",
    "for sample_json_dir in sample_json_dirs:\n",
    "    _class2samples = load_class2samples_from_json_dir(sample_json_dir)\n",
    "    print(_class2samples)\n",
    "    for class_name in _class2samples:\n",
    "        # report how many samples loaded from the sample json dir\n",
    "        print(f\"Loaded {len(_class2samples[class_name])} annotated samples from {sample_json_dir / class_name}\")\n",
    "\n",
    "    if all_class2samples is None:\n",
    "        all_class2samples = _class2samples\n",
    "    for class_name in _class2samples:\n",
    "\n",
    "        all_class2samples[class_name] += _class2samples[class_name]\n",
    "        _extra_info =  [{\"src_dir\": sample_json_dir} for _ in range(len(_class2samples[class_name]))]\n",
    "        if class_name not in all_class2sample_extra_info:\n",
    "            all_class2sample_extra_info[class_name] = _extra_info\n",
    "        else:\n",
    "            all_class2sample_extra_info[class_name] += _extra_info\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_class2sample_extra_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_class2samples[\"mitosis\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Automatically prepare normal samples\n",
    "\n",
    "require tracking done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all scs from class_samples not in normal class\n",
    "exclude_scs = []\n",
    "total_non_normal_samples = 0\n",
    "for class_name, samples in all_class2samples.items():\n",
    "    if class_name != \"normal\":\n",
    "        for sample in samples:\n",
    "            exclude_scs.extend(sample)\n",
    "            total_non_normal_samples += 1\n",
    "\n",
    "exclude_scs = set(exclude_scs)\n",
    "exclude_scs_ids = {str(sc.id) for sc in exclude_scs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from livecell_tracker.core.sct_operator import create_scs_edit_viewer\n",
    "# sct_operator = create_scs_edit_viewer(exclude_scs, img_dataset = list(exclude_scs)[0].img_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load all scs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scs_json_path = [\"./datasets/test_scs_EBSS_starvation/XY1/single_cells.json\", \"./datasets/test_scs_EBSS_starvation/XY16/single_cells.json\"]\n",
    "# all_scs_json_path = \"./datasets/test_scs_EBSS_starvation/XY16/tmp_corrected_scs.json\"\n",
    "all_scs = SingleCellStatic.load_single_cells_jsons(all_scs_json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from livecell_tracker.core.single_cell import SingleCellTrajectoryCollection\n",
    "from livecell_tracker.track.sort_tracker_utils import (\n",
    "    track_SORT_bbox_from_scs\n",
    ")\n",
    "# with open(\"./EBSS_starvation_24h_xy16_annotation/single_cell_trajectory_collection.json\", \"r\") as file:\n",
    "#     json_dict = json.load(file)\n",
    "# sctc = SingleCellTrajectoryCollection().load_from_json_dict(json_dict)\n",
    "sctc = track_SORT_bbox_from_scs(all_scs, raw_imgs=all_scs[0].img_dataset, min_hits=3, max_age=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set numpy seed\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "\n",
    "objective_sample_num = total_non_normal_samples * 10\n",
    "\n",
    "normal_frame_len_range = (3, 10)\n",
    "counter = 0\n",
    "normal_samples = []\n",
    "normal_samples_extra_info = []\n",
    "max_trial_counter = 100000\n",
    "while counter < objective_sample_num and max_trial_counter > 0:\n",
    "    # randomly select a sct from sctc\n",
    "    # generate a list of scs\n",
    "    track_id = np.random.choice(list(sctc.track_id_to_trajectory.keys()))  \n",
    "    sct = sctc.get_trajectory(track_id)\n",
    "    # randomly select a length\n",
    "    frame_len = np.random.randint(*normal_frame_len_range)\n",
    "    # generate a sample\n",
    "    times = list(sct.timeframe_to_single_cell.keys())\n",
    "    times = sorted(times)\n",
    "    if len(times) <= frame_len:\n",
    "        continue\n",
    "    start_idx = np.random.randint(0, len(times) - frame_len)\n",
    "    start_time = times[start_idx]\n",
    "    end_time = times[start_idx + frame_len - 1]\n",
    "\n",
    "    sub_sct = sct.subsct(start_time, end_time)\n",
    "\n",
    "    is_some_sc_in_exclude_scs = False\n",
    "    for time, sc in sub_sct.timeframe_to_single_cell.items():\n",
    "        # print(\"sc.id:\", sc.id, type(sc.id))\n",
    "        if str(sc.id) in exclude_scs_ids:\n",
    "            is_some_sc_in_exclude_scs = True\n",
    "            break\n",
    "    if is_some_sc_in_exclude_scs:\n",
    "        print(\"some sc in exclude scs\")\n",
    "        continue\n",
    "    \n",
    "    new_sample = []\n",
    "    for time, sc in sub_sct.timeframe_to_single_cell.items():\n",
    "        new_sample.append(sc)\n",
    "    normal_samples.append(new_sample)\n",
    "    normal_samples_extra_info.append({\"src_dir\": sub_sct.get_all_scs()[0].meta[\"src_json\"]})\n",
    "    counter += 1\n",
    "    max_trial_counter -= 1\n",
    "\n",
    "normal_samples[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_class2samples[\"normal\"].extend(normal_samples)\n",
    "all_class2sample_extra_info[\"normal\"].extend(normal_samples_extra_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_class2samples[\"normal\"]), len(all_class2sample_extra_info[\"normal\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare videos and annotations for MMDetection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = all_class2samples.keys()\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from livecell_tracker.core.utils import gray_img_to_rgb, rgb_img_to_gray\n",
    "from livecell_tracker.preprocess.utils import normalize_img_to_uint8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from livecell_tracker.track.classify_utils import video_frames_and_masks_from_sample, combine_video_frames_and_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def gen_mp4_from_frames(video_frames, output_file, fps):\n",
    "    # Define the output video file name and properties\n",
    "    frame_size = video_frames[0].shape[:2][::-1]  # reverse the order of width and height\n",
    "    # Create a VideoWriter object\n",
    "    # fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'H265')\n",
    "    out = cv2.VideoWriter(str(output_file), fourcc, fps, frame_size, isColor=True)\n",
    "    # Write each frame to the output video\n",
    "    for frame in video_frames:\n",
    "        out.write(frame)\n",
    "    out.release()\n",
    "\n",
    "def gen_samples_mp4s(sc_samples: List[List[SingleCellStatic]], samples_info_list, class_label, output_dir, fps = 3, padding_pixels=50, prefix=\"\"):\n",
    "    \"\"\"\n",
    "    Generate mp4 videos and masks from a list of SingleCellStatic samples.\n",
    "    Args:\n",
    "        sc_samples: A list of SingleCellStatic samples.\n",
    "        sample_info_list: A list of dictionaries containing the information of the samples.\n",
    "        class_label: A string representing the class label of the samples.\n",
    "        output_dir: A Path object representing the directory to save the generated videos and masks.\n",
    "        fps: An integer representing the frames per second of the generated videos.\n",
    "        padding_pixels: An integer representing the number of pixels to pad around the cells in the generated videos and masks.\n",
    "    Returns:\n",
    "        A dictionary containing the file paths of the generated videos, masks, and combined videos.\n",
    "    \"\"\"\n",
    "    res_paths = {\n",
    "        \"video\": [],\n",
    "        \"mask\": [],\n",
    "        \"combined\": []\n",
    "    }\n",
    "    res_extra_info = []\n",
    "    for i, sample in enumerate(sc_samples):\n",
    "        output_file = output_dir / (f'{prefix}_{class_label}_{i}_raw_padding-{padding_pixels}.mp4')\n",
    "        mask_output_file = output_dir / (f'{prefix}_{class_label}_{i}_mask_padding-{padding_pixels}.mp4')\n",
    "        combined_output_file = output_dir / (f'{prefix}_{class_label}_{i}_combined_padding-{padding_pixels}.mp4')\n",
    "        \n",
    "        # record video file path and class label\n",
    "        video_frames, video_frame_masks = video_frames_and_masks_from_sample(sample, padding_pixels=padding_pixels)\n",
    "        combined_frames = combine_video_frames_and_masks(video_frames, video_frame_masks)\n",
    "        assert combined_frames[0].shape[-1] == 3, \"The number of channels of the combined frames should be 3.\"\n",
    "\n",
    "        # # for debug\n",
    "        # print(\"len video_frames: \", len(video_frames))\n",
    "        # print(\"len masks video: \", len(video_frame_masks))\n",
    "        # print(\"len combined_frames: \", len(combined_frames))\n",
    "\n",
    "        gen_mp4_from_frames(video_frames, output_file, fps=fps)\n",
    "        gen_mp4_from_frames(video_frame_masks, mask_output_file, fps=fps)\n",
    "        gen_mp4_from_frames(combined_frames, combined_output_file, fps=fps)\n",
    "        res_paths[\"video\"].append(output_file)\n",
    "        res_paths[\"mask\"].append(mask_output_file)\n",
    "        res_paths[\"combined\"].append(combined_output_file)\n",
    "        \n",
    "        extra_sample_info = samples_info_list[i]\n",
    "        res_extra_info.append(extra_sample_info)\n",
    "    return res_paths, res_extra_info\n",
    "\n",
    "\n",
    "ver = 8\n",
    "# ver = \"-test\"\n",
    "data_dir = Path(f'notebook_results/mmaction_train_data_v{ver}')\n",
    "class_labels = ['mitosis', 'apoptosis', 'normal']\n",
    "class_label = \"mitosis\"\n",
    "frame_types = [\"video\", \"mask\", \"combined\"]\n",
    "fps = 3\n",
    "\n",
    "padding_pixels = [0, 20, 40, 50, 100, 200, 400]\n",
    "\n",
    "def gen_samples_df(class2samples, class2sample_extra_info, data_dir, class_labels, padding_pixels, frame_types, fps, prefix=\"\"):\n",
    "    df_cols = [\"path\", \"label_index\", \"padding_pixels\", \"frame_type\", \"src_dir\"]\n",
    "    sample_info_df = pd.DataFrame(columns=df_cols)\n",
    "    for class_label in class_labels:\n",
    "        output_dir = Path(data_dir) / \"videos\"\n",
    "        output_dir.mkdir(exist_ok=True, parents=True)\n",
    "        video_frames_samples = class2samples[class_label]\n",
    "        video_frames_samples_info = class2sample_extra_info[class_label]\n",
    "        for padding_pixel in padding_pixels:\n",
    "            res_paths, res_extra_info = gen_samples_mp4s(video_frames_samples, video_frames_samples_info, class_label, output_dir, padding_pixels=padding_pixel, fps=fps, prefix=prefix)\n",
    "            for selected_frame_type in frame_types:\n",
    "                # mmaction_df = mmaction_df.append(pd.DataFrame([(str(path.name), class_labels.index(class_label), padding_pixel, selected_frame_type) for path in res_paths[selected_frame_type]], columns=[\"path\", \"label_index\", \"padding_pixels\", \"frame_type\"]), ignore_index=True)\n",
    "                sample_info_df = pd.concat([sample_info_df, pd.DataFrame([(str(path.name), \n",
    "                                                                    class_labels.index(class_label), \n",
    "                                                                    padding_pixel, selected_frame_type, res_extra_info[i][\"src_dir\"])\n",
    "                                                                    for i, path in enumerate(res_paths[selected_frame_type])], columns=df_cols)])\n",
    "    return sample_info_df\n",
    "\n",
    "\n",
    "# split train and test data\n",
    "\n",
    "# get #samples from all_class2samples\n",
    "_split = 0.8\n",
    "\n",
    "train_class2samples = {}\n",
    "test_class2samples = {}\n",
    "train_class2sample_extra_info = {}\n",
    "test_class2sample_extra_info = {}\n",
    "for key in all_class2samples.keys():\n",
    "    split_idx = int(len(all_class2samples[key]) * _split)\n",
    "\n",
    "    train_class2samples[key] = all_class2samples[key][:split_idx]\n",
    "    test_class2samples[key] = all_class2samples[key][split_idx:]\n",
    "\n",
    "    train_class2sample_extra_info[key] = all_class2sample_extra_info[key][:split_idx]\n",
    "    test_class2sample_extra_info[key] = all_class2sample_extra_info[key][split_idx:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_class2samples[\"normal\"]), len(test_class2samples[\"normal\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_class2samples[\"mitosis\"]), len(test_class2samples[\"mitosis\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_frames_and_masks_from_sample(train_class2samples[\"normal\"][6])[0][0].shape\n",
    "# train_class2samples[\"normal\"][6][1].show_panel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_check = 6\n",
    "video_frames, video_frame_masks = video_frames_and_masks_from_sample(train_class2samples[\"normal\"][idx_to_check], padding_pixels=0)\n",
    "print(\"video frames dtype:\", video_frames[0].dtype)\n",
    "print(\"video frames shape:\", video_frames[0].shape)\n",
    "print(\"video frame masks dtype:\", video_frame_masks[0].dtype)\n",
    "print(\"video frame masks shape:\", video_frame_masks[0].shape)\n",
    "combined_frames = combine_video_frames_and_masks(video_frames, video_frame_masks)\n",
    "combined_frames = np.array(combined_frames).astype(np.uint8)\n",
    "# combined_frames = np.maximum(combined_frames - 1, 0).astype(np.uint8)\n",
    "print(\"combined_frames shape: \", combined_frames[0].shape)\n",
    "gen_mp4_from_frames(combined_frames, \"./test_video_output.mp4\", fps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(combined_frames).flatten().min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # for debug\n",
    "# train_class2samples = {key: value[:5] for key, value in all_class2samples.items()}\n",
    "# test_class2samples = {key: value[:5] for key, value in all_class2samples.items()}\n",
    "# padding_pixels = [20]\n",
    "\n",
    "\n",
    "train_sample_info_df = gen_samples_df(train_class2samples, train_class2sample_extra_info, data_dir, class_labels, padding_pixels, frame_types, fps, prefix=\"train\")\n",
    "test_sample_info_df = gen_samples_df(test_class2samples, test_class2sample_extra_info, data_dir, class_labels, padding_pixels, frame_types, fps, prefix=\"test\")\n",
    "\n",
    "train_sample_info_df.to_csv(data_dir/f'train_data.txt', index=False, header=False, sep=' ', )\n",
    "test_sample_info_df.to_csv(data_dir/f'test_data.txt', index=False, header=False, sep=' ', )\n",
    "\n",
    "for selected_frame_type in frame_types:\n",
    "    train_df_path = data_dir/f'mmaction_train_data_{selected_frame_type}.txt'\n",
    "    train_selected_frame_type_df = train_sample_info_df[train_sample_info_df[\"frame_type\"] == selected_frame_type]\n",
    "    train_selected_frame_type_df = train_selected_frame_type_df.reset_index(drop=True)\n",
    "    train_selected_frame_type_df = train_selected_frame_type_df[[\"path\", \"label_index\"]]\n",
    "    train_selected_frame_type_df.to_csv(train_df_path, index=False, header=False, sep=' ')\n",
    "    \n",
    "    test_df_path = data_dir/f'mmaction_test_data_{selected_frame_type}.txt'\n",
    "    test_selected_frame_type_df = test_sample_info_df[test_sample_info_df[\"frame_type\"] == selected_frame_type]\n",
    "    test_selected_frame_type_df = test_selected_frame_type_df[[\"path\", \"label_index\"]]\n",
    "    test_selected_frame_type_df = test_selected_frame_type_df.reset_index(drop=True)\n",
    "    test_selected_frame_type_df.to_csv(test_df_path, index=False, header=False, sep=' ')\n",
    "\n",
    "\n",
    "# # the follwing code generates v1-v7 test data. The issue is that some of test data shows up in train data, through different padding values.\n",
    "# data_df_path = data_dir/'all_data.txt'\n",
    "# sample_df = gen_samples_df(data_dir, class_labels, padding_pixels, frame_types, fps)\n",
    "# sample_df.to_csv(data_df_path, index=False, header=False, sep=' ')\n",
    "# for selected_frame_type in frame_types:\n",
    "#     selected_frame_type_df = sample_df[sample_df[\"frame_type\"] == selected_frame_type]\n",
    "#     selected_frame_type_df = selected_frame_type_df.reset_index(drop=True)\n",
    "#     train_df_path = data_dir/f'train_data_{selected_frame_type}.txt'\n",
    "#     test_df_path = data_dir/f'test_data_{selected_frame_type}.txt'\n",
    "#     train_df = selected_frame_type_df.sample(frac=0.8, random_state=0, replace=False)\n",
    "#     test_df = selected_frame_type_df.drop(train_df.index, inplace=False)\n",
    "\n",
    "#     # only keep the path and label_index columns\n",
    "#     train_df = train_df[[\"path\", \"label_index\"]]\n",
    "#     test_df = test_df[[\"path\", \"label_index\"]]\n",
    "\n",
    "#     train_df.to_csv(train_df_path, index=False, header=False, sep=' ')\n",
    "#     test_df.to_csv(test_df_path, index=False, header=False, sep=' ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_class2samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "video_paths = list(Path(data_dir/'videos').glob('*.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to a `decord` package [issue](https://github.com/dmlc/decord/issues/150), to use mmaction2 we must check if the videos can be loaded by `decord` correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import decord\n",
    "for path in video_paths:\n",
    "# for path in [\"./notebook_results/train_normal_6_raw_padding-0.mp4\"]:\n",
    "# for path in [\"./test_video_output.mp4\"]:\n",
    "    reader = decord.VideoReader(str(path))\n",
    "    reader.seek(0)\n",
    "    imgs = list()\n",
    "    frame_inds = range(0, len(reader))\n",
    "    for idx in frame_inds:\n",
    "        reader.seek(idx)\n",
    "        frame = reader.next()\n",
    "        imgs.append(frame.asnumpy())\n",
    "        frame = frame.asnumpy()\n",
    "\n",
    "        num_channels = frame.shape[-1]\n",
    "        if num_channels != 3:\n",
    "            print(\"invalid video for decord (https://github.com/dmlc/decord/issues/150): \", path)\n",
    "            break\n",
    "        # fig, axes = plt.subplots(1, num_channels, figsize=(20, 10))\n",
    "        # for i in range(num_channels):\n",
    "        #     axes[i].imshow(frame[:, :, i])\n",
    "        # plt.show()\n",
    "    del reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decord.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check if videos can be loaded by cv2 correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(\"./test_video_output.mp4\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    assert frame.shape[-1] == 3, \"frame should be in RGB format\"\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# train_df_path = data_dir/'train_data.csv'\n",
    "# test_df_path = data_dir/'test_data.csv'\n",
    "\n",
    "# # split train and test from df\n",
    "# train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "# train_df.to_csv(train_df_path, index=False, header=False, sep=' ')\n",
    "# test_df.to_csv(test_df_path, index=False, header=False, sep=' ')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "livecell",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
