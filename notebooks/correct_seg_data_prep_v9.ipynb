{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "from livecellx.core import (\n",
    "    SingleCellTrajectory,\n",
    "    SingleCellStatic,\n",
    "    SingleCellTrajectoryCollection,\n",
    ")\n",
    "\n",
    "from livecellx.core.datasets import LiveCellImageDataset\n",
    "from livecellx.preprocess.utils import (\n",
    "    overlay,\n",
    "    enhance_contrast,\n",
    "    normalize_img_to_uint8,\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Labelme Json to COCO Json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run the following code once for generating coco json\n",
    "```\n",
    "import livecellx.segment\n",
    "import livecellx.annotation\n",
    "import livecellx.annotation.labelme2coco\n",
    "import os\n",
    "labelme_json_folder = r\"\"\"../datasets/a549_ccnn/annotation_data\"\"\"\n",
    "dataset_folder_path = r\"\"\"../datasets/a549_ccnn/original_data\"\"\"\n",
    "export_dir = \"./notebook_results/correction_cnn_v0.0.0/\"\n",
    "os.makedirs(export_dir, exist_ok=True)\n",
    "livecellx.annotation.labelme2coco.convert(\n",
    "    labelme_json_folder,\n",
    "    export_dir,\n",
    "    train_split_rate=0.9,\n",
    "    dataset_folder_path=dataset_folder_path,\n",
    "    # is_image_in_json_folder=True,\n",
    "    image_file_ext=\"tif\",\n",
    "    # image_file_ext=\"png\",\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load COCO into SingleCell Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycocotools.coco import COCO\n",
    "\n",
    "# coco_data = COCO(\"../datasets/a549_ccnn/a549_ccnn_coco_v0.0.0/train.json\")\n",
    "# out_dir = Path(\"./notebook_results/a549_ccp_vim/train_data_v9/\")\n",
    "\n",
    "coco_data = COCO(\"../datasets/a549_ccnn/a549_ccnn_coco_v0.0.0/val.json\")\n",
    "# out_dir = Path(\"./notebook_results/a549_ccp_vim/test_data_v9/\")\n",
    "out_dir = Path(\"./notebook_results/a549_ccp_vim/tmp_test/\")\n",
    "\n",
    "coco_data.anns.keys(), coco_data.anns[1].keys(), coco_data.anns[1][\"segmentation\"][0][\n",
    "    :5\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_data.imgs.keys(), coco_data.imgs[1].keys(), coco_data.imgs[1][\"file_name\"],\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from livecellx.annotation.coco_utils import coco_to_sc\n",
    "\n",
    "single_cells = coco_to_sc(coco_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment the block below for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for testing\n",
    "# single_cells = single_cells[:20]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(10, 5))\n",
    "cell_id = 10\n",
    "axes[0].imshow(single_cells[cell_id].get_img_crop(padding=100))\n",
    "axes[1].imshow(single_cells[cell_id].get_contour_mask_closed_form(padding=100))\n",
    "axes[2].imshow(single_cells[cell_id].get_contour_mask(padding=100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(single_cells)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save a list of single cell objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SingleCellStatic.write_single_cells_json(\n",
    "    single_cells, \"../datasets/a549_ccnn/single_cells.json\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contour_mask = single_cells[cell_id].get_contour_mask(padding=100)\n",
    "contour_mask.astype(np.uint8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "from livecellx.preprocess.utils import dilate_or_erode_mask\n",
    "\n",
    "plt.imshow(dilate_or_erode_mask(contour_mask.astype(np.uint8), 1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute similarity between manually segmented cell and segmentation results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will take sample_sc as an example to show how to compute IOU based similarity between manually segmented cell and segmentation results from machine learning models.  \n",
    "Instead, this part may be done by a human annotator by clicking the corresponding cell in the segmentation results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sc = single_cells[cell_id]\n",
    "sample_sc.meta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "raw_img_dataset = sample_sc.img_dataset\n",
    "seg_data_dir = \"../datasets/a549_ccnn/seg_tiles_CCP_A549-VIM_lessThan24hr_Calcein_1mg-ml_DP_Ti2e_2022-9-11\"\n",
    "seg_paths = glob.glob(os.path.join(seg_data_dir, \"*.png\"))\n",
    "print(\"sample seg paths:\", seg_paths[:2])\n",
    "matched_time2seg = {}\n",
    "# for time, img_path in raw_img_dataset.time2url.items():\n",
    "#     substr = os.path.basename(img_path).split(\".\")[0]\n",
    "#     print(\"substr:\", substr)\n",
    "#     for seg_path\n",
    "#     break\n",
    "corrected_indices = []\n",
    "for seg_path in seg_paths:\n",
    "    substr = os.path.basename(seg_path).split(\".\")[0] # get rid of extension\n",
    "    substr = substr[4:]  # get rid of seg_ prefix\n",
    "    img, path, index = raw_img_dataset.get_img_by_url(\n",
    "        substr, return_path_and_time=True, ignore_missing=True\n",
    "    )\n",
    "    if path is None:\n",
    "        print(\"skip due to substr not found:\", substr)\n",
    "        continue\n",
    "    matched_time2seg[index] = seg_path\n",
    "\n",
    "seg_data = LiveCellImageDataset(time2url=matched_time2seg, ext=\"png\")\n",
    "sample_sc.mask_dataset = seg_data\n",
    "assert len(seg_data) == len(raw_img_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 4, figsize=(10, 5))\n",
    "axes[0].imshow(sample_sc.get_img_crop(padding=10))\n",
    "axes[1].imshow(sample_sc.get_contour_mask(padding=10))\n",
    "axes[2].imshow(sample_sc.get_contour_mask_closed_form(padding=10))\n",
    "axes[3].imshow(sample_sc.get_mask_crop())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show a sample whole image with code below\n",
    "\n",
    "```\n",
    "fig, ax = plt.subplots(1, 1, figsize=(20, 20))\n",
    "ax.imshow(sample_sc.get_img())\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_mask = seg_data.get_img_by_url(\n",
    "    os.path.basename(sample_sc.meta[\"path\"]).split(\".\")[0], exact_match=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(seg_mask.flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axes[0].imshow(seg_mask)\n",
    "axes[1].imshow(sample_sc.get_contour_img(crop=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_seg_mask = SingleCellStatic.gen_skimage_bbox_img_crop(sample_sc.bbox, seg_mask)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 10))\n",
    "axes[0].imshow(\n",
    "    overlay(sample_sc.get_img_crop(), cropped_seg_mask, img_channel_rgb_val_factor=1)\n",
    ")\n",
    "axes[0].set_title(\"over-segmentation from ML model\")\n",
    "axes[1].imshow(\n",
    "    overlay(\n",
    "        sample_sc.get_img_crop(),\n",
    "        sample_sc.get_contour_img(),\n",
    "        img_channel_rgb_val_factor=1,\n",
    "    )\n",
    ")\n",
    "axes[1].set_title(\"ground truth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from livecellx.segment.utils import match_mask_labels_by_iou\n",
    "\n",
    "match_mask_labels_by_iou(cropped_seg_mask, sample_sc.get_contour_mask())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(sample_sc.get_contour_mask(crop=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(10, 10))\n",
    "axes[0].imshow(\n",
    "    overlay(\n",
    "        enhance_contrast(normalize_img_to_uint8(sample_sc.get_img()), factor=0.5),\n",
    "        sample_sc.get_contour_mask(crop=False),\n",
    "        img_channel_rgb_val_factor=2,\n",
    "    )\n",
    ")\n",
    "axes[0].set_title(\"some gt cell annotation overlay\")\n",
    "axes[1].imshow(\n",
    "    overlay(\n",
    "        enhance_contrast(normalize_img_to_uint8(sample_sc.get_img()), factor=0.9),\n",
    "        seg_mask,\n",
    "        img_channel_rgb_val_factor=2,\n",
    "    )\n",
    ")\n",
    "axes[1].set_title(\"T07 XY4 TILE7 seg overlay\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sc.get_contour_mask()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_seg_mask_label(mask: np.array, sc: SingleCellStatic):\n",
    "    \"\"\"match a single cell's label in a mask. sc must contain its contour information.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    mask : np.array\n",
    "        _description_\n",
    "    sc : \n",
    "        _description_\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    a dict with keys \"seg_label\" and \"iou\"\n",
    "    \"\"\"    \n",
    "    cropped_seg_mask = SingleCellStatic.gen_skimage_bbox_img_crop(sc.bbox, seg_mask)\n",
    "    match_res = match_mask_labels_by_iou(cropped_seg_mask, sc.get_contour_mask())\n",
    "    assert len(match_res) == 1, \"Either sc's get contour mask returns a mask with more than 1 gt, or there is some bug in match_mask_labels_by_iou\"\n",
    "    match_res = list(match_res.values())[0]\n",
    "    return match_res\n",
    "\n",
    "# example usage\n",
    "seg_label = match_seg_mask_label(seg_mask, sample_sc)[\"seg_label\"]\n",
    "seg_label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute similarity for all cells and get the mapping between single cells and its corresponding label in the segmentation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sc in tqdm(single_cells):\n",
    "    sc_img_path_substr = os.path.basename(sc.meta[\"path\"]).split(\".\")[0]\n",
    "    seg_mask = seg_data.get_img_by_url(sc_img_path_substr, exact_match=False)\n",
    "    sc.meta[\"seg_label\"] = match_seg_mask_label(seg_mask, sc)[\"seg_label\"]\n",
    "    sc.mask_dataset = seg_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "sample_sc.show_mask()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate dilated and eroded masks for each cell\n",
    "Create an augmented dataset.\n",
    "Save results via single cell data structure\n",
    "```\n",
    "Single Cell Json metadata\n",
    "{\n",
    "    seg_label: 13,\n",
    "    img_id: 1,\n",
    "}\n",
    "```\n",
    "\n",
    "We pad the each cell mask with a defined background value (0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(seg_data), len(sample_sc.img_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sc = single_cells[-1]\n",
    "sample_sc.meta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Undersegmentation case: create mapping from seg label id to gt id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_cells[-1].meta, single_cells[-2].meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sc.meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg2scs = {}\n",
    "for sc in single_cells:\n",
    "    seg_label = sc.meta[\"seg_label\"]\n",
    "    img_id = sc.meta[\"img_id\"]\n",
    "    key = (img_id, seg_label)\n",
    "    if key not in seg2scs:\n",
    "        seg2scs[key] = []\n",
    "    seg2scs[key].append(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count how many simple undersegmentation there are in our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "underseg_cases = {key: val for key, val in seg2scs.items() if len(val) > 1}\n",
    "len(underseg_cases)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize one such undersegmentation case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose any case\n",
    "underseg_case = list(underseg_cases.items())[2]\n",
    "underseg_case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 4, figsize=(10, 5))\n",
    "underseg_scs = underseg_case[1]\n",
    "padding = 30\n",
    "axes[0].imshow(underseg_scs[0].get_mask_crop(padding=padding))\n",
    "axes[1].imshow(underseg_scs[0].get_contour_img(padding=padding))\n",
    "axes[2].imshow(underseg_scs[1].get_mask_crop(padding=padding))\n",
    "axes[3].imshow(underseg_scs[1].get_contour_img(padding=padding))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augment undersegmentation case  \n",
    "sc.mask_dataset, sc.get_mask(): from seg_mask  \n",
    "sc.bbox, sc.contour, sc.get_contour(): from gt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "from skimage.measure import regionprops\n",
    "import pandas as pd\n",
    "from livecellx.core.io_utils import save_tiff\n",
    "from typing import Tuple\n",
    "from skimage.measure import regionprops\n",
    "import pandas as pd\n",
    "from livecellx.core.io_utils import save_tiff\n",
    "from livecellx.segment.ou_utils import csn_augment_helper, underseg_overlay_gt_masks, gen_aug_diff_mask\n",
    "\n",
    "\n",
    "\n",
    "underseg_seg2scs = underseg_cases\n",
    "\n",
    "underseg_out_dir = out_dir / \"real_underseg_cases\"\n",
    "raw_out_dir = underseg_out_dir / \"raw\"\n",
    "seg_out_dir = underseg_out_dir / \"seg\"\n",
    "gt_out_dir = underseg_out_dir / \"gt\"\n",
    "gt_label_out_dir = underseg_out_dir / \"gt_label_mask\"\n",
    "augmented_seg_dir = underseg_out_dir / \"augmented_seg\"\n",
    "raw_transformed_img_dir = underseg_out_dir / \"raw_transformed_img\"\n",
    "augmented_diff_seg_dir = underseg_out_dir / \"augmented_diff_seg\"\n",
    "\n",
    "os.makedirs(raw_out_dir, exist_ok=True)\n",
    "os.makedirs(seg_out_dir, exist_ok=True)\n",
    "os.makedirs(gt_out_dir, exist_ok=True)\n",
    "os.makedirs(augmented_seg_dir, exist_ok=True)\n",
    "os.makedirs(gt_label_out_dir, exist_ok=True)\n",
    "os.makedirs(raw_transformed_img_dir, exist_ok=True)\n",
    "os.makedirs(augmented_diff_seg_dir, exist_ok=True)\n",
    "\n",
    "scale_factors = np.linspace(0, 0.3, 10)\n",
    "\n",
    "train_path_tuples = []\n",
    "augmented_data = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for img_id, seg_label in tqdm(underseg_seg2scs):\n",
    "    scs = underseg_seg2scs[(img_id, seg_label)]\n",
    "    assert len(scs) > 0, \"the list of single cells should not be empty\"\n",
    "    (img_crop, seg_crop, combined_gt_label_mask) = underseg_overlay_gt_masks(seg_label, scs, padding_scale=2)\n",
    "    raw_img_path = raw_out_dir / (\"img-%d_seg-%d.tif\" % (img_id, seg_label))\n",
    "    seg_img_path = seg_out_dir / (\"img-%d_seg-%d.tif\" % (img_id, seg_label))\n",
    "    gt_img_path = gt_out_dir / (\"img-%d_seg-%d.tif\" % (img_id, seg_label))\n",
    "    gt_label_img_path = gt_label_out_dir / (\"img-%d_seg-%d.tif\" % (img_id, seg_label))\n",
    "\n",
    "    # call csn augment helper\n",
    "    csn_augment_helper(img_crop=img_crop, \n",
    "        seg_label_crop=seg_crop, \n",
    "        combined_gt_label_mask=combined_gt_label_mask,\n",
    "        scale_factors=scale_factors,\n",
    "        train_path_tuples=train_path_tuples,\n",
    "        augmented_data=augmented_data,\n",
    "        img_id=img_id,\n",
    "        seg_label=seg_label,\n",
    "        gt_label=None,\n",
    "        raw_img_path=raw_img_path,\n",
    "        seg_img_path=seg_img_path,\n",
    "        gt_img_path=gt_img_path,\n",
    "        gt_label_img_path=gt_label_img_path,\n",
    "        augmented_seg_dir=augmented_seg_dir,\n",
    "        augmented_diff_seg_dir=augmented_diff_seg_dir,\n",
    "        raw_transformed_img_dir=raw_transformed_img_dir,\n",
    "        df_save_path=out_dir/\"data.csv\",\n",
    "    )\n",
    "\n",
    "\n",
    "pd.DataFrame(\n",
    "    train_path_tuples,\n",
    "    columns=[\"raw\", \"seg\", \"gt\", \"raw_seg\", \"scale\", \"aug_diff_mask\", \"gt_label_mask\", \"raw_transformed_img\"],\n",
    ").to_csv(underseg_out_dir / \"data.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize augmented data on one row\n",
    "for aug_data in augmented_data:\n",
    "    img_id = aug_data[\"img_id\"]\n",
    "    seg_label = aug_data[\"seg_label\"]\n",
    "    img_crop = aug_data[\"img_crop\"]\n",
    "    seg_crop = aug_data[\"seg_crop\"]\n",
    "    combined_gt_label_mask = aug_data[\"combined_gt_label_mask\"]\n",
    "    aug_seg_crop = aug_data[\"aug_seg_crop\"]\n",
    "    aug_diff_mask = aug_data[\"aug_diff_mask\"]\n",
    "    combined_gt_label_mask = aug_data[\"combined_gt_label_mask\"]\n",
    "    raw_transformed_img_crop = aug_data[\"raw_transformed_img_crop\"]\n",
    "    \n",
    "    fig, ax = plt.subplots(2, 4, figsize=(20, 10))\n",
    "    ax[0, 0].imshow(img_crop)\n",
    "    ax[0, 0].set_title(\"raw\")\n",
    "    ax[0, 1].imshow(seg_crop)\n",
    "    ax[0, 1].set_title(\"seg\")\n",
    "    ax[0, 2].imshow(combined_gt_label_mask)\n",
    "    ax[0, 2].set_title(\"gt_label\")\n",
    "    ax[0, 3].imshow(aug_seg_crop)\n",
    "    ax[0, 3].set_title(\"aug_seg\")\n",
    "    ax[1, 0].imshow(aug_diff_mask)\n",
    "    ax[1, 0].set_title(\"aug_diff_mask\")\n",
    "    ax[1, 1].imshow(raw_transformed_img_crop)\n",
    "    ax[1, 1].set_title(\"raw_transformed_img\")\n",
    "\n",
    "    # show distribution of raw transformed image\n",
    "    ax[1, 2].hist(raw_transformed_img_crop.flatten(), bins=100)\n",
    "    ax[1, 2].set_title(\"raw_transformed_img hist\")\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate oversegmentation cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BackgroundSimulator:\n",
    "    pass\n",
    "\n",
    "class OverSegSimulator:\n",
    "    pass\n",
    "\n",
    "class UnderSegSimulator:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1, 2], [3, 4]])\n",
    "a[(1,1), (0,0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import random\n",
    "from livecellx.trajectory.contour_utils import get_cellTool_contour_points, viz_contours\n",
    "\n",
    "def get_line_pixels(pt1, pt2, thickness=2, max_x=float(\"inf\"), max_y=float(\"inf\")):\n",
    "    \"\"\"get all pixel coordinates between two points\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    pt1 : _type_\n",
    "        _description_\n",
    "    pt2 : _type_\n",
    "        _description_\n",
    "    thickness : int, optional\n",
    "        _description_, by default 3\n",
    "    max_x : _type_, optional\n",
    "        _description_, by default float(\"inf\")\n",
    "    max_y : _type_, optional\n",
    "        _description_, by default float(\"inf\")\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    _type_\n",
    "        _description_\n",
    "    \"\"\"\n",
    "    def _get_line_pixels_xy(x1, y1, x2, y2, max_x, max_y):\n",
    "        # get the line equation\n",
    "        if x1 == x2:\n",
    "            m = 0\n",
    "        else:\n",
    "            m = (y2 - y1) / (x2 - x1)\n",
    "        b = y1 - m * x1\n",
    "        # get the pixels\n",
    "        pixels = set()\n",
    "\n",
    "        def add_xy(x, y):\n",
    "            if y < max_y and x < max_x and y >= 0 and x >= 0:\n",
    "                pixels.add((x, y))\n",
    "            # simple thickening\n",
    "            sx, sy = x - thickness, y - thickness\n",
    "            for nx in range(sx, sx + thickness * 2):\n",
    "                for ny in range(sy, sy + thickness * 2):\n",
    "                    # if nx ny in bound\n",
    "                    if nx >= 0 and ny >= 0 and nx < max_x and ny < max_y:\n",
    "                        pixels.add((nx, ny))\n",
    "        # exclude x2 purposely to follow skimage bbox conventions\n",
    "        for x in range(x1, x2): \n",
    "            y = int(m * x + b)\n",
    "            add_xy(x, y)\n",
    "            y = int(m * x + b) + 1\n",
    "            add_xy(x, y)\n",
    "        return pixels\n",
    "    x1, y1 = pt1\n",
    "    x2, y2 = pt2\n",
    "    x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "    if x1 > x2:\n",
    "        pt1, pt2 = pt2, pt1\n",
    "        x1, y1, x2, y2 = x2, y2, x1, y1\n",
    "    pixel_set1 = _get_line_pixels_xy(x1, y1, x2, y2, max_x, max_y)\n",
    "\n",
    "    if y1 > y2:\n",
    "        x1, y1, x2, y2 = x2, y2, x1, y1\n",
    "    _pixel_set2 = _get_line_pixels_xy(y1, x1, y2, x2, max_y, max_x)\n",
    "    pixel_set2 = set()\n",
    "    for coord in _pixel_set2:\n",
    "        pixel_set2.add((coord[1], coord[0]))\n",
    "    return pixel_set1.union(pixel_set2)\n",
    "\n",
    "\n",
    "def divide_single_cell_brute_force(sample_sc: SingleCellStatic, seg_crop, sampled_points=None):\n",
    "    \n",
    "    # get the contour points\n",
    "    contour_points = sample_sc.get_contour_coords_on_img_crop()\n",
    "    assert len(contour_points) >= 2, \"need more than 2 contour points to divide a cell\"\n",
    "    if sampled_points is None:\n",
    "        sampled_points = random.choices(contour_points, k=2)\n",
    "        print(\"sampled_points:\", sampled_points)\n",
    "\n",
    "    pt1 = sampled_points[0]\n",
    "    pt2 = sampled_points[1]\n",
    "\n",
    "    # TODO remove the resample code below\n",
    "    # # resample if the points are on the same vertical line\n",
    "    # while pt1[0] == pt2[0] or pt1[1] == pt2[1]:\n",
    "    #     sampled_points = random.choices(contour_points, k=2)\n",
    "    #     pt1 = sampled_points[0]\n",
    "    #     pt2 = sampled_points[1]\n",
    "\n",
    "    line_pixels = np.array(list(get_line_pixels(pt1, pt2, max_x=seg_crop.shape[0], max_y=seg_crop.shape[1])), dtype=int)\n",
    "\n",
    "    if len(line_pixels) == 0:\n",
    "        print(\"[WARN] the sampled line pixels is empty, skipping division process...\")\n",
    "        return\n",
    "\n",
    "    seg_crop[line_pixels[:, 0], line_pixels[:, 1]] = 0\n",
    "    # get the center of mass of the contour\n",
    "    center_of_mass = sample_sc\n",
    "    \n",
    "    # TODO: remove deepcopy because it creates underlying dataset objects holding paths as well\n",
    "    new_sc = deepcopy(sample_sc)\n",
    "    sample_sc.get_contour_img()\n",
    "\n",
    "\n",
    "sampled_sc = single_cells[0]\n",
    "# contour_points = sampled_sc.contour\n",
    "# sampled_contour_points = contour_points[::3]\n",
    "sc_img_path_substr = os.path.basename(sampled_sc.meta[\"path\"]).split(\".\")[0]\n",
    "seg_mask = seg_data.get_img_by_url(sc_img_path_substr, exact_match=False)\n",
    "seg_crop = sampled_sc.gen_skimage_bbox_img_crop(sampled_sc.bbox, seg_mask)\n",
    "\n",
    "sampled_sc.show_contour_mask()\n",
    "plt.show()\n",
    "# plt.imshow(seg_crop[:10, :])\n",
    "# plt.show()\n",
    "\n",
    "# print(\"contour points:\", sampled_sc.get_contour_coords_on_img_crop())\n",
    "\n",
    "# two test cases\n",
    "sampled_points = [[ 85., 66.], [ 73., 0]]\n",
    "# sampled_points = [[ 3., 50.], [ 3., 96.0]]\n",
    "# sample_points = [[ 37., 120.], [54., 12.]]\n",
    "\n",
    "contour_img = sampled_sc.get_contour_img()\n",
    "divide_single_cell_brute_force(sampled_sc, seg_crop=contour_img, sampled_points=sampled_points)\n",
    "# divide_single_cell_brute_force(sampled_sc, seg_crop=contour_img, sampled_points=None)\n",
    "# get_line_pixels([1, 5], [10, 10])\n",
    "# plt.imshow(seg_crop)\n",
    "plt.imshow(contour_img)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qualitatively generate and test bf more thoroughly..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_divide_bf(sc):\n",
    "    contour_img = sc.get_contour_img()\n",
    "    divide_single_cell_brute_force(sc, seg_crop=contour_img, sampled_points=None)\n",
    "    plt.imshow(contour_img)\n",
    "    plt.show()\n",
    "\n",
    "for i in range(3):\n",
    "    test_divide_bf(sampled_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import ndimage\n",
    "from skimage.segmentation import watershed\n",
    "from skimage.feature import peak_local_max\n",
    "from scipy import ndimage as ndi\n",
    "from skimage.morphology import local_maxima, h_maxima\n",
    "from skimage.measure import regionprops, label\n",
    "import scipy.stats\n",
    "import livecellx\n",
    "\n",
    "def add_random_gauss_to_img(contour_mask, raw_crop, square_len, gauss_center_val=200, gauss_std=8, inplace=False, pos=None):\n",
    "    # add random gaussian noise to the raw image\n",
    "    # randomly choose a point inside the contour\n",
    "    if not inplace:\n",
    "        raw_crop = raw_crop.copy()\n",
    "    np.where(contour_mask > 0)\n",
    "    cell_points =np.where(contour_mask > 0)\n",
    "\n",
    "    # # double check: viz cell points from np\n",
    "    # temp = np.zeros(contour_mask.shape)\n",
    "    # temp[cell_points] = 1\n",
    "    # plt.imshow(temp)\n",
    "    # plt.title(\"temp\")\n",
    "    # plt.show()\n",
    "    if pos is not None:\n",
    "        rand_pt = pos\n",
    "    else:\n",
    "        rand_idx = np.random.randint(0, len(cell_points[0]))\n",
    "        rand_pt = np.array([cell_points[0][rand_idx], cell_points[1][rand_idx]])\n",
    "\n",
    "    # the mesh grid is the square around the random point\n",
    "    x_min, x_max = max(rand_pt[0] - square_len, 0), min(rand_pt[0] + square_len, contour_mask.shape[0])\n",
    "    y_min, y_max = max(rand_pt[1] - square_len, 0), min(rand_pt[1] + square_len, contour_mask.shape[1])\n",
    "    grid = np.meshgrid(np.arange(x_min, x_max), np.arange(y_min, y_max))\n",
    "    grid = np.stack(grid, axis=-1)\n",
    "\n",
    "\n",
    "    # compute the distance between the random point and the mesh grid\n",
    "    dist_to_center = np.linalg.norm(grid - rand_pt, axis=-1)\n",
    "\n",
    "\n",
    "    # calculate the gaussian cdf  based on dist to center\n",
    "    gaussian_cdf = scipy.stats.norm.cdf(-dist_to_center, loc=0, scale=gauss_std)\n",
    "\n",
    "    # add gaussian noise to seg_crop\n",
    "    raw_crop[x_min:x_max, y_min:y_max] += gaussian_cdf.T * gauss_center_val\n",
    "\n",
    "    # print(\"cell_points:\", cell_points)\n",
    "    # print(\"cell_points len:\", len(cell_points[0]))\n",
    "    # print(\"contour mask sum:\", contour_mask.sum())\n",
    "    # print(\"square_len:\", square_len)\n",
    "    # print(\"grid shape:\", grid.shape)\n",
    "    # print(\"dist_to_center shape:\", dist_to_center.shape)\n",
    "    # print(\"dist_to_center mean:\", np.mean(dist_to_center))\n",
    "    # print(\"gaussian noise shape:\", gaussian_cdf.shape)\n",
    "    # print(\"gaussian mean:\", np.mean(gaussian_cdf))\n",
    "    return raw_crop, rand_pt\n",
    "\n",
    "\n",
    "\n",
    "def divide_single_cell_watershed(sample_sc: SingleCellStatic, raw_crop=None, peak_distance=20, markers=None, marker_method=\"hmax\", h_threshold=1, normalize=True, normalize_edt=True, gauss_center_val=200, edt_gauss_center_val=1, gauss_std=8, num_gauss_areas=2, return_all=False):\n",
    "    contour_points = sample_sc.get_contour_coords_on_img_crop()\n",
    "    contour_mask = sample_sc.get_contour_mask()\n",
    "    \n",
    "    if raw_crop is None:\n",
    "        raw_crop = sample_sc.get_contour_img()\n",
    "    else:\n",
    "        raw_crop = raw_crop.copy()\n",
    "\n",
    "    # normalize seg_crop\n",
    "    if normalize:\n",
    "        raw_crop = livecellx.preprocess.utils.normalize_img_to_uint8(raw_crop)\n",
    "        raw_crop = raw_crop.astype(float)\n",
    "\n",
    "    # # print statistics of seg_crop\n",
    "    # print(\"seg_crop shape:\", raw_crop.shape)\n",
    "    # print(\"seg_crop unique:\", np.unique(raw_crop))\n",
    "    # print(\"seg_crop mean:\", np.mean(raw_crop))\n",
    "    # print(\"cell area:\", prop.area)\n",
    "    # print(\"cell axis_major_length:\", prop.major_axis_length)\n",
    "    # print(\"cell axis_minor_length:\", prop.minor_axis_length)\n",
    "\n",
    "    # edt transform\n",
    "    edt_distance = ndimage.distance_transform_edt(contour_mask)\n",
    "    if normalize_edt:\n",
    "        edt_flattened = edt_distance.flatten()\n",
    "        edt_distance = (edt_distance - np.min(edt_flattened)) / (np.max(edt_flattened) - np.min(edt_flattened))\n",
    "    # # print stats of edt_distance\n",
    "    # print(\"edt_distance shape:\", edt_distance.shape)\n",
    "    # print(\"edt max:\", np.max(edt_distance))\n",
    "    # print(\"edt min:\", np.min(edt_distance))\n",
    "    # print(\"edt mean:\", np.mean(edt_distance))\n",
    "    # TODO: add gaussian noise\n",
    "\n",
    "    # determin the area of noise (new labeled region for oversegmentation)\n",
    "    assert len(np.unique(contour_mask)) == 2, \"seg_crop should only contain one label\"\n",
    "    props = regionprops(label_image=contour_mask.astype(int), intensity_image=raw_crop)\n",
    "    assert len(props) == 1, \"seg_crop should only contain one label\"\n",
    "    prop = props[0]\n",
    "    \n",
    "    square_len = int(np.sqrt(prop.area))\n",
    "    for _ in range(num_gauss_areas):\n",
    "        _, rand_pos = add_random_gauss_to_img(contour_mask, raw_crop, square_len, gauss_center_val=gauss_center_val, gauss_std=gauss_std, inplace=True)\n",
    "        add_random_gauss_to_img(contour_mask, edt_distance, square_len, gauss_center_val=edt_gauss_center_val, gauss_std=gauss_std, inplace=True, pos=rand_pos)\n",
    "\n",
    "    # # show edt_distance\n",
    "    # plt.imshow(edt_distance)\n",
    "    # plt.title(\"edt_distance\")\n",
    "    # plt.show()\n",
    "    # watershed segmentation\n",
    "    if markers is None and marker_method == \"hmax\":\n",
    "        # local_hmax = h_maxima(raw_crop, h_threshold)\n",
    "        local_hmax = h_maxima(edt_distance, h_threshold)\n",
    "        markers = label(local_hmax, connectivity=1)\n",
    "    elif markers is None and marker_method == \"local\":\n",
    "        # use local peak as default markers\n",
    "        coords = peak_local_max(edt_distance, min_distance=peak_distance, footprint=np.ones((3, 3)))\n",
    "        mask = np.zeros(edt_distance.shape, dtype=bool)\n",
    "        mask[tuple(coords.T)] = True\n",
    "        markers, _ = ndi.label(mask)\n",
    "\n",
    "    # labels = watershed(edt_distance, markers, mask=contour_mask)\n",
    "    label_mask = watershed(-edt_distance, markers, mask=contour_mask)\n",
    "\n",
    "    # # print shapes\n",
    "    # print(\"markers shape:\", markers.shape)\n",
    "    # print(\"markers unique values:\", np.unique(markers))\n",
    "    # print(np.where(markers > 0))\n",
    "    \n",
    "    # print(\"labels shape:\", label_mask.shape)\n",
    "    # print(\"labels unique values:\", np.unique(label_mask))\n",
    "    # plt.clf()\n",
    "    # plt.imshow(label_mask)\n",
    "    # plt.title(\"labels\")\n",
    "    # plt.show()\n",
    "    if return_all:\n",
    "        return raw_crop, label_mask, edt_distance, markers\n",
    "    return label_mask\n",
    "\n",
    "\n",
    "raw_crop = sampled_sc.get_contour_img()\n",
    "# new_img, label_mask = divide_single_cell_watershed(sampled_sc, peak_distance=20, num_gauss_areas=4, marker_method=\"local\", gauss_center_val=150)\n",
    "\n",
    "new_raw_crop, label_mask, edt_distance, markers = divide_single_cell_watershed(sampled_sc, num_gauss_areas=3, marker_method=\"hmax\", edt_gauss_center_val=10, gauss_std=16, h_threshold=1, return_all=True)\n",
    "\n",
    "def erode_label_mask(label_mask: np.array, scale_factor=-0.1, bg_val=0):\n",
    "    \"\"\"Erode label mask to make each labeled region smaller and thus separated.\"\"\"\n",
    "    labels = np.unique(label_mask)\n",
    "    # remove bg label\n",
    "    labels = labels[labels != bg_val]\n",
    "\n",
    "    res = np.zeros(label_mask.shape)\n",
    "    for label in labels:\n",
    "        bin_mask = label_mask == label\n",
    "        bin_mask = bin_mask.astype(np.uint8)\n",
    "        eroded_mask = dilate_or_erode_mask(bin_mask, scale_factor=scale_factor)\n",
    "        res = res + eroded_mask * label\n",
    "    return res\n",
    "\n",
    "eroded_label_mask = erode_label_mask(label_mask, scale_factor=-0.1, bg_val=0)\n",
    "\n",
    "fig, axes = plt.subplots(1, 6, figsize=(60, 10))\n",
    "ax = axes[0]\n",
    "ax.imshow(raw_crop)\n",
    "ax.set_title(\"raw_img\")\n",
    "ax = axes[1]\n",
    "ax.imshow(new_raw_crop)\n",
    "ax.set_title(\"new_img\")\n",
    "ax = axes[2]\n",
    "ax.imshow(label_mask)\n",
    "ax.set_title(\"label_mask\")\n",
    "ax = axes[3]\n",
    "ax.imshow(edt_distance)\n",
    "ax.set_title(\"edt_distance\")\n",
    "ax = axes[4]\n",
    "ax.imshow(markers)\n",
    "ax.set_title(\"markers\")\n",
    "ax = axes[5]\n",
    "ax.imshow(eroded_label_mask)\n",
    "ax.set_title(\"eroded_label_mask\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate synthetic data by watershed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_synthetic_overseg(sc, num_samples=10, max_try=20, **kwargs):\n",
    "    res_label_masks_and_params = []\n",
    "    num_gauss_area = kwargs[\"num_gauss_areas\"]\n",
    "    for _ in range(num_samples):\n",
    "        counter = 0\n",
    "        num_segs = -1\n",
    "        while num_segs < num_gauss_area and counter < max_try:\n",
    "            label_mask = divide_single_cell_watershed(sc, **kwargs)\n",
    "            num_segs = len(np.unique(label_mask)) - 1\n",
    "            counter += 1\n",
    "        if num_segs < num_gauss_area:\n",
    "            # print(\"fail to generate enough segs\")\n",
    "            continue\n",
    "        meta = kwargs.copy()\n",
    "        meta[\"num_segs\"] = num_segs\n",
    "        eroded_label_mask = erode_label_mask(label_mask, scale_factor=-0.1, bg_val=0)\n",
    "        res_label_masks_and_params.append((label_mask, eroded_label_mask, meta))\n",
    "    return res_label_masks_and_params\n",
    "\n",
    "overseg_uns_key = \"overseg_imgs\"\n",
    "num_gauss_areas = np.arange(3, 6)\n",
    "num_samples = 5\n",
    "\n",
    "def process_sc_synthetic_overseg_crops(sc):\n",
    "    sc.uns[overseg_uns_key] = []\n",
    "    for num_gauss_area in num_gauss_areas:\n",
    "        label_masks_and_params_hmax = gen_synthetic_overseg(sc, num_samples=num_samples, peak_distance=10, num_gauss_areas=num_gauss_area, marker_method=\"hmax\", edt_gauss_center_val=10, gauss_std=16, h_threshold=1)\n",
    "        label_masks_and_params_local = gen_synthetic_overseg(sc, num_samples=num_samples, peak_distance=10, num_gauss_areas=num_gauss_area, edt_gauss_center_val=10, gauss_std=16, marker_method=\"local\",  gauss_center_val=150)\n",
    "        sc.uns[overseg_uns_key].extend(label_masks_and_params_hmax)\n",
    "        sc.uns[overseg_uns_key].extend(label_masks_and_params_local)\n",
    "    return sc\n",
    "\n",
    "from multiprocessing import Pool\n",
    "pool = Pool()\n",
    "res_single_cells = []\n",
    "for res_sc in tqdm(pool.imap_unordered(process_sc_synthetic_overseg_crops, single_cells, chunksize=1), total=len(single_cells)):\n",
    "    res_single_cells.append(res_sc)\n",
    "# pool.map(process_sc_synthetic_overseg_crops, single_cells)\n",
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_cells = res_single_cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    sc = res_single_cells[i]\n",
    "\n",
    "    # somehow failed to generate synthetic data meeting our criterion\n",
    "    if len(sc.uns[overseg_uns_key]) == 0:\n",
    "        continue\n",
    "    for j in range(len(sc.uns[overseg_uns_key])):\n",
    "        label_mask, eroded_label_mask, params = sc.uns[overseg_uns_key][j]\n",
    "        print(params)\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(5, 2))\n",
    "        ax = axes[0]\n",
    "        ax.imshow(label_mask)\n",
    "        ax.set_title(\"label_mask\")\n",
    "        ax = axes[1]\n",
    "        ax.imshow(eroded_label_mask)\n",
    "        ax.set_title(\"eroded_label_mask\")\n",
    "        plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove overseg out directory contents if necessary\n",
    "```# !rm -r $overseg_out_dir```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(single_cells)\n",
    "np.sum([len(sc.uns[overseg_uns_key]) for sc in single_cells])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from livecellx.segment.ou_utils import csn_augment_helper\n",
    "subdir = Path(\"synthetic_overseg\")\n",
    "overseg_out_dir = out_dir / subdir\n",
    "raw_out_dir = overseg_out_dir / \"raw\"\n",
    "\n",
    "# seg_out_dir is the directory containing all raw segmentation masks for training\n",
    "# e.g. the eroded raw segmentation masks\n",
    "seg_out_dir = overseg_out_dir / \"seg\"\n",
    "\n",
    "# raw_seg_dir is the directory containing all raw segmentation masks for recording purposes\n",
    "raw_seg_dir = overseg_out_dir / \"raw_seg_crop\"\n",
    "gt_out_dir = overseg_out_dir / \"gt\"\n",
    "gt_label_out_dir = overseg_out_dir / \"gt_label_mask\"\n",
    "augmented_seg_dir = overseg_out_dir / \"augmented_seg\"\n",
    "raw_transformed_img_dir = overseg_out_dir / \"raw_transformed_img\"\n",
    "augmented_diff_seg_dir = overseg_out_dir / \"augmented_diff_seg\"\n",
    "meta_path = overseg_out_dir / \"metadata.csv\"\n",
    "syn_overseg_df_save_path = overseg_out_dir / \"data.csv\"\n",
    "\n",
    "os.makedirs(raw_out_dir, exist_ok=True)\n",
    "os.makedirs(seg_out_dir, exist_ok=True)\n",
    "os.makedirs(raw_seg_dir, exist_ok=True)\n",
    "os.makedirs(gt_out_dir, exist_ok=True)\n",
    "os.makedirs(augmented_seg_dir, exist_ok=True)\n",
    "os.makedirs(gt_label_out_dir, exist_ok=True)\n",
    "os.makedirs(raw_transformed_img_dir, exist_ok=True)\n",
    "os.makedirs(augmented_diff_seg_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "overseg_train_path_tuples = []\n",
    "augmented_overseg_data = []\n",
    "filename_pattern = \"img-%d_syn-%d.tif\"\n",
    "overseg_metadata = []\n",
    "overseg_erosion_scale_factors = np.linspace(-0.1, 0, 10)\n",
    "all_df = None\n",
    "for sc in tqdm(single_cells):\n",
    "    img_id = sc.timeframe\n",
    "    for syn_id, overseg_datarow in enumerate(sc.uns[overseg_uns_key]):\n",
    "        params = overseg_datarow[1]\n",
    "        img_crop = sc.get_contour_img()\n",
    "        raw_seg_crop = overseg_datarow[0]\n",
    "        eroded_seg_crop = overseg_datarow[1]\n",
    "\n",
    "        combined_gt_label_mask = sc.get_contour_mask()\n",
    "        assert img_crop.shape == raw_seg_crop.shape == combined_gt_label_mask.shape\n",
    "        raw_img_path = raw_out_dir / (filename_pattern % (img_id, syn_id))\n",
    "        seg_img_path = seg_out_dir / (filename_pattern % (img_id, syn_id))\n",
    "        raw_seg_img_path = raw_seg_dir / (filename_pattern % (img_id, syn_id))\n",
    "        gt_img_path = gt_out_dir / (filename_pattern % (img_id, syn_id))\n",
    "        gt_label_img_path = gt_label_out_dir / (filename_pattern % (img_id, syn_id))\n",
    "\n",
    "        # metadata is a dict, containing params used to genereate our synthetic overseg data\n",
    "        meta_info = overseg_datarow[2]\n",
    "        meta_info[\"raw_img_path\"] = raw_img_path\n",
    "        meta_info[\"seg_img_path\"] = seg_img_path\n",
    "        meta_info[\"gt_img_path\"] = gt_img_path\n",
    "        \n",
    "        overseg_metadata.append(meta_info)\n",
    "\n",
    "        # call csn augment helper\n",
    "        res_dict = csn_augment_helper(img_crop=img_crop, \n",
    "            seg_label_crop=eroded_seg_crop, \n",
    "            combined_gt_label_mask=combined_gt_label_mask,\n",
    "            overseg_raw_seg_crop=raw_seg_crop,\n",
    "            overseg_raw_seg_img_path=raw_seg_img_path,\n",
    "            scale_factors=overseg_erosion_scale_factors,\n",
    "            train_path_tuples=overseg_train_path_tuples,\n",
    "            augmented_data=augmented_overseg_data,\n",
    "            img_id=img_id,\n",
    "            seg_label=syn_id,\n",
    "            gt_label=sc.timeframe,\n",
    "            raw_img_path=raw_img_path,\n",
    "            seg_img_path=seg_img_path,\n",
    "            gt_img_path=gt_img_path,\n",
    "            gt_label_img_path=gt_label_img_path,\n",
    "            augmented_seg_dir=augmented_seg_dir,\n",
    "            augmented_diff_seg_dir=augmented_diff_seg_dir,\n",
    "            filename_pattern=filename_pattern,\n",
    "            raw_transformed_img_dir=raw_transformed_img_dir,\n",
    "            # df_save_path=syn_overseg_df_save_path,\n",
    "        )\n",
    "        all_df = res_dict[\"df\"]\n",
    "\n",
    "all_df.to_csv(syn_overseg_df_save_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    overseg_train_path_tuples,\n",
    "    columns=[\"raw\", \"seg\", \"gt\", \"raw_seg\", \"scale\", \"aug_diff_mask\", \"gt_label_mask\", \"raw_transformed_img\"],\n",
    ").to_csv(overseg_out_dir / \"data.csv\", index=False)\n",
    "\n",
    "pd.DataFrame(\n",
    "    overseg_metadata,\n",
    ").to_csv(meta_path, index=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Synthetic Undersegmentation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_sc(sc1, sc2):\n",
    "    pass\n",
    "sc1 = single_cells[0]\n",
    "sc2 = single_cells[1]\n",
    "sc2.show(padding=10)\n",
    "plt.show()\n",
    "sc2.show_contour_img()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_underseg_cases(scs):\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine data.csv files generated in each subfolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = []\n",
    "for subdir in out_dir.iterdir():\n",
    "    if subdir.is_dir():\n",
    "        data_path = subdir / \"data.csv\"\n",
    "        dataframe = pd.read_csv(data_path)\n",
    "        dataframe[\"subdir\"] = subdir.name\n",
    "        dataframes.append(dataframe)\n",
    "combined_dataframe = pd.concat(dataframes)\n",
    "combined_dataframe.to_csv(out_dir / \"train_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(combined_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_dataframe[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_overseg_mask_labels(mask: np.array, sc: SingleCellStatic, io_seg_threshold=0.6):\n",
    "    \"\"\"match a single cell's label in a mask. sc must contain its contour information.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    mask : np.array\n",
    "        _description_\n",
    "    sc : \n",
    "        _description_\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    a dict with keys \"seg_label\" and \"iou\"\n",
    "    \"\"\"    \n",
    "    cropped_seg_mask = SingleCellStatic.gen_skimage_bbox_img_crop(sc.bbox, seg_mask)\n",
    "\n",
    "    # Note the order of the arguments are reversed compared with underseg case\n",
    "    # because match_mask_labels_by_iou is designed to match one seg mask to several gt masks (select gt sc's best matching seg label)\n",
    "    # and in the oversegmentation case, we need to match one gt mask to several seg masks\n",
    "    _, seg2gt_info = match_mask_labels_by_iou(seg_mask=sc.get_contour_mask(), gt_mask=cropped_seg_mask, return_all=True)\n",
    "    matched_seg_labels = []\n",
    "    for info in seg2gt_info:\n",
    "        seg_label = info[\"seg_label\"]\n",
    "        iou = info[\"iou\"]\n",
    "        # Not the code below is not a bug: remember we reverse the order of the arguments\n",
    "        io_gt = info[\"io_seg\"]\n",
    "        io_seg = info[\"io_gt\"]\n",
    "        if io_seg > io_seg_threshold:\n",
    "            matched_seg_labels.append(seg_label)\n",
    "    return matched_seg_labels\n",
    "\n",
    "for sc in tqdm(single_cells):\n",
    "    sc_img_path_substr = os.path.basename(sc.meta[\"path\"]).split(\".\")[0]\n",
    "    seg_mask = seg_data.get_img_by_url(sc_img_path_substr, substr=True)\n",
    "    sc.meta[\"overseg_labels\"] = match_seg_mask_label(seg_mask, sc)[\"seg_label\"]\n",
    "    sc.mask_dataset = seg_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO Below: adapt to new code (for real data's oversegmentation case); Skip for now because there is no oversegmentation case in our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(img_crop, seg_crop, combined_mask, aug_mask, aug_diff_mask, combined_gt_label_mask, raw_transformed_img_crop) = augmented_data[(1, 14)][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(combined_mask), np.unique(aug_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "\n",
    "mask_tuples = list(augmented_overseg_data.values())[0]\n",
    "nsamples = 10\n",
    "# nsamples = np.sum([len(v) for v in augmented_data.values()])\n",
    "ncol = 7\n",
    "fig, axes = plt.subplots(nsamples, ncol, figsize=(25, 5.5 * nsamples))\n",
    "fig.tight_layout()\n",
    "\n",
    "sample_counter = 0\n",
    "for key, mask_tuples in augmented_overseg_data.items():\n",
    "    for j in range(len(mask_tuples)):\n",
    "        i = sample_counter\n",
    "        axes[i, 0].imshow(mask_tuples[j][0])\n",
    "        axes[i, 0].set_title(\"raw mask\")\n",
    "        axes[i, 1].imshow(mask_tuples[j][1])\n",
    "        axes[i, 1].set_title(\"seg img\")\n",
    "        axes[i, 2].imshow(mask_tuples[j][2])\n",
    "        axes[i, 2].set_title(\"combined mask\")\n",
    "        axes[i, 3].imshow(mask_tuples[j][3])\n",
    "        axes[i, 3].set_title(\"augmented mask\")\n",
    "        im = axes[i, 4].imshow(mask_tuples[j][4])\n",
    "        axes[i, 4].set_title(\"augmented diff mask\")\n",
    "\n",
    "        values = np.unique(mask_tuples[j][4])\n",
    "        colors = [ im.cmap(im.norm(value)) for value in values]\n",
    "        patches = [ mpatches.Patch(color=colors[i], label=\"Level {l}\".format(l=values[i]) ) for i in range(len(values)) ]\n",
    "        axes[i, 4].legend(handles=patches, loc=2, borderaxespad=0. )\n",
    "\n",
    "        axes[i, 5].imshow(mask_tuples[j][5])\n",
    "        axes[i, 5].set_title(\"combined gt label mask\")\n",
    "\n",
    "        axes[i, 6].imshow(mask_tuples[j][6])\n",
    "        axes[i, 6].set_title(\"raw transformed img\")\n",
    "\n",
    "        sample_counter += 1\n",
    "        if sample_counter >= nsamples:\n",
    "            break\n",
    "    if sample_counter >= nsamples:\n",
    "        break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deprecated code for augmenting a single cell for CSN\n",
    "```\n",
    "from pathlib import Path\n",
    "from copy import deepcopy\n",
    "from PIL import Image, ImageSequence\n",
    "\n",
    "img_paths = []\n",
    "augment_dir = Path(\"../datasets/a549_ccnn/augmented_cells\")\n",
    "augmented_cells = []\n",
    "scale_factor = 0.01\n",
    "padding = 100\n",
    "\n",
    "def augment_single_cell_csn(sc: SingleCellStatic, augment_dir: Path, scale_factor=0.01, padding=40, show=False, bg_value=0):\n",
    "    mask = sc.get_mask_crop(padding=padding).astype(np.uint8)\n",
    "    mask_label = sc.meta[\"seg_label\"]\n",
    "    mask[mask!=mask_label] = bg_value\n",
    "\n",
    "    augmented_mask = dilate_or_erode_mask(mask, scale_factor=scale_factor)\n",
    "    augmentation_save_path = augment_dir / f\"{i}_mask.tif\"\n",
    "    save_png(augmented_mask, str(augmentation_save_path))\n",
    "\n",
    "    meta = {}\n",
    "    meta[\"original_path\"] = sc.meta[\"path\"]\n",
    "    meta[\"original_seg_label\"] = sc.meta[\"seg_label\"]\n",
    "    meta[\"path\"] = augmentation_save_path.as_posix()\n",
    "    meta[\"padding\"] = padding\n",
    "    meta[\"scale_factor\"] = scale_factor\n",
    "    meta[\"method\"] = \"dilate/erode\"\n",
    "\n",
    "    new_sc = SingleCellStatic(\n",
    "        img_dataset=sc.img_dataset,\n",
    "        mask_dataset=sc.mask_dataset,\n",
    "        contour = np.array(sc.contour),\n",
    "        meta=meta,\n",
    "    )\n",
    "\n",
    "    if show:\n",
    "        fig, axes = plt.subplots(1, 4, figsize=(10, 10))\n",
    "        # sc.show_mask(ax=axes[0])\n",
    "        sc.show(ax=axes[0])\n",
    "        axes[2].imshow(mask)\n",
    "        sc.show_contour_img(ax=axes[1])\n",
    "        axes[3].imshow(augmented_mask)\n",
    "\n",
    "        axes[0].set_title(\"original image crop\")\n",
    "        axes[2].set_title(\"seg mask\")\n",
    "        axes[1].set_title(\"gt contour mask\")\n",
    "        axes[3].set_title(\"augmented mask\")\n",
    "    return new_sc\n",
    "\n",
    "\n",
    "augmented_single_cells = []\n",
    "for i in tqdm(range(len(single_cells))):\n",
    "    sc = single_cells[i]\n",
    "    augmented_sc = augment_single_cell_csn(sc, augment_dir, scale_factor=scale_factor, padding=padding, show=False)\n",
    "    augmented_single_cells.append(augmented_sc)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Undersegmentation case:\n",
    "    overlay all the ground truth masks on the original image, and then use the result as the ground truth mask for the undersegmentation case.\n",
    "    Segmentation mask \n",
    "    gt mask\n",
    "\n",
    "OVERSEGMENTATION CASE:\n",
    "    # future work\n",
    "    Segmentation mask\n",
    "    gt mask\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Overlay segmentation mask and gt mask\n",
    "2. Shift the cells in the segmentation mask to the center of the cell\n",
    "3. Synthetic dataset\n",
    "\n",
    "thin_plate_spline?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "livecell",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d9c7226d793827cd27273ad20fbb4775c3cb91053ab9378a09de5f8c6f258919"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
