{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from cellpose import models\n",
    "from cellpose.io import imread\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from PIL import Image, ImageSequence\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import os.path\n",
    "from livecellx import segment\n",
    "from livecellx import core\n",
    "from livecellx.core import datasets\n",
    "from livecellx.core.datasets import LiveCellImageDataset\n",
    "from skimage import measure\n",
    "from livecellx.core import SingleCellTrajectory, SingleCellStatic\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "import cv2\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from livecellx.segment.detectron_utils import gen_cfg\n",
    "\n",
    "from livecellx.segment.detectron_utils import (\n",
    "    segment_detectron_wrapper,\n",
    "    segment_images_by_detectron,\n",
    "    convert_detectron_instance_pred_masks_to_binary_masks,\n",
    "    convert_detectron_instances_to_label_masks,\n",
    ")\n",
    "from livecellx.segment.detectron_utils import (\n",
    "    convert_detectron_instance_pred_masks_to_binary_masks,\n",
    "    convert_detectron_instances_to_label_masks,\n",
    "    segment_images_by_detectron,\n",
    "    segment_single_img_by_detectron_wrapper,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291 png img file paths loaded;\n"
     ]
    }
   ],
   "source": [
    "dataset_dir_path = Path(\"../datasets/EBSS_Starvation/tif_STAV-A549_VIM_24hours_NoTreat_NA_YL_Ti2e_2022-12-21/XY15/\")\n",
    "\n",
    "mask_dataset_path = Path(\n",
    "    \"../datasets/EBSS_Starvation/tif_STAV-A549_VIM_24hours_NoTreat_NA_YL_Ti2e_2022-12-21/out/XY15/seg\"\n",
    ")\n",
    "\n",
    "mask_dataset = LiveCellImageDataset(mask_dataset_path, ext=\"png\")\n",
    "time2url = sorted(glob.glob(str((Path(dataset_dir_path) / Path(\"*_DIC.tif\")))))\n",
    "time2url = {i: path for i, path in enumerate(time2url)}\n",
    "dic_dataset = LiveCellImageDataset(time2url=time2url, ext=\"tif\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert label masks to single objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 79/291 [00:04<00:09, 21.23it/s]"
     ]
    }
   ],
   "source": [
    "from livecellx.core.io_sc import process_scs_from_label_mask, prep_scs_from_mask_dataset\n",
    "\n",
    "single_cells = prep_scs_from_mask_dataset(mask_dataset, dic_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for testing\n",
    "# single_cells = single_cells[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(single_cells)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the cells visually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for time in overlap_map_by_time:\n",
    "#     overlap_map = overlap_map_by_time[time]\n",
    "#     for sc_tmp1, sc_tmp2 in overlap_map:\n",
    "#         if sc_tmp1 == sc_tmp2:\n",
    "#             continue\n",
    "#         if overlap_map[(sc_tmp1, sc_tmp2)][0] > 0:\n",
    "#             print(sc_tmp1.timeframe, sc_tmp2.timeframe, overlap_map[(sc_tmp1, sc_tmp2)])\n",
    "#             fig, axes = plt.subplots(1, 6, figsize=(15, 5))\n",
    "#             padding=50\n",
    "#             sc_tmp1.show_contour_mask(crop=False, ax = axes[0])\n",
    "#             sc_tmp2.show_contour_mask(crop=False, ax = axes[1])\n",
    "#             sc_tmp1.show(crop=True, ax = axes[2], padding=padding)\n",
    "#             sc_tmp2.show(crop=True, ax = axes[3], padding=padding)\n",
    "#             sc_tmp1.show_contour_mask(crop=True, ax = axes[4], padding=padding)\n",
    "#             sc_tmp2.show_contour_mask(crop=True, ax = axes[5], padding=padding)\n",
    "#             plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "sc.datasets[\"img\"]\n",
    "sc.datasets[\"mask\"]\n",
    "sc.datasets[\"label\"]\n",
    "sc.datasets[\"TRITC\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from livecellx.segment.utils import match_mask_labels_by_iou\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Track cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from livecellx.track.sort_tracker_utils import (\n",
    "    gen_SORT_detections_input_from_contours,\n",
    "    update_traj_collection_by_SORT_tracker_detection,\n",
    "    track_SORT_bbox_from_contours,\n",
    "    track_SORT_bbox_from_scs,\n",
    ")\n",
    "\n",
    "traj_collection = track_SORT_bbox_from_scs(single_cells, dic_dataset, mask_dataset=mask_dataset, max_age=1, min_hits=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within the same trajectory, check if there is any multiple mapping issue within an interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from livecellx.segment.utils import filter_labels_match_map\n",
    "\n",
    "\n",
    "def filter_labels_match_map(gt2seg_iou__map, iou_threshold):\n",
    "    label_map = {}\n",
    "    for label_1 in gt2seg_iou__map:\n",
    "        label_map[label_1] = {}\n",
    "        for score_info in gt2seg_iou__map[label_1]:\n",
    "            if score_info[\"iou\"] > iou_threshold:\n",
    "                label_map[label_1][score_info[\"seg_label\"]] = {\"iou\": score_info[\"iou\"]}\n",
    "    return label_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from livecellx.model_zoo.segmentation.sc_correction import CorrectSegNet\n",
    "\n",
    "# ckpt = r\"/home/ken67/LiveCellTracker-dev/notebooks/lightning_logs/version_real-02/checkpoints/epoch=3720-test_loss=0.0085.ckpt\"\n",
    "# ckpt = r\"/home/ken67/LiveCellTracker-dev/notebooks/lightning_logs/version_802/checkpoints/epoch=2570-test_out_matched_num_gt_iou_0.5_percent_real_underseg_cases=0.8548.ckpt\"\n",
    "# ckpt = r\"/home/ken67/LiveCellTracker-dev/notebooks/lightning_logs/version_v10_02/checkpoints/epoch=2999-global_step=0.ckpt\"\n",
    "ckpt = (\n",
    "    r\"/home/ken67/LiveCellTracker-dev/notebooks/lightning_logs/version_v10_02/checkpoints/epoch=5999-global_step=0.ckpt\"\n",
    ")\n",
    "# ckpt = r\"/home/ken67/LiveCellTracker-dev/notebooks/lightning_logs/version_v11_02/checkpoints/last.ckpt\"\n",
    "\n",
    "model = CorrectSegNet.load_from_checkpoint(ckpt)\n",
    "model = model.cuda()\n",
    "model = model.eval()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Psuedocode  \n",
    "\n",
    "Start at each timepoint  \n",
    "    from t to t + window_size  \n",
    "    count if segmentation at time t conforms with the majority of the segmentation results  \n",
    "    try using correction CNN to correct if not\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from livecellx.segment.ou_viz import viz_ou_sc_outputs\n",
    "from livecellx.core.parallel import parallelize\n",
    "from torchvision import transforms\n",
    "\n",
    "trajectory = traj_collection.get_trajectory(5)\n",
    "input_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(size=(412, 412)),\n",
    "    ]\n",
    ")\n",
    "fig_out_dir = Path(\"./tmp_csn_temporal_correct\")\n",
    "os.makedirs(fig_out_dir, exist_ok=True)\n",
    "\n",
    "padding_pixels = 50\n",
    "one_object = True\n",
    "out_threshold = 4\n",
    "remove_bg = False\n",
    "\n",
    "\n",
    "def consensus_trajectory(trajectory: SingleCellTrajectory, sliding_window=3, iou_threshold=0.3):\n",
    "    failed_consensus_track_times = []\n",
    "    conflict_track_id_and_time_pairs = []\n",
    "    track_id = trajectory.track_id\n",
    "\n",
    "    for time, pivot_sc in trajectory:\n",
    "        _consensus = []\n",
    "        cur_bbox = pivot_sc.get_bbox()\n",
    "        cur_label_mask = pivot_sc.get_sc_mask()  # a mask containing one label\n",
    "        cur_time = time\n",
    "        for i in range(sliding_window):\n",
    "            # next_time = time + i + 1\n",
    "            cur_time = trajectory.next_time(cur_time)\n",
    "            if cur_time is None:\n",
    "                break\n",
    "            next_sc = trajectory[cur_time]\n",
    "            next_label_mask = next_sc.get_mask_crop(bbox=cur_bbox, dtype=int)\n",
    "            _, all_gt2seg_iou__map = match_mask_labels_by_iou(next_label_mask, cur_label_mask, return_all=True)\n",
    "            label_map = filter_labels_match_map(all_gt2seg_iou__map, iou_threshold=iou_threshold)\n",
    "            assert len(label_map) == 1, \"only one label should be matched\"\n",
    "            label = list(label_map)[0]\n",
    "            is_uniform_map = len(label_map[label]) == 1\n",
    "            _consensus.append(is_uniform_map)\n",
    "            if not is_uniform_map:\n",
    "                conflict_track_id_and_time_pairs.append((track_id, time, cur_time))\n",
    "        if len(_consensus) == 0:\n",
    "            continue\n",
    "        is_majority_consenus = sum(_consensus) > (len(_consensus) / 2 - 1)  # -1 for including itself\n",
    "        # print(\"is_majority_consenus:\", is_majority_consenus)\n",
    "        if not is_majority_consenus:\n",
    "            failed_consensus_track_times.append((trajectory.track_id, time))\n",
    "    return failed_consensus_track_times, conflict_track_id_and_time_pairs\n",
    "\n",
    "\n",
    "inputs = []\n",
    "iou_threshold = 0.3\n",
    "sliding_window = 10\n",
    "for track_id, trajectory in traj_collection:\n",
    "    inputs.append((trajectory, sliding_window, iou_threshold))\n",
    "\n",
    "results = parallelize(consensus_trajectory, inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count how many time point pairs in total\n",
    "total_time_point_pairs = 0\n",
    "for track, trajectory in traj_collection:\n",
    "    total_time_point_pairs += len(trajectory) - 1\n",
    "print(\"total_time_point_pairs:\", total_time_point_pairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed_consensus_track_times = [item for x in [result[0] for result in results] for item in x]\n",
    "conflict_track_id_and_time_pairs = [item for x in [result[1] for result in results] for item in x]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(traj_collection), len(failed_consensus_track_times), len(conflict_track_id_and_time_pairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_track_time_pairs = 0\n",
    "for _, trajectory in traj_collection:\n",
    "    total_track_time_pairs += len(trajectory)\n",
    "total_track_time_pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed_consensus_track_times[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conflict_track_id_and_time_pairs[:2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectory.timeframe_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conflict_track_id_and_time_pairs[0][0]\n",
    "trajectory = traj_collection.get_trajectory(track_id)\n",
    "trajectory.timeframe_set\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize and save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conflict_track_idx = 120\n",
    "\n",
    "\n",
    "def viz_conflict_track(conflict_track_idx, conflict_track_id_and_time_pairs, sliding_window=1):\n",
    "    track_id = conflict_track_id_and_time_pairs[conflict_track_idx][0]\n",
    "    time = conflict_track_id_and_time_pairs[conflict_track_idx][1]\n",
    "    cur_time = conflict_track_id_and_time_pairs[conflict_track_idx][2]\n",
    "\n",
    "    trajectory = traj_collection.get_trajectory(track_id)\n",
    "\n",
    "    cur_sc = trajectory[time]\n",
    "    next_sc = trajectory[cur_time]\n",
    "    cur_bbox = cur_sc.get_bbox()\n",
    "    cur_label_mask = cur_sc.get_sc_mask()\n",
    "    fig_out_dir = Path(\"./tmp_csn_temporal_correct\")\n",
    "    os.makedirs(fig_out_dir, exist_ok=True)\n",
    "\n",
    "    print(\">\" * 80)\n",
    "    print(\"track id:\", track_id)\n",
    "    print(\"time, next_time:\", time, cur_time)\n",
    "    print(\"current sc:\")\n",
    "    # viz cells\n",
    "    cur_sc.show_panel(padding=50)\n",
    "    # plt.savefig(fig_out_dir / f\"{track_id}_{time}_{next_time}_first.png\")\n",
    "    viz_ou_sc_outputs(\n",
    "        cur_sc,\n",
    "        model,\n",
    "        transforms=input_transforms,\n",
    "        save_path=fig_out_dir / f\"{track_id}_{time}_{cur_time}_first_csn.png\",\n",
    "        show=True,\n",
    "        remove_bg=remove_bg,\n",
    "        padding_pixels=padding_pixels,\n",
    "        out_threshold=out_threshold,\n",
    "    )\n",
    "    for i in range(sliding_window):\n",
    "        cur_time = time + i + 1\n",
    "        if cur_time not in trajectory.timeframe_set:\n",
    "            # print(\"next time not in trajectory.timeframe_set\")\n",
    "            break\n",
    "        next_sc = trajectory[cur_time]\n",
    "        next_label_mask = next_sc.get_mask_crop(bbox=cur_bbox, dtype=int)\n",
    "\n",
    "        print(\"sc at time:\", cur_time)\n",
    "        next_sc.show_panel(padding=50)\n",
    "        # plt.savefig(fig_out_dir / f\"{track_id}_{time}_{next_time}_second.png\")\n",
    "\n",
    "        viz_ou_sc_outputs(\n",
    "            next_sc,\n",
    "            model,\n",
    "            transforms=input_transforms,\n",
    "            save_path=fig_out_dir / f\"{track_id}_{time}_{cur_time}_second_csn.png\",\n",
    "            show=True,\n",
    "            remove_bg=remove_bg,\n",
    "            padding_pixels=padding_pixels,\n",
    "            out_threshold=out_threshold,\n",
    "        )\n",
    "\n",
    "\n",
    "# for _ in range(10):\n",
    "#     rand_idx = np.random.randint(len(conflict_track_id_and_time_pairs))\n",
    "#     viz_conflict_track(rand_idx, conflict_track_id_and_time_pairs, sliding_window=1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from livecellx.segment.ou_utils import create_ou_input_from_sc\n",
    "from livecellx.segment.ou_viz import viz_ou_outputs\n",
    "\n",
    "\n",
    "def compute_underseg_percents_by_csn_consensus(\n",
    "    sc: SingleCellStatic,\n",
    "    trajectory: SingleCellTrajectory,\n",
    "    csn_model: CorrectSegNet,\n",
    "    show=False,\n",
    "    sliding_window=10,\n",
    "    out_threshold=0.9,\n",
    "    one_object=True,\n",
    "    remove_bg=False,\n",
    "    padding_pixels=50,\n",
    "    save_dir=None,\n",
    "    path_prefix=\"\",\n",
    "):\n",
    "    def get_cell_num_by_csn(some_sc):\n",
    "        ou_input = create_ou_input_from_sc(\n",
    "            some_sc, padding_pixels=padding_pixels, dtype=int, remove_bg=remove_bg, one_object=one_object, scale=0\n",
    "        )\n",
    "        if save_dir:\n",
    "            save_path = Path(save_dir) / (path_prefix + f\"_{trajectory.track_id}_{some_sc.timeframe}_csn.png\")\n",
    "        else:\n",
    "            save_path = None\n",
    "        output, watershed_mask = viz_ou_outputs(\n",
    "            ou_input,\n",
    "            some_sc.get_sc_mask(),\n",
    "            csn_model,\n",
    "            input_transforms,\n",
    "            out_threshold=out_threshold,\n",
    "            show=show,\n",
    "            original_img=some_sc.get_img_crop(padding=50),\n",
    "            save_path=save_path,\n",
    "        )\n",
    "        output = output > out_threshold\n",
    "        output = output[0, 0].cpu().numpy()\n",
    "        num_cells_threshold = measure.label(output, connectivity=1)\n",
    "        num_cells_threshold = len(np.unique(num_cells_threshold)) - 1\n",
    "        num_cells_watershed = len(np.unique(watershed_mask)) - 1\n",
    "        return num_cells_threshold, num_cells_watershed\n",
    "\n",
    "    num_cells_threshold, num_cells_watershed = get_cell_num_by_csn(sc)\n",
    "    cur_time = sc.timeframe\n",
    "\n",
    "    watershed_nums = []\n",
    "    threshold_nums = []\n",
    "    for i in range(sliding_window):\n",
    "        cur_time = trajectory.next_time(cur_time)\n",
    "        if cur_time is None:\n",
    "            # print(\"next time not in trajectory.timeframe_set\")\n",
    "            break\n",
    "        cur_sc = trajectory[cur_time]\n",
    "        cur_num_cells_threshold, cur_num_cells_watershed = get_cell_num_by_csn(cur_sc)\n",
    "        watershed_nums.append(cur_num_cells_watershed)\n",
    "        threshold_nums.append(cur_num_cells_threshold)\n",
    "\n",
    "    watershed_nums = np.array(watershed_nums)\n",
    "    threshold_nums = np.array(threshold_nums)\n",
    "\n",
    "    underseg_counts_watershed = np.sum(watershed_nums > num_cells_watershed)\n",
    "    underseg_counts_threshold = np.sum(threshold_nums > num_cells_threshold)\n",
    "\n",
    "    underseg_counts_watershed_percent = underseg_counts_watershed / sliding_window\n",
    "    underseg_counts_threshold_percent = underseg_counts_threshold / sliding_window\n",
    "    return underseg_counts_watershed_percent, underseg_counts_threshold_percent\n",
    "\n",
    "\n",
    "def compute_underseg_percents_by_csn_consensus_wrapper(inputs):\n",
    "    underseg_counts_watershed_percent, underseg_counts_threshold_percent = compute_underseg_percents_by_csn_consensus(\n",
    "        sc, trajectory, model, show=False, sliding_window=10\n",
    "    )\n",
    "    if underseg_counts_watershed_percent >= 0.4:\n",
    "        compute_underseg_percents_by_csn_consensus(\n",
    "            inputs[0],\n",
    "            inputs[1],\n",
    "            inputs[2],\n",
    "            sliding_window=inputs[3],\n",
    "            save_dir=Path(\"csn_underseg_percent_inconsistent_cells\"),\n",
    "            show=False,\n",
    "        )\n",
    "\n",
    "\n",
    "track_ids = traj_collection.get_track_ids()\n",
    "inputs = []\n",
    "# for _ in range(100):\n",
    "    # rand_track_id = np.random.choice(track_ids)\n",
    "    # trajectory = traj_collection[rand_track_id]\n",
    "case_id = 0\n",
    "for track_id, trajectory in traj_collection:\n",
    "    for time in trajectory.timeframe_set:\n",
    "        sc = trajectory[time]\n",
    "        (\n",
    "            underseg_counts_watershed_percent,\n",
    "            underseg_counts_threshold_percent,\n",
    "        ) = compute_underseg_percents_by_csn_consensus(sc, trajectory, model, show=False, sliding_window=10)\n",
    "\n",
    "        if underseg_counts_watershed_percent >= 0.4:\n",
    "            print(\n",
    "                \"time:\",\n",
    "                time,\n",
    "                \"underseg_counts_watershed_percent, underseg_counts_threshold_percent:\",\n",
    "                underseg_counts_watershed_percent,\n",
    "                underseg_counts_threshold_percent,\n",
    "            )\n",
    "            case_id += 1\n",
    "            compute_underseg_percents_by_csn_consensus(\n",
    "                sc,\n",
    "                trajectory,\n",
    "                model,\n",
    "                sliding_window=10,\n",
    "                save_dir=Path(\"csn_underseg_percent_inconsistent_cells\"),\n",
    "                show=False,\n",
    "                path_prefix=f\"case-{case_id}\",\n",
    "            )\n",
    "        inputs.append([sc, trajectory, model, 10])\n",
    "\n",
    "# parallelize(compute_underseg_percents_by_csn_consensus_wrapper, inputs) # failure\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d9c7226d793827cd27273ad20fbb4775c3cb91053ab9378a09de5f8c6f258919"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
