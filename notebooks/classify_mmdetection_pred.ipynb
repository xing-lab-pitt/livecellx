{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from cellpose import models\n",
    "from cellpose.io import imread\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from PIL import Image, ImageSequence\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import os.path\n",
    "# from livecell_tracker import segment\n",
    "from livecell_tracker import core\n",
    "from livecell_tracker.core import datasets\n",
    "from livecell_tracker.core.datasets import LiveCellImageDataset, SingleImageDataset\n",
    "from skimage import measure\n",
    "from livecell_tracker.core import SingleCellTrajectory, SingleCellStatic\n",
    "# import detectron2\n",
    "# from detectron2.utils.logger import setup_logger\n",
    "\n",
    "# setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "import cv2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate single cells from a mask dataset and write single cell json data to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = \"XY1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# dataset_dir_path = Path(\n",
    "#     f\"../datasets/EBSS_Starvation/tif_STAV-A549_VIM_24hours_NoTreat_NA_YL_Ti2e_2022-12-21/{pos}/\"\n",
    "# )\n",
    "\n",
    "# mask_dataset_path = Path(f\"../datasets/EBSS_Starvation/tif_STAV-A549_VIM_24hours_NoTreat_NA_YL_Ti2e_2022-12-21/out/{pos}/seg\")\n",
    "\n",
    "# mask_dataset = LiveCellImageDataset(mask_dataset_path, ext=\"png\")\n",
    "# time2url = sorted(glob.glob(str((Path(dataset_dir_path) / Path(\"*_DIC.tif\")))))\n",
    "# time2url = {i: path for i, path in enumerate(time2url)}\n",
    "# dic_dataset = LiveCellImageDataset(time2url=time2url, ext=\"tif\")\n",
    "\n",
    "# from livecell_tracker.segment.utils import prep_scs_from_mask_dataset\n",
    "# single_cells = prep_scs_from_mask_dataset(mask_dataset, dic_dataset)\n",
    "\n",
    "# scs_write_path = f\"./datasets/test_scs_EBSS_starvation/{pos}/scs.json\"\n",
    "# dataset_dir = Path(f\"./datasets/test_scs_EBSS_starvation/{pos}/datasets\")\n",
    "# SingleCellStatic.write_single_cells_json(single_cells, scs_write_path, dataset_dir=dataset_dir)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read single cell object data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from livecell_tracker.core.single_cell import SingleCellTrajectoryCollection, SingleCellStatic\n",
    "from livecell_tracker.track.sort_tracker_utils import (\n",
    "    track_SORT_bbox_from_scs\n",
    ")\n",
    "\n",
    "# all_scs_json_path = \"./datasets/test_scs_EBSS_starvation/tmp_corrected_scs.json\"\n",
    "all_scs_json_path = f\"./datasets/test_scs_EBSS_starvation/{pos}/scs.json\"\n",
    "all_scs = SingleCellStatic.load_single_cells_json(all_scs_json_path)\n",
    "sctc = track_SORT_bbox_from_scs(all_scs, raw_imgs=all_scs[0].img_dataset, min_hits=3, max_age=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_dataset = all_scs[0].img_dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read trained an MMAction model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "model_dir = Path(r\"./scripts/mmdetection_classify/work_dirs/tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb-v6-combined-clipL=2/\")\n",
    "# path = r\"./scripts/mmdetection_classify/work_dirs/tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb-v6-combined-clipL=2/best_acc_top1_epoch_28.pth\"\n",
    "# model = torch.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmengine.config import Config, DictAction\n",
    "from mmaction.registry import MODELS\n",
    "config_file = str(model_dir / \"tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb.py\")\n",
    "checkpoint_file = str(model_dir / \"best_acc_top1_epoch_28.pth\")\n",
    "cfg = Config.fromfile(config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = MODELS.build()\n",
    "import mmcv\n",
    "from mmaction.apis import init_recognizer, inference_recognizer\n",
    "model = init_recognizer(config_file, checkpoint_file, device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmcv.video.io import VideoReader\n",
    "import tempfile\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from livecell_tracker.track.classify_utils import video_frames_and_masks_from_sample, combine_video_frames_and_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = sctc.get_all_trajectories()[11].get_all_scs()\n",
    "\n",
    "def gen_sc_frames(sample):\n",
    "    print(\"length of sample:\", len(sample))\n",
    "    frames, frame_masks = video_frames_and_masks_from_sample(sample)\n",
    "    combined_frames = combine_video_frames_and_masks(frames, frame_masks)\n",
    "    sct_input_frames = [np.array(frame) for frame in combined_frames]\n",
    "    return sct_input_frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sct_input_frames = gen_sc_frames(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import uuid\n",
    "# video = r\"D:\\LiveCellTracker-dev\\notebooks\\notebook_results\\mmaction_train_data\\videos\\mitosis_1_mask.mp4\"\n",
    "# video = r\"D:\\LiveCellTracker-dev\\notebooks\\notebook_results\\mmaction_train_data\\videos\\normal_6.mp4\"\n",
    "# input_frames = sct_input_frames[:5]\n",
    "\n",
    "def predict_on_frame_windows(model, frames, window_size=5, step_size=1, fps = 1):\n",
    "    frame_windows = []\n",
    "    for i in range(0, len(frames), step_size):\n",
    "        if i + window_size > len(frames):\n",
    "            break\n",
    "        frame_window = frames[i:i+window_size]\n",
    "        frame_windows.append(frame_window)\n",
    "    results = []\n",
    "    for frame_window in frame_windows:\n",
    "        results.append(predict_on_frames(model, frame_window, fps))\n",
    "    return results\n",
    "\n",
    "def predict_on_frames(model, input_frames, fps, tmp_dir = \"./tmp_video\"):\n",
    "    os.makedirs(tmp_dir, exist_ok=True)\n",
    "    tmp_id = uuid.uuid4()\n",
    "    input_tmp_filename = os.path.join(tmp_dir, f\"tmp-{tmp_id}.mp4\")\n",
    "\n",
    "    def save_frames(frames, filename):\n",
    "        with open(filename, \"wb+\") as tmp_video_file:\n",
    "            # mmcv.frames2video(frames, tmp_video_file.name, fps=1)\n",
    "            fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "            # Create a VideoWriter object to write the frames to the output file\n",
    "            height, width, channels = frames[0].shape\n",
    "            video_writer = cv2.VideoWriter(tmp_video_file.name, fourcc, fps, (width, height))\n",
    "\n",
    "            # Write the frames to the output file\n",
    "            for frame in frames:\n",
    "                video_writer.write(frame)\n",
    "            video_writer.release()\n",
    "            tmp_video_file.flush()\n",
    "            return tmp_video_file\n",
    "        \n",
    "    tmp_video_file = save_frames(input_frames, input_tmp_filename)\n",
    "    results = inference_recognizer(model, tmp_video_file.name)\n",
    "    predicted_label = results.pred_labels.item.cpu().numpy()[0]\n",
    "    new_filename = os.path.join(tmp_dir, f\"label-{predicted_label}-tmp-{tmp_id}.mp4\")\n",
    "\n",
    "    # convert the first channel in input_frames to RGB and save the video\n",
    "    input_frames = np.array(input_frames)\n",
    "    input_frames_rgb = [cv2.cvtColor(frame, cv2.COLOR_GRAY2RGB) for frame in input_frames[..., 0]]\n",
    "    raw_frame_video_filename = os.path.join(tmp_dir, f\"label-{predicted_label}-tmp-{tmp_id}-raw.mp4\")\n",
    "    save_frames(input_frames_rgb, raw_frame_video_filename)\n",
    "\n",
    "    # move file to new filename\n",
    "    os.rename(input_tmp_filename, new_filename)\n",
    "    return predicted_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = predict_on_frame_windows(model, sct_input_frames, window_size=20, step_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on sctc samples\n",
    "from tqdm import tqdm\n",
    "def predict_on_sctc_samples(model, sctc, window_size=5, step_size=1, fps = 1):\n",
    "    all_samples_results = {}\n",
    "    for track_id, trajectory in tqdm(sctc):\n",
    "        sample = trajectory.get_all_scs()\n",
    "        sct_input_frames = gen_sc_frames(sample)\n",
    "        sample_results = predict_on_frame_windows(model, sct_input_frames, window_size=window_size, step_size=step_size, fps=fps)\n",
    "        if 0 in sample_results:\n",
    "            print(\"track_id:\", track_id, \"contains mitosis\")\n",
    "        all_samples_results[track_id] = sample_results\n",
    "    return all_samples_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r ./tmp_video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_id_to_sample_results = predict_on_sctc_samples(model, sctc, window_size=10, step_size=5, fps=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize mitosis cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from livecell_tracker.core.sct_operator import create_scts_operator_viewer\n",
    "\n",
    "# mitosis_tids = [7, 4, 1, 16] # EBSS less than 24h, xy1\n",
    "mitosis_tids = [tid for tid in track_id_to_sample_results if 0 in track_id_to_sample_results[tid]]\n",
    "mitosis_tids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from livecell_tracker.core.sct_operator import create_scts_operator_viewer, create_scs_edit_viewer\n",
    "\n",
    "# scts_operator = create_scs_edit_viewer(single_cells, img_dataset = dic_dataset, time_span=(145, 155))\n",
    "# # If you would like to start from sctc, you can use the following code\n",
    "# scts_operator = create_scts_operator_viewer(sctc, img_dataset = dic_dataset) #, time_span=(1, 2))\n",
    "# scts_operator = create_scts_operator_viewer(sctc.subset(mitosis_tids), img_dataset = dic_dataset) #, time_span=(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = inference_recognizer(model, r\"D:\\LiveCellTracker-dev\\notebooks\\notebook_results\\mmaction_train_data_v5\\videos\\mitosis_2_combined_padding-40.mp4\")\n",
    "# results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "video_dir = r\"./notebook_results/mmaction_train_data_v5/videos\"\n",
    "\n",
    "mmaction_data_tsv = r\"./notebook_results/mmaction_train_data_v6/test_data_combined.txt\"\n",
    "\n",
    "# df columns are path and label\n",
    "mmaction_data_df = pd.read_csv(mmaction_data_tsv, sep=\" \", header=None)\n",
    "mmaction_data_df.columns = [\"path\", \"label\"]\n",
    "mmaction_data_df[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "# test on all video in the df\n",
    "for i, row in tqdm(mmaction_data_df.iterrows()):\n",
    "    video_path = os.path.join(video_dir, row[\"path\"])\n",
    "    results = inference_recognizer(model, video_path)\n",
    "    predicted_label = results.pred_labels.item.cpu().numpy()[0]\n",
    "    if predicted_label != row[\"label\"]:\n",
    "        print(\"wrong prediction:\", row[\"path\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "livecell-work",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
