{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import TQDMProgressBar\n",
    "\n",
    "from livecell_tracker.model_zoo.segmentation.sc_correction import CorrectSegNet\n",
    "import numpy as np\n",
    "torch.manual_seed(237)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available(), torch.cuda.current_device(), torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import TQDMProgressBar\n",
    "\n",
    "from livecell_tracker.model_zoo.segmentation.sc_correction import CorrectSegNet\n",
    "from livecell_tracker.model_zoo.segmentation.sc_correction_dataset import CorrectSegNetDataset\n",
    "torch.manual_seed(237)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "train_dir = Path(\"./notebook_results/a549_ccp_vim/train_data_v4/\")\n",
    "test_dir = Path(\"./notebook_results/a549_ccp_vim/test_data_v4/\")\n",
    "\n",
    "train_csv = train_dir / \"train_data.csv\"\n",
    "train_df = pd.read_csv(train_csv)\n",
    "test_df = pd.read_csv(test_dir / \"train_data.csv\")\n",
    "train_df[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assemble_dataset(df: pd.DataFrame):\n",
    "    raw_img_paths = list(df[\"raw\"])\n",
    "    scaled_seg_mask_paths = list(df[\"seg\"])\n",
    "    gt_mask_paths = list(df[\"gt\"])\n",
    "    raw_seg_paths = list(df[\"raw_seg\"])\n",
    "    scales = list(df[\"scale\"])\n",
    "    aug_diff_img_paths = list(df[\"aug_diff_mask\"])\n",
    "    raw_transformed_img_paths = list(df[\"raw_transformed_img\"])\n",
    "\n",
    "    split_seed = 237\n",
    "\n",
    "    dataset = CorrectSegNetDataset(\n",
    "        raw_img_paths,\n",
    "        scaled_seg_mask_paths,\n",
    "        gt_mask_paths,\n",
    "        raw_seg_paths=raw_seg_paths,\n",
    "        scales=scales,\n",
    "        transform=None,\n",
    "        raw_transformed_img_paths=raw_transformed_img_paths,\n",
    "        aug_diff_img_paths=aug_diff_img_paths,\n",
    "    )\n",
    "    return dataset\n",
    "\n",
    "split_seed = 237\n",
    "dataset = assemble_dataset(train_df)\n",
    "train_sample_num = int(len(dataset) * 0.8)\n",
    "val_sample_num = len(dataset) - train_sample_num\n",
    "split_generator = torch.Generator().manual_seed(split_seed)\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(\n",
    "    dataset, [train_sample_num, val_sample_num], generator=split_generator\n",
    ")\n",
    "\n",
    "test_dataset = assemble_dataset(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate\n",
    "\n",
    "Three cases:\n",
    "correct segmentation case\n",
    "oversegmentatin\n",
    "undersegmentation\n",
    "Can one mdoel correct three cases?\n",
    "E.g. correct single cell mask ---model---> correct mask as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ckpt = \"/home/ke/LiveCellTracker-dev/notebooks/lightning_logs/version_68/checkpoints/epoch=197-step=44352.ckpt\"\n",
    "# ckpt = \"/home/ke/LiveCellTracker-dev/notebooks/lightning_logs/version_67/checkpoints/epoch=440-step=98784.ckpt\"\n",
    "# ckpt = \"/home/ke/LiveCellTracker-dev/notebooks/lightning_logs/version_67/epoch=499-step=112000.ckpt\"\n",
    "\n",
    "# # model 70 v0\n",
    "# ckpt = r\"/home/ke/LiveCellTracker-dev/notebooks/lightning_logs/version_70/checkpoints/epoch=999-step=224000.ckpt\"\n",
    "# # model 70 v1\n",
    "# ckpt = r\"/home/ke/LiveCellTracker-dev/notebooks/lightning_logs/version_70/checkpoints/epoch=999-step=224000-v1.ckpt\"\n",
    "# ckpt = r\"/home/ke/LiveCellTracker-dev/notebooks/lightning_logs/version_71/checkpoints/epoch=999-step=224000.ckpt\"\n",
    "# # model 73\n",
    "# ckpt = r\"/home/ke/LiveCellTracker-dev/notebooks/lightning_logs/version_73/epoch=421-step=94528.ckpt\"\n",
    "\n",
    "# # model 76\n",
    "ckpt = r\"/home/ken67/LiveCellTracker-dev/notebooks/lightning_logs/version_76/checkpoints/epoch=769-step=172480.ckpt\"\n",
    "\n",
    "model = CorrectSegNet.load_from_checkpoint(ckpt)\n",
    "# model.load_state_dict(torch.load(ckpt)[\"state_dict\"])\n",
    "model.cuda();\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from livecell_tracker.model_zoo.segmentation.sc_correction_dataset import CorrectSegNetDataset\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def evaluate_sample_v3_underseg(sample: dict, model:CorrectSegNet, raw_seg=None, scale=None, out_threshold=0.6):\n",
    "    out_mask = model(sample[\"input\"].unsqueeze(0).cuda())\n",
    "    original_input_mask = sample[\"input\"].numpy().squeeze()[2]\n",
    "    original_input_mask = original_input_mask.astype(bool)\n",
    "    gt_mask = sample[\"gt_mask\"].numpy().squeeze()\n",
    "    gt_seg_mask = gt_mask[0, :].astype(bool)\n",
    "    assert set(np.unique(gt_seg_mask).tolist()) == set([0, 1])\n",
    "\n",
    "    out_mask = out_mask[0].cpu().detach().numpy()\n",
    "    combined_over_under_seg = np.zeros([3] + list(out_mask.shape[1:]))\n",
    "    combined_over_under_seg[0, out_mask[1, :] > out_threshold] = 1\n",
    "    combined_over_under_seg[1, out_mask[2, :] > out_threshold] = 1\n",
    "\n",
    "    # ignore pixels outside an area, only works for undersegmentation\n",
    "    out_mask_predicted[original_input_mask < 0.5] = 0\n",
    "    out_mask_predicted = out_mask_predicted.astype(bool)\n",
    "\n",
    "    metrics_dict = {}\n",
    "    metrics_dict[\"out_mask_accuracy\"] = (out_mask_predicted == gt_seg_mask).sum() / np.prod(out_mask_predicted.shape)\n",
    "    metrics_dict[\"original_mask_accuracy\"] = (original_input_mask == gt_seg_mask).sum() / np.prod(out_mask_predicted.shape)\n",
    "    metrics_dict[\"out_mask_iou\"] = (out_mask_predicted & gt_seg_mask).sum() / (out_mask_predicted | gt_seg_mask).sum()\n",
    "    metrics_dict[\"original_mask_iou\"] = (original_input_mask & gt_seg_mask).sum() / (original_input_mask | gt_seg_mask).sum()\n",
    "    return metrics_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_THRESHOLD = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate on training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "train_metrics = {}\n",
    "for i, sample in enumerate(tqdm.tqdm((train_dataset))):\n",
    "    # print(sample.keys())\n",
    "    single_sample_metrics = evaluate_sample_v3_underseg(sample, model, out_threshold=OUT_THRESHOLD)\n",
    "    for metric, value in single_sample_metrics.items():\n",
    "        if metric not in train_metrics:\n",
    "            train_metrics[metric] = []\n",
    "        train_metrics[metric].append(value)\n",
    "\n",
    "for key in train_metrics:\n",
    "    train_metrics[key] = np.array(train_metrics[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metrics.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "data = {\n",
    "    \"csn\" : train_metrics[\"out_mask_accuracy\"],\n",
    "    \"original\" : train_metrics[\"original_mask_accuracy\"],\n",
    "}\n",
    "print(\"csn mean:\", np.mean(data[\"csn\"]))\n",
    "print(\"csn std:\", np.std(data[\"csn\"]))\n",
    "print(\"original mean:\", np.mean(data[\"original\"]))\n",
    "print(\"original std:\", np.std(data[\"original\"]))\n",
    "bins = 20\n",
    "plt.hist(data[\"csn\"], bins=bins, alpha=0.5, label=\"csn\", edgecolor='black', linewidth=1)\n",
    "plt.hist(data[\"original\"], bins=bins, alpha=0.5, label=\"original\", edgecolor='black', linewidth=1)\n",
    "plt.title(\"Pixel Accuracy Per Single Cell Image\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"csn\" : train_metrics[\"out_mask_iou\"],\n",
    "    \"original\" : train_metrics[\"original_mask_iou\"],\n",
    "}\n",
    "print(\"csn mean:\", np.mean(data[\"csn\"]))\n",
    "print(\"csn std:\", np.std(data[\"csn\"]))\n",
    "print(\"original mean:\", np.mean(data[\"original\"]))\n",
    "print(\"original std:\", np.std(data[\"original\"]))\n",
    "bins = 20\n",
    "plt.hist(data[\"csn\"], bins=bins, alpha=0.5, label=\"csn\", edgecolor='black', linewidth=1)\n",
    "plt.hist(data[\"original\"], bins=bins, alpha=0.5, label=\"original\", edgecolor='black', linewidth=1)\n",
    "plt.title(\"IOU comparison Per Single Cell Image\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "test_metrics = {}\n",
    "for i, sample in tqdm.tqdm(enumerate(test_dataset)):\n",
    "    # print(sample.keys())\n",
    "    single_sample_metrics = evaluate_sample_v3_underseg(sample, model, out_threshold=OUT_THRESHOLD)\n",
    "    for metric, value in single_sample_metrics.items():\n",
    "        if metric not in test_metrics:\n",
    "            test_metrics[metric] = []\n",
    "        test_metrics[metric].append(value)\n",
    "\n",
    "for key in test_metrics:\n",
    "    test_metrics[key] = np.array(test_metrics[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "data = {\n",
    "    \"csn\" : test_metrics[\"out_mask_accuracy\"],\n",
    "    \"original\" : test_metrics[\"original_mask_accuracy\"],\n",
    "}\n",
    "print(\"csn mean:\", np.mean(data[\"csn\"]))\n",
    "print(\"csn std:\", np.std(data[\"csn\"]))\n",
    "print(\"original mean:\", np.mean(data[\"original\"]))\n",
    "print(\"original std:\", np.std(data[\"original\"]))\n",
    "bins = 20\n",
    "plt.hist(data[\"csn\"], bins=bins, alpha=0.5, label=\"csn\", edgecolor='black', linewidth=1)\n",
    "plt.hist(data[\"original\"], bins=bins, alpha=0.5, label=\"original\", edgecolor='black', linewidth=1)\n",
    "plt.title(\"Pixel Accuracy Per Single Cell Image\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"csn\" : test_metrics[\"out_mask_iou\"],\n",
    "    \"original\" : test_metrics[\"original_mask_iou\"],\n",
    "}\n",
    "print(\"csn mean:\", np.mean(data[\"csn\"]))\n",
    "print(\"csn std:\", np.std(data[\"csn\"]))\n",
    "print(\"original mean:\", np.mean(data[\"original\"]))\n",
    "print(\"original std:\", np.std(data[\"original\"]))\n",
    "bins = 20\n",
    "plt.hist(data[\"csn\"], bins=bins, alpha=0.5, label=\"csn\", edgecolor='black', linewidth=1)\n",
    "plt.hist(data[\"original\"], bins=bins, alpha=0.5, label=\"original\", edgecolor='black', linewidth=1)\n",
    "plt.title(\"IOU comparison Per Single Cell Image\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_sample_result(idx, model, dataset: CorrectSegNetDataset):\n",
    "    sample = dataset[idx]\n",
    "    check_sample_v1(sample, model, raw_seg=dataset.get_raw_seg(idx), scale=dataset.get_scale(idx))\n",
    "\n",
    "\n",
    "def check_sample_v1(sample: dict, model, raw_seg=None, scale=None):\n",
    "    out_mask = model(sample[\"input\"].unsqueeze(0).cuda())\n",
    "    out_mask = out_mask[0].argmax(0).cpu().numpy()\n",
    "    fig, axes = plt.subplots(1, 5, figsize=(25, 5))\n",
    "    axes[0].imshow(sample[\"input\"][0])\n",
    "    axes[0].set_title(\"raw\")\n",
    "\n",
    "    axes[1].imshow(sample[\"input\"][1])\n",
    "    axes[1].set_title(\"augmented seg, scale: {:.2f}\".format(scale if scale is not None else float(\"inf\")))\n",
    "\n",
    "    axes[2].imshow(out_mask)\n",
    "    axes[2].set_title(\"predicted seg\")\n",
    "\n",
    "    axes[3].imshow(sample[\"gt_mask\"].numpy().squeeze())\n",
    "    axes[3].set_title(\"gt seg\")\n",
    "\n",
    "    if raw_seg is not None:\n",
    "        axes[4].imshow(raw_seg)\n",
    "        axes[4].set_title(\"raw seg\")\n",
    "\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "def add_colorbar(im, ax, fig):\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes('right', size='3%', pad=0.05)\n",
    "    fig.colorbar(im, cax=cax, orientation='vertical')\n",
    "\n",
    "def check_sample_v3(sample: dict, model, raw_seg=None, scale=None, out_threshold=OUT_THRESHOLD):\n",
    "    out_mask = model(sample[\"input\"].unsqueeze(0).cuda())\n",
    "    original_input_mask = sample[\"input\"].numpy().squeeze()[2]\n",
    "    original_input_mask = original_input_mask.astype(bool)\n",
    "\n",
    "    gt_mask = sample[\"gt_mask\"].numpy().squeeze()\n",
    "    out_mask = out_mask[0].cpu().detach().numpy()\n",
    "    fig, axes = plt.subplots(1, 11, figsize=(80, 6))\n",
    "    axes[0].imshow(sample[\"input\"][0])\n",
    "    axes[0].set_title(\"raw\")\n",
    "\n",
    "    axes[1].imshow(sample[\"input\"][1])\n",
    "    axes[1].set_title(\"augmented seg, scale: {:.2f}\".format(scale if scale is not None else float(\"inf\")))\n",
    "    im2 = axes[2].imshow(out_mask[0, :])\n",
    "    axes[2].set_title(\"out0seg\")\n",
    "    add_colorbar(im2, axes[2], fig)\n",
    "\n",
    "    axes[3].imshow(gt_mask[0, :])\n",
    "    axes[3].set_title(\"gt0 seg\")\n",
    "\n",
    "    im4 = axes[4].imshow(out_mask[1, :])\n",
    "    axes[4].set_title(\"out1seg\")\n",
    "    add_colorbar(im4, axes[4], fig)\n",
    "    \n",
    "    im5 = axes[5].imshow(gt_mask[1, :])\n",
    "    add_colorbar(im5, axes[5], fig)\n",
    "    axes[5].set_title(\"gt1 seg\")\n",
    "\n",
    "    im6 = axes[6].imshow(out_mask[2, :])\n",
    "    add_colorbar(im6, axes[6], fig)\n",
    "    axes[6].set_title(\"out2 seg\")\n",
    "\n",
    "    im7 = axes[7].imshow(gt_mask[2, :])\n",
    "    add_colorbar(im7, axes[7], fig)\n",
    "    axes[7].set_title(\"gt2 seg\")\n",
    "\n",
    "\n",
    "    combined_over_under_seg = np.zeros([3] + list(out_mask.shape[1:]))\n",
    "    combined_over_under_seg[0, out_mask[1, :] > out_threshold] = 1\n",
    "    combined_over_under_seg[1, out_mask[2, :] > out_threshold] = 1\n",
    "    im = axes[8].imshow(np.moveaxis(combined_over_under_seg, 0, 2))\n",
    "    axes[8].set_title(\"out(1,2), over/under seg combined\")\n",
    "\n",
    "    # import matplotlib.patches as mpatches\n",
    "    # values = [-1, 0, 1]\n",
    "    # colors = [im.cmap(im.norm(value)) for value in values]\n",
    "    # patches = [mpatches.Patch(color=colors[i], label=\"Level {l}\".format(l=values[i]) ) for i in range(len(values))]\n",
    "    # axes[8].legend(handles=patches, loc=2, borderaxespad=0. )\n",
    "   \n",
    "\n",
    "    axes[9].imshow(out_mask[0] > out_threshold)\n",
    "    axes[9].set_title(f\"out0 >{out_threshold} threshold\")\n",
    "\n",
    "\n",
    "    out_mask_predicted = out_mask[0] > out_threshold\n",
    "    # ignore pixels outside an area, only works for undersegmentation\n",
    "    out_mask_predicted[original_input_mask < 0.5] = 0\n",
    "    out_mask_predicted = out_mask_predicted.astype(bool)\n",
    "    axes[10].imshow(out_mask_predicted)\n",
    "    axes[10].set_title(f\"cleaned out mask prediction\")\n",
    "\n",
    "    # # visualize out specifically\n",
    "    # fig, axes = plt.subplots(1, 3, figsize=(25, 5))\n",
    "    # axes[0].imshow(out_mask[1] > out_threshold)\n",
    "    # axes[0].set_title(f\"out1 >{out_threshold} threshold\")\n",
    "    # axes[1].imshow(out_mask[2] > out_threshold)\n",
    "    # axes[1].set_title(f\"out2 >{out_threshold} threshold\")\n",
    "    \n",
    "    # combined_over_under_seg = np.zeros([3] + list(out_mask.shape[1:]))\n",
    "    # combined_over_under_seg[0, out_mask[1, :] > 2] = 1\n",
    "    # combined_over_under_seg[1, out_mask[2, :] > 2] = 1\n",
    "    # axes[2].imshow(np.moveaxis(combined_over_under_seg, 0, 2))\n",
    "    # axes[2].set_title(\"out(1,2), over/under seg combined\")\n",
    "\n",
    "    # print(\"g1 seg stats:\", gt_mask[1, :].mean(), gt_mask[1, :].std(), np.unique(gt_mask.flatten()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "for i, sample in enumerate(train_dataset):\n",
    "    # print(sample.keys())\n",
    "    check_sample_v3(sample, model, out_threshold=OUT_THRESHOLD)\n",
    "    if i > 50:\n",
    "        break\n",
    "warnings.filterwarnings(\"default\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation set\n",
    "```\n",
    "for i in range(len(model.val_dataset)):\n",
    "    sample = model.val_dataset[i]\n",
    "    check_sample_result(sample, model)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_sample = dataset[9]\n",
    "# plt.imshow(chosen_sample[\"input\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shift the cell to edge to check if the model only focuses on center area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shift_sample = {}\n",
    "shift_sample[\"input\"] = chosen_sample[\"input\"][:, :-150, :-150]\n",
    "# # for v1, single mask prediction\n",
    "# shift_sample[\"gt_mask\"] = chosen_sample[\"gt_mask\"][0, :-150, :-150]\n",
    "\n",
    "shift_sample[\"gt_mask\"] = chosen_sample[\"gt_mask\"][:, :-150, :-150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shift_sample[\"input\"].shape, shift_sample[\"gt_mask\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check_sample_v1(shift_sample, model)\n",
    "check_sample_v3(shift_sample, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shift_sample = {}\n",
    "shift_sample[\"input\"] = chosen_sample[\"input\"][:, :-100, :-100]\n",
    "shift_sample[\"gt_mask\"] = chosen_sample[\"gt_mask\"][:, :-100, :-100]\n",
    "check_sample_v3(shift_sample, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shift_sample = {}\n",
    "shift_sample[\"input\"] = chosen_sample[\"input\"][:, :-50, :-50]\n",
    "shift_sample[\"gt_mask\"] = chosen_sample[\"gt_mask\"][:, :-50, :-50]\n",
    "check_sample_v3(shift_sample, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shift_sample = {}\n",
    "shift_sample[\"input\"] = chosen_sample[\"input\"][:, :-10, :-10]\n",
    "shift_sample[\"gt_mask\"] = chosen_sample[\"gt_mask\"][:, :-10, :-10]\n",
    "check_sample_v3(shift_sample, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = assemble_dataset(test_df)\n",
    "for i, sample in enumerate(test_dataset):\n",
    "    # print(sample.keys())\n",
    "    check_sample_v3(sample, model, out_threshold=OUT_THRESHOLD)\n",
    "    if i > 50:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('livecell')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d9c7226d793827cd27273ad20fbb4775c3cb91053ab9378a09de5f8c6f258919"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
