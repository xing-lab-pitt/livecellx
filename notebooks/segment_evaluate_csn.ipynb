{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import TQDMProgressBar\n",
    "\n",
    "from livecell_tracker.model_zoo.segmentation.sc_correction import CorrectSegNet\n",
    "import numpy as np\n",
    "torch.manual_seed(237)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available(), torch.cuda.current_device(), torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import TQDMProgressBar\n",
    "\n",
    "from livecell_tracker.model_zoo.segmentation.sc_correction import CorrectSegNet\n",
    "from livecell_tracker.model_zoo.segmentation.sc_correction_dataset import CorrectSegNetDataset\n",
    "torch.manual_seed(237)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "# train_dir = Path(\"./notebook_results/a549_ccp_vim/train_data_v4/\")\n",
    "# test_dir = Path(\"./notebook_results/a549_ccp_vim/test_data_v4/\")\n",
    "train_dir = Path(\"./notebook_results/a549_ccp_vim/train_data_v5/\")\n",
    "test_dir = Path(\"./notebook_results/a549_ccp_vim/test_data_v5/\")\n",
    "\n",
    "train_csv = train_dir / \"train_data.csv\"\n",
    "train_df = pd.read_csv(train_csv)\n",
    "test_df = pd.read_csv(test_dir / \"train_data.csv\")\n",
    "train_df[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ckpt = \"/home/ke/LiveCellTracker-dev/notebooks/lightning_logs/version_68/checkpoints/epoch=197-step=44352.ckpt\"\n",
    "# ckpt = \"/home/ke/LiveCellTracker-dev/notebooks/lightning_logs/version_67/checkpoints/epoch=440-step=98784.ckpt\"\n",
    "# ckpt = \"/home/ke/LiveCellTracker-dev/notebooks/lightning_logs/version_67/epoch=499-step=112000.ckpt\"\n",
    "\n",
    "# # model 70 v0\n",
    "# ckpt = r\"/home/ke/LiveCellTracker-dev/notebooks/lightning_logs/version_70/checkpoints/epoch=999-step=224000.ckpt\"\n",
    "# # model 70 v1\n",
    "# ckpt = r\"/home/ke/LiveCellTracker-dev/notebooks/lightning_logs/version_70/checkpoints/epoch=999-step=224000-v1.ckpt\"\n",
    "# ckpt = r\"/home/ke/LiveCellTracker-dev/notebooks/lightning_logs/version_71/checkpoints/epoch=999-step=224000.ckpt\"\n",
    "# # model 73\n",
    "# ckpt = r\"/home/ken67/LiveCellTracker-dev/notebooks/lightning_logs/version_73/epoch=421-step=94528.ckpt\"\n",
    "\n",
    "# # model 76\n",
    "# ckpt = r\"/home/ken67/LiveCellTracker-dev/notebooks/lightning_logs/version_85/checkpoints/epoch=999-step=224000.ckpt\"\n",
    "ckpt = r\"/home/ken67/LiveCellTracker-dev/notebooks/lightning_logs/version_310/checkpoints/epoch=15-step=344384.ckpt\"\n",
    "\n",
    "model = CorrectSegNet.load_from_checkpoint(ckpt)\n",
    "# model.load_state_dict(torch.load(ckpt)[\"state_dict\"])\n",
    "model.cuda();\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from livecell_tracker.model_zoo.segmentation.eval_csn import assemble_dataset, assemble_train_test_dataset\n",
    "\n",
    "# split_seed = 237\n",
    "# dataset = assemble_dataset(train_df, apply_gt_seg_edt = model.apply_gt_seg_edt, exclude_raw_input_bg=model.exclude_raw_input_bg, input_type=model.input_type)\n",
    "# train_sample_num = int(len(dataset) * 0.8)\n",
    "# val_sample_num = len(dataset) - train_sample_num\n",
    "# split_generator = torch.Generator().manual_seed(split_seed)\n",
    "# train_dataset, val_dataset = torch.utils.data.random_split(\n",
    "#     dataset, [train_sample_num, val_sample_num], generator=split_generator\n",
    "# )\n",
    "\n",
    "# test_dataset = assemble_dataset(test_df, apply_gt_seg_edt = model.apply_gt_seg_edt, exclude_raw_input_bg=model.exclude_raw_input_bg, input_type=model.input_type)\n",
    "train_dataset, val_dataset, test_dataset, dataset = assemble_train_test_dataset(train_df, test_df, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OUT_THRESHOLD = 1\n",
    "OUT_THRESHOLD = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate\n",
    "\n",
    "Three cases:\n",
    "correct segmentation case\n",
    "oversegmentatin\n",
    "undersegmentation\n",
    "Can one mdoel correct three cases?\n",
    "E.g. correct single cell mask ---model---> correct mask as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from livecell_tracker.model_zoo.segmentation.sc_correction_dataset import CorrectSegNetDataset\n",
    "from livecell_tracker.model_zoo.segmentation.eval_csn import evaluate_sample_v3_underseg, match_label_mask_by_iou\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate metrics "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize one sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.measure\n",
    "import random\n",
    "out_threshold = OUT_THRESHOLD\n",
    "# idx = 0\n",
    "# randomly select an index\n",
    "idx = random.randint(0, len(train_dataset) - 1)\n",
    "sample = train_dataset[idx]\n",
    "origin_idx = train_dataset.indices[idx]\n",
    "gt_label_mask = dataset.get_gt_label_mask(origin_idx)\n",
    "original_input_mask = sample[\"seg_mask\"].numpy().squeeze()\n",
    "original_input_mask = original_input_mask.astype(bool)\n",
    "print(\"original_input_mask.shape\", original_input_mask.shape)\n",
    "\n",
    "out_mask = model(sample[\"input\"].unsqueeze(0).cuda())\n",
    "out_mask = out_mask[0].cpu().detach().numpy()\n",
    "print(\"out_mask shape\", out_mask.shape)\n",
    "out_mask_predicted = out_mask[0] > out_threshold\n",
    "# out_mask_predicted[original_input_mask < 0.5] = 0\n",
    "out_mask_predicted = out_mask_predicted.astype(bool)\n",
    "\n",
    "out_label_mask = skimage.measure.label(out_mask_predicted)\n",
    "\n",
    "fig, axes = plt.subplots(1, 5, figsize=(15, 5))\n",
    "ax = axes[0]\n",
    "ax.set_title(\"input\")\n",
    "ax.imshow(sample[\"input\"][0])\n",
    "ax = axes[1]\n",
    "ax.set_title(\"origin_seg_mask\")\n",
    "ax.imshow(sample[\"seg_mask\"])\n",
    "ax = axes[2]\n",
    "ax.set_title(\"out_mask_predicted\")\n",
    "ax.imshow(out_mask_predicted)\n",
    "ax = axes[3]\n",
    "ax.set_title(\"out_label_mask\")\n",
    "ax.imshow(out_label_mask)\n",
    "ax = axes[4]\n",
    "ax.set_title(\"gt_label_mask\")\n",
    "ax.imshow(gt_label_mask)\n",
    "\n",
    "match_label_mask_by_iou(out_label_mask, gt_label_mask, match_threshold=0.8)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On Testing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "test_metrics = {}\n",
    "for i, sample in tqdm.tqdm(enumerate(test_dataset)):\n",
    "    # print(sample.keys())\n",
    "    gt_label_mask = test_dataset.get_gt_label_mask(i)\n",
    "    single_sample_metrics = evaluate_sample_v3_underseg(sample, model, out_threshold=OUT_THRESHOLD, gt_label_mask=gt_label_mask)\n",
    "    \n",
    "\n",
    "    for metric, value in single_sample_metrics.items():\n",
    "        if metric not in test_metrics:\n",
    "            test_metrics[metric] = []\n",
    "        test_metrics[metric].append(value)\n",
    "\n",
    "for key in test_metrics:\n",
    "    test_metrics[key] = np.array(test_metrics[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "data = {\n",
    "    \"csn\" : test_metrics[\"out_mask_accuracy\"],\n",
    "    \"original\" : test_metrics[\"original_mask_accuracy\"],\n",
    "}\n",
    "print(\"csn mean:\", np.mean(data[\"csn\"]))\n",
    "print(\"csn std:\", np.std(data[\"csn\"]))\n",
    "print(\"original mean:\", np.mean(data[\"original\"]))\n",
    "print(\"original std:\", np.std(data[\"original\"]))\n",
    "bins = 20\n",
    "plt.hist(data[\"csn\"], bins=bins, alpha=0.5, label=\"csn\", edgecolor='black', linewidth=1)\n",
    "plt.hist(data[\"original\"], bins=bins, alpha=0.5, label=\"original\", edgecolor='black', linewidth=1)\n",
    "plt.title(\"Pixel Accuracy Per Single Cell Image\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"csn\" : test_metrics[\"out_mask_iou\"],\n",
    "    \"original\" : test_metrics[\"original_mask_iou\"],\n",
    "}\n",
    "print(\"csn mean:\", np.mean(data[\"csn\"]))\n",
    "print(\"csn std:\", np.std(data[\"csn\"]))\n",
    "print(\"original mean:\", np.mean(data[\"original\"]))\n",
    "print(\"original std:\", np.std(data[\"original\"]))\n",
    "bins = 20\n",
    "plt.hist(data[\"csn\"], bins=bins, alpha=0.5, label=\"csn\", edgecolor='black', linewidth=1)\n",
    "plt.hist(data[\"original\"], bins=bins, alpha=0.5, label=\"original\", edgecolor='black', linewidth=1)\n",
    "plt.title(\"IOU comparison Per Single Cell Image\")\n",
    "plt.legend()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the real underseg cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_underseg_test_df = test_df[test_df[\"subdir\"] == \"real_underseg_cases\"]\n",
    "print(len(real_underseg_test_df))\n",
    "real_underseg_test_df[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_underseg_test_dataset = assemble_dataset(\n",
    "        real_underseg_test_df,\n",
    "        apply_gt_seg_edt=model.apply_gt_seg_edt,\n",
    "        exclude_raw_input_bg=model.exclude_raw_input_bg,\n",
    "        input_type=model.input_type,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "underseg_test_metrics = {}\n",
    "for i, sample in enumerate(tqdm.tqdm(real_underseg_test_dataset)):\n",
    "    # print(sample.keys())\n",
    "    gt_label_mask = real_underseg_test_dataset.get_gt_label_mask(i)\n",
    "    single_sample_metrics = evaluate_sample_v3_underseg(sample, model, out_threshold=OUT_THRESHOLD, gt_label_mask=gt_label_mask)\n",
    "    for metric, value in single_sample_metrics.items():\n",
    "        if metric not in underseg_test_metrics:\n",
    "            underseg_test_metrics[metric] = []\n",
    "        underseg_test_metrics[metric].append(value)\n",
    "\n",
    "for key in underseg_test_metrics:\n",
    "    underseg_test_metrics[key] = np.array(underseg_test_metrics[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"csn\" : underseg_test_metrics[\"out_mask_accuracy\"],\n",
    "    \"original\" : underseg_test_metrics[\"original_mask_accuracy\"],\n",
    "}\n",
    "print(\"csn mean:\", np.mean(data[\"csn\"]))\n",
    "print(\"csn std:\", np.std(data[\"csn\"]))\n",
    "print(\"original mean:\", np.mean(data[\"original\"]))\n",
    "print(\"original std:\", np.std(data[\"original\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from livecell_tracker.model_zoo.segmentation.eval_csn import viz_sample_v3\n",
    "for i, sample in enumerate(real_underseg_test_dataset):\n",
    "    # print(sample.keys())\n",
    "    viz_sample_v3(sample, model, out_threshold=OUT_THRESHOLD)\n",
    "    if i > 10:\n",
    "        break\n",
    "warnings.filterwarnings(\"default\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate on training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "train_metrics = {}\n",
    "for i, sample in enumerate(tqdm.tqdm((train_dataset))):\n",
    "    # print(sample.keys())\n",
    "    origin_idx = train_dataset.indices[i]\n",
    "    gt_label_mask = dataset.get_gt_label_mask(origin_idx)\n",
    "    single_sample_metrics = evaluate_sample_v3_underseg(sample, model, out_threshold=OUT_THRESHOLD, gt_label_mask=gt_label_mask)\n",
    "    for metric, value in single_sample_metrics.items():\n",
    "        if metric not in train_metrics:\n",
    "            train_metrics[metric] = []\n",
    "        train_metrics[metric].append(value)\n",
    "\n",
    "for key in train_metrics:\n",
    "    train_metrics[key] = np.array(train_metrics[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "data = {\n",
    "    \"csn\" : train_metrics[\"out_mask_accuracy\"],\n",
    "    \"original\" : train_metrics[\"original_mask_accuracy\"],\n",
    "}\n",
    "print(\"csn mean:\", np.mean(data[\"csn\"]))\n",
    "print(\"csn std:\", np.std(data[\"csn\"]))\n",
    "print(\"original mean:\", np.mean(data[\"original\"]))\n",
    "print(\"original std:\", np.std(data[\"original\"]))\n",
    "bins = 20\n",
    "plt.hist(data[\"csn\"], bins=bins, alpha=0.5, label=\"csn\", edgecolor='black', linewidth=1)\n",
    "plt.hist(data[\"original\"], bins=bins, alpha=0.5, label=\"original\", edgecolor='black', linewidth=1)\n",
    "plt.title(\"Pixel Accuracy Per Single Cell Image\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"csn\" : train_metrics[\"out_mask_iou\"],\n",
    "    \"original\" : train_metrics[\"original_mask_iou\"],\n",
    "}\n",
    "print(\"csn mean:\", np.mean(data[\"csn\"]))\n",
    "print(\"csn std:\", np.std(data[\"csn\"]))\n",
    "print(\"original mean:\", np.mean(data[\"original\"]))\n",
    "print(\"original std:\", np.std(data[\"original\"]))\n",
    "bins = 20\n",
    "plt.hist(data[\"csn\"], bins=bins, alpha=0.5, label=\"csn\", edgecolor='black', linewidth=1)\n",
    "plt.hist(data[\"original\"], bins=bins, alpha=0.5, label=\"original\", edgecolor='black', linewidth=1)\n",
    "plt.title(\"IOU comparison Per Single Cell Image\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_sample_result(idx, model, dataset: CorrectSegNetDataset):\n",
    "    sample = dataset[idx]\n",
    "    check_sample_v1(sample, model, raw_seg=dataset.get_raw_seg(idx), scale=dataset.get_scale(idx))\n",
    "\n",
    "\n",
    "def check_sample_v1(sample: dict, model, raw_seg=None, scale=None):\n",
    "    out_mask = model(sample[\"input\"].unsqueeze(0).cuda())\n",
    "    out_mask = out_mask[0].argmax(0).cpu().numpy()\n",
    "    fig, axes = plt.subplots(1, 5, figsize=(25, 5))\n",
    "    axes[0].imshow(sample[\"input\"][0])\n",
    "    axes[0].set_title(\"raw\")\n",
    "\n",
    "    axes[1].imshow(sample[\"input\"][1])\n",
    "    axes[1].set_title(\"augmented seg, scale: {:.2f}\".format(scale if scale is not None else float(\"inf\")))\n",
    "\n",
    "    axes[2].imshow(out_mask)\n",
    "    axes[2].set_title(\"predicted seg\")\n",
    "\n",
    "    axes[3].imshow(sample[\"gt_mask\"].numpy().squeeze())\n",
    "    axes[3].set_title(\"gt seg\")\n",
    "\n",
    "    if raw_seg is not None:\n",
    "        axes[4].imshow(raw_seg)\n",
    "        axes[4].set_title(\"raw seg\")\n",
    "\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "def add_colorbar(im, ax, fig):\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes('right', size='3%', pad=0.05)\n",
    "    fig.colorbar(im, cax=cax, orientation='vertical')\n",
    "\n",
    "def check_sample_v3(sample: dict, model, raw_seg=None, scale=None, out_threshold=OUT_THRESHOLD):\n",
    "    out_mask = model(sample[\"input\"].unsqueeze(0).cuda())\n",
    "    original_input_mask = sample[\"input\"].numpy().squeeze()[2]\n",
    "    original_input_mask = original_input_mask.astype(bool)\n",
    "\n",
    "    gt_mask = sample[\"gt_mask\"].numpy().squeeze()\n",
    "    out_mask = out_mask[0].cpu().detach().numpy()\n",
    "    fig, axes = plt.subplots(1, 12, figsize=(12 * 7, 6))\n",
    "    axes[0].imshow(sample[\"input\"][0])\n",
    "    axes[0].set_title(\"raw\")\n",
    "\n",
    "    axes[1].imshow(sample[\"input\"][1])\n",
    "    axes[1].set_title(\"augmented seg, scale: {:.2f}\".format(scale if scale is not None else float(\"inf\")))\n",
    "    im2 = axes[2].imshow(out_mask[0, :])\n",
    "    axes[2].set_title(\"out0seg\")\n",
    "    add_colorbar(im2, axes[2], fig)\n",
    "\n",
    "    axes[3].imshow(gt_mask[0, :])\n",
    "    axes[3].set_title(\"gt0 seg\")\n",
    "\n",
    "    im4 = axes[4].imshow(out_mask[1, :])\n",
    "    axes[4].set_title(\"out1seg\")\n",
    "    add_colorbar(im4, axes[4], fig)\n",
    "    \n",
    "    im5 = axes[5].imshow(gt_mask[1, :])\n",
    "    add_colorbar(im5, axes[5], fig)\n",
    "    axes[5].set_title(\"gt1 seg\")\n",
    "\n",
    "    im6 = axes[6].imshow(out_mask[2, :])\n",
    "    add_colorbar(im6, axes[6], fig)\n",
    "    axes[6].set_title(\"out2 seg\")\n",
    "\n",
    "    im7 = axes[7].imshow(gt_mask[2, :])\n",
    "    add_colorbar(im7, axes[7], fig)\n",
    "    axes[7].set_title(\"gt2 seg\")\n",
    "\n",
    "\n",
    "    combined_over_under_seg = np.zeros([3] + list(out_mask.shape[1:]))\n",
    "    combined_over_under_seg[0, out_mask[1, :] > out_threshold] = 1\n",
    "    combined_over_under_seg[1, out_mask[2, :] > out_threshold] = 1\n",
    "    im = axes[8].imshow(np.moveaxis(combined_over_under_seg, 0, 2))\n",
    "    axes[8].set_title(\"out(1,2), over/under seg combined\")\n",
    "\n",
    "    # import matplotlib.patches as mpatches\n",
    "    # values = [-1, 0, 1]\n",
    "    # colors = [im.cmap(im.norm(value)) for value in values]\n",
    "    # patches = [mpatches.Patch(color=colors[i], label=\"Level {l}\".format(l=values[i]) ) for i in range(len(values))]\n",
    "    # axes[8].legend(handles=patches, loc=2, borderaxespad=0. )\n",
    "   \n",
    "\n",
    "    axes[9].imshow(out_mask[0] > out_threshold)\n",
    "    axes[9].set_title(f\"out0 >{out_threshold} threshold\")\n",
    "\n",
    "\n",
    "    out_mask_predicted = out_mask[0] > out_threshold\n",
    "    # ignore pixels outside an area, only works for undersegmentation\n",
    "    out_mask_predicted[original_input_mask < 0.5] = 0\n",
    "    out_mask_predicted = out_mask_predicted.astype(bool)\n",
    "    axes[10].imshow(out_mask_predicted)\n",
    "    axes[10].set_title(f\"cleaned out mask prediction\")\n",
    "\n",
    "    axes[11].imshow(sample[\"input\"][2])\n",
    "    axes[11].set_title(\"input:dim2\")\n",
    "    # # visualize out specifically\n",
    "    # fig, axes = plt.subplots(1, 3, figsize=(25, 5))\n",
    "    # axes[0].imshow(out_mask[1] > out_threshold)\n",
    "    # axes[0].set_title(f\"out1 >{out_threshold} threshold\")\n",
    "    # axes[1].imshow(out_mask[2] > out_threshold)\n",
    "    # axes[1].set_title(f\"out2 >{out_threshold} threshold\")\n",
    "    \n",
    "    # combined_over_under_seg = np.zeros([3] + list(out_mask.shape[1:]))\n",
    "    # combined_over_under_seg[0, out_mask[1, :] > 2] = 1\n",
    "    # combined_over_under_seg[1, out_mask[2, :] > 2] = 1\n",
    "    # axes[2].imshow(np.moveaxis(combined_over_under_seg, 0, 2))\n",
    "    # axes[2].set_title(\"out(1,2), over/under seg combined\")\n",
    "\n",
    "    # print(\"g1 seg stats:\", gt_mask[1, :].mean(), gt_mask[1, :].std(), np.unique(gt_mask.flatten()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "visualize test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "for i, sample in enumerate(test_dataset):\n",
    "    # print(sample.keys())\n",
    "    check_sample_v3(sample, model, out_threshold=OUT_THRESHOLD)\n",
    "    if i > 10:\n",
    "        break\n",
    "warnings.filterwarnings(\"default\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "visualize training image results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "for i, sample in enumerate(train_dataset):\n",
    "    # print(sample.keys())\n",
    "    check_sample_v3(sample, model, out_threshold=OUT_THRESHOLD)\n",
    "    if i > 10:\n",
    "        break\n",
    "warnings.filterwarnings(\"default\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation set\n",
    "```\n",
    "for i in range(len(model.val_dataset)):\n",
    "    sample = model.val_dataset[i]\n",
    "    check_sample_result(sample, model)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shift the cell to edge to check if the model only focuses on center area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_sample = dataset[9]\n",
    "# plt.imshow(chosen_sample[\"input\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shift_sample = {}\n",
    "shift_sample[\"input\"] = chosen_sample[\"input\"][:, :-150, :-150]\n",
    "# # for v1, single mask prediction\n",
    "# shift_sample[\"gt_mask\"] = chosen_sample[\"gt_mask\"][0, :-150, :-150]\n",
    "\n",
    "shift_sample[\"gt_mask\"] = chosen_sample[\"gt_mask\"][:, :-150, :-150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shift_sample[\"input\"].shape, shift_sample[\"gt_mask\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check_sample_v1(shift_sample, model)\n",
    "check_sample_v3(shift_sample, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shift_sample = {}\n",
    "shift_sample[\"input\"] = chosen_sample[\"input\"][:, :-100, :-100]\n",
    "shift_sample[\"gt_mask\"] = chosen_sample[\"gt_mask\"][:, :-100, :-100]\n",
    "check_sample_v3(shift_sample, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shift_sample = {}\n",
    "shift_sample[\"input\"] = chosen_sample[\"input\"][:, :-50, :-50]\n",
    "shift_sample[\"gt_mask\"] = chosen_sample[\"gt_mask\"][:, :-50, :-50]\n",
    "check_sample_v3(shift_sample, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shift_sample = {}\n",
    "shift_sample[\"input\"] = chosen_sample[\"input\"][:, :-10, :-10]\n",
    "shift_sample[\"gt_mask\"] = chosen_sample[\"gt_mask\"][:, :-10, :-10]\n",
    "check_sample_v3(shift_sample, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = assemble_dataset(test_df)\n",
    "for i, sample in enumerate(test_dataset):\n",
    "    # print(sample.keys())\n",
    "    check_sample_v3(sample, model, out_threshold=OUT_THRESHOLD)\n",
    "    if i > 50:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('livecell')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d9c7226d793827cd27273ad20fbb4775c3cb91053ab9378a09de5f8c6f258919"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
