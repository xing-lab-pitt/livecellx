{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-19 20:09:27.219145: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-01-19 20:09:27.219175: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-01-19 20:09:27.220036: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-19 20:09:27.224270: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-19 20:09:27.847836: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/ken67/anaconda3/envs/livecellx/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/ken67/anaconda3/envs/livecellx/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DeepLabV3_ResNet50_Weights.COCO_WITH_VOC_LABELS_V1`. You can also use `weights=DeepLabV3_ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Using MSE loss\n",
      ">>> Based on loss type, training output threshold:  1\n",
      "|-----> json loaded from notebook_results/CXA_process2_7_19/sctc_filled_SORT_bbox_max_age_3_min_hits_1.json\n",
      "|-----> Creating SingleCellTrajectoryCollection from json_dict...\n",
      "|-----> Loading SingleCellTrajectoryCollection from json_dict done.\n",
      "# of cp_scs 134553\n",
      "# of filtered_cp_scs 106348\n",
      "# of filtered cells 28205\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import livecellx\n",
    "from livecellx.model_zoo.segmentation.custom_transforms import CustomTransformEdtV9\n",
    "from livecellx.preprocess.utils import overlay\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "from livecellx.core import (\n",
    "    SingleCellTrajectory,\n",
    "    SingleCellStatic,\n",
    "    SingleCellTrajectoryCollection,\n",
    ")\n",
    "from livecellx.core.single_cell import get_time2scs\n",
    "from livecellx.core.datasets import LiveCellImageDataset\n",
    "from livecellx.preprocess.utils import (\n",
    "    overlay,\n",
    "    enhance_contrast,\n",
    "    normalize_img_to_uint8,\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from typing import List\n",
    "\n",
    "\n",
    "import glob\n",
    "from PIL import Image, ImageSequence\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import TQDMProgressBar\n",
    "\n",
    "from livecellx.model_zoo.segmentation.sc_correction import CorrectSegNet\n",
    "from livecellx.model_zoo.segmentation.sc_correction_aux import CorrectSegNetAux\n",
    "from livecellx.core.utils import label_mask_to_edt_mask\n",
    "from livecellx.core.single_cell import combine_scs_label_masks\n",
    "import livecellx.model_zoo.segmentation.csn_configs as csn_configs\n",
    "import numpy as np\n",
    "import warnings\n",
    "import tqdm\n",
    "from livecellx.core.io_sc import prep_scs_from_mask_dataset\n",
    "from livecellx.core.sc_filters import filter_boundary_cells, filter_scs_by_size\n",
    "import random\n",
    "\n",
    "import tqdm\n",
    "from datetime import datetime\n",
    "import torch\n",
    "from livecellx.core.utils import label_mask_to_edt_mask\n",
    "from livecellx.segment.ou_viz import viz_ou_outputs\n",
    "from livecellx.segment.ou_utils import create_ou_input_from_sc\n",
    "from livecellx.preprocess.utils import normalize_edt\n",
    "from livecellx.core.io_utils import save_png\n",
    "from livecellx.model_zoo.segmentation.sc_correction_dataset import CorrectSegNetDataset\n",
    "from livecellx.model_zoo.segmentation.csn_sc_utils import correct_sc, correct_sc_mask\n",
    "\n",
    "\n",
    "from livecellx.segment.ou_utils import dilate_or_erode_label_mask\n",
    "\n",
    "\n",
    "\n",
    "from livecellx.model_zoo.segmentation.sc_correction_dataset import CorrectSegNetDataset\n",
    "\n",
    "torch.manual_seed(237)\n",
    "# PADDING_PIXELS = 50\n",
    "# PADDING_PIXELS = 10\n",
    "PADDING_PIXELS = 20\n",
    "OUT_THRESHOLD = 1\n",
    "\n",
    "\n",
    "model_ckpt = \"/home/ken67/livecellx/notebooks/lightning_logs/version_v18_02-inEDTv1-augEdtV9-scaleV2-lr-0.0001-aux-seed-404/checkpoints/last.ckpt\"\n",
    "\n",
    "# model_ckpt = (\n",
    "#     \"lightning_logs/version_v17_02-inEDTv1-augEdtV8-scaleV2-lr=0.00001-aux/checkpoints/last.ckpt\"\n",
    "# )\n",
    "model = CorrectSegNetAux.load_from_checkpoint(model_ckpt)\n",
    "# input_transforms = csn_configs.gen_train_transform_edt_v8(degrees=0, shear=0, flip_p=0)\n",
    "\n",
    "model.cuda()\n",
    "model.eval()\n",
    "\n",
    "\n",
    "\n",
    "input_transforms = CustomTransformEdtV9(degrees=0, shear=0, flip_p=0, use_gaussian_blur=True, gaussian_blur_sigma=15)\n",
    "\n",
    "\n",
    "lcx_out_dir = Path(\"./notebook_results/CXA_process2_7_19/\")\n",
    "lcx_out_dir.mkdir(parents=True, exist_ok=True)\n",
    "# mapping_path = lcx_out_dir / \"iomin_all_sci2sci2metric.json\"\n",
    "mapping_path = lcx_out_dir / \"iou_all_sci2sci2metric.json\"\n",
    "\n",
    "\n",
    "sci2sci2metric = json.load(open(mapping_path, \"r\"))\n",
    "\n",
    "\n",
    "\n",
    "# all_scs = prep_scs_from_mask_dataset(d2_mask_dataset, d2_mask_dataset)\n",
    "all_tracked_scs = SingleCellTrajectoryCollection.load_from_json_file(\n",
    "    lcx_out_dir / \"sctc_filled_SORT_bbox_max_age_3_min_hits_1.json\").get_all_scs()\n",
    "\n",
    "filtered_tracked_scs = filter_boundary_cells(all_tracked_scs, dist_to_boundary=30, use_box_center=False)\n",
    "\n",
    "\n",
    "print(\"# of cp_scs\", len(all_tracked_scs))\n",
    "print(\"# of filtered_cp_scs\", len(filtered_tracked_scs))\n",
    "print(\"# of filtered cells\", len(all_tracked_scs) - len(filtered_tracked_scs))\n",
    "\n",
    "# ## Apply CSN to all the cells\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/106348 [00:00<?, ?it/s]/home/ken67/anaconda3/envs/livecellx/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/home/ken67/anaconda3/envs/livecellx/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "  0%|          | 100/106348 [00:06<1:56:49, 15.16it/s]/home/ken67/anaconda3/envs/livecellx/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "  0%|          | 128/106348 [00:08<1:59:13, 14.85it/s]"
     ]
    }
   ],
   "source": [
    "id2sc = {sc.id: sc for sc in all_tracked_scs}\n",
    "\n",
    "# Use only the date in the filename\n",
    "csn_out = lcx_out_dir / \"csn_apply_all\" / f\"v18-404-correct-ALL-scs-{datetime.now().strftime('%Y%m%d')}_PAD={PADDING_PIXELS}_OUTTH={OUT_THRESHOLD}\"\n",
    "\n",
    "\n",
    "csn_viz_out = csn_out / \"viz\"\n",
    "csn_mask_out = csn_out / \"mask\"\n",
    "csn_out.mkdir(parents=True, exist_ok=True)\n",
    "csn_viz_out.mkdir(parents=True, exist_ok=True)\n",
    "csn_mask_out.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "results_df = pd.DataFrame(\n",
    "    columns=[\"sc_id\", \"label_str\", \"#ws-scs\"]\n",
    ")\n",
    "results_dict = {\n",
    "    \"sc_id\": [],\n",
    "    \"label_str\": [],\n",
    "    \"#ws-scs\": [],\n",
    "}\n",
    "save_df_interval = 100\n",
    "\n",
    "all_corrected_scs = []\n",
    "for idx, _sc in tqdm.tqdm(enumerate(filtered_tracked_scs), total=len(filtered_tracked_scs)):\n",
    "    # out_mask_transformed, watershed_mask, label_str = correct_sc_mask(sc_from, model, PADDING_PIXELS, input_transforms, gpu=True)\n",
    "    res_dict = correct_sc(_sc, model, PADDING_PIXELS, input_transforms, gpu=True, return_outputs=True)\n",
    "    _corrected_scs = res_dict[\"scs\"]\n",
    "    all_corrected_scs.extend(_corrected_scs)\n",
    "\n",
    "    out_mask_transformed = res_dict[\"out_mask\"]\n",
    "    watershed_mask = res_dict[\"watershed_mask\"]\n",
    "    label_str = res_dict[\"label_str\"]\n",
    "    \n",
    "    _sc.meta[\"csn_out_aux_label\"] = label_str\n",
    "\n",
    "    results_dict[\"sc_id\"].append(_sc.id)\n",
    "    results_dict[\"label_str\"].append(label_str)\n",
    "    results_dict[\"#ws-scs\"].append(len(np.unique(watershed_mask)) - 1)\n",
    "    # # # Save resaults\n",
    "    save_png(out_mask_transformed[0], csn_mask_out / f\"raw-seg-{_sc.id}_from.png\", mode=\"RGB\") # 3 channel, (SEG, US, OS)\n",
    "    save_png(watershed_mask, csn_mask_out / f\"watershed-sc-{_sc.id}_from.png\")\n",
    "\n",
    "    np.save(csn_mask_out / f\"raw-seg-{_sc.id}.npy\", out_mask_transformed[0], allow_pickle=False)\n",
    "    np.save(csn_mask_out / f\"watershed_sc-{_sc.id}.npy\", watershed_mask, allow_pickle=False)\n",
    "    if idx % save_df_interval == 0:\n",
    "        results_df = pd.DataFrame(results_dict)\n",
    "        results_df.to_csv(csn_out / \"results.csv\", index=False)\n",
    "\n",
    "SingleCellStatic.write_single_cells_json(all_corrected_scs, csn_out / \"csn_applied_scs.json\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SORT track\n",
    "from livecellx.track.sort_tracker_utils import track_SORT_bbox_from_scs\n",
    "\n",
    "img_dataset = all_corrected_scs[0].img_dataset\n",
    "mask_dataset = all_corrected_scs[0].mask_dataset\n",
    "all_corrected_scs = filter_scs_by_size(all_corrected_scs, min_size=400)\n",
    "\n",
    "tracked_sctc = track_SORT_bbox_from_scs(all_corrected_scs, img_dataset, mask_dataset, max_age=3, min_hits=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracked_sctc.write_json(csn_out / \"corrected_all_retrack_v18-1-19.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "livecellx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
