{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from cellpose import models\n",
    "from cellpose.io import imread\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from PIL import Image, ImageSequence\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import os.path\n",
    "from livecell_tracker import segment\n",
    "from livecell_tracker import core\n",
    "from livecell_tracker.core import datasets\n",
    "from livecell_tracker.core.datasets import LiveCellImageDataset\n",
    "from skimage import measure\n",
    "from livecell_tracker.core import SingleCellTrajectory, SingleCellStatic\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "import cv2\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from livecell_tracker.segment.detectron_utils import gen_cfg\n",
    "\n",
    "from livecell_tracker.segment.detectron_utils import (\n",
    "    segment_detectron_wrapper,\n",
    "    segment_images_by_detectron,\n",
    "    convert_detectron_instance_pred_masks_to_binary_masks,\n",
    "    convert_detectron_instances_to_label_masks,\n",
    ")\n",
    "from livecell_tracker.segment.detectron_utils import (\n",
    "    convert_detectron_instance_pred_masks_to_binary_masks,\n",
    "    convert_detectron_instances_to_label_masks,\n",
    "    segment_images_by_detectron,\n",
    "    segment_single_img_by_detectron_wrapper,\n",
    ")\n",
    "\n",
    "\n",
    "dataset_dir_path = Path(\n",
    "    \"../datasets/test_data_STAV-A549/DIC_data\"\n",
    ")\n",
    "\n",
    "mask_dataset_path = Path(\"../datasets/test_data_STAV-A549/mask_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_dataset = LiveCellImageDataset(mask_dataset_path, ext=\"png\")\n",
    "mask_dataset.time2url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_dataset = LiveCellImageDataset(dataset_dir_path, ext=\"tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_dataset.time2url"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert label masks to single objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.measure import regionprops\n",
    "\n",
    "single_cells = []\n",
    "\n",
    "for time in mask_dataset.time2url:\n",
    "    img = dic_dataset.get_img_by_time(time)\n",
    "    seg_mask = mask_dataset.get_img_by_time(time)\n",
    "    props_list = regionprops(seg_mask)\n",
    "    for prop in props_list:\n",
    "        single_cells.append(\n",
    "            SingleCellStatic(\n",
    "                timeframe=time,\n",
    "                img_dataset = dic_dataset,\n",
    "                mask_dataset = mask_dataset,\n",
    "                bbox=prop.bbox,\n",
    "                contour=prop.coords, # TODO: fix BUG here... should not be coords but contour\n",
    "            )\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for testing\n",
    "# single_cells = single_cells[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(single_cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_cells_by_time = {}\n",
    "for cell in single_cells:\n",
    "    if cell.timeframe not in single_cells_by_time:\n",
    "        single_cells_by_time[cell.timeframe] = []\n",
    "    single_cells_by_time[cell.timeframe].append(cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for time in single_cells_by_time:\n",
    "    print(time, len(single_cells_by_time[time]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize one single cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = single_cells[0]\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(10, 5))\n",
    "sc.show(ax=axes[0])\n",
    "sc.show_mask(ax=axes[1])\n",
    "sc.show_contour_img(ax=axes[2])\n",
    "sc.show_contour_mask(ax=axes[3])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate overlap between two single cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.show_mask(padding=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.show_contour_mask(padding=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc1 = single_cells_by_time[0][0]\n",
    "sc2 = single_cells_by_time[0][1]\n",
    "\n",
    "def compute_overlap_bf(sc1, sc2):\n",
    "    # calculate overlap\n",
    "    img_shape = sc1.get_img().shape\n",
    "    # TODO: add a helper function in single_cell to returna mask with only the current cell in it.\n",
    "    mask1 = sc1.get_contour_mask(padding=np.max(img_shape)).astype(bool)\n",
    "    mask2 = sc2.get_contour_mask(padding=np.max(img_shape)).astype(bool)\n",
    "\n",
    "    overlap_area = np.logical_and(mask1, mask2).sum()\n",
    "    iou = overlap_area / (mask1 | mask2).sum()\n",
    "    return overlap_area, iou\n",
    "\n",
    "def bbox_overlap(bbox1, bbox2):\n",
    "    # calculate overlap\n",
    "    x1_min, y1_min, x1_max, y1_max = bbox1\n",
    "    x2_min, y2_min, x2_max, y2_max = bbox2\n",
    "    x_overlap = max(0, min(x1_max, x2_max) - max(x1_min, x2_min))\n",
    "    y_overlap = max(0, min(y1_max, y2_max) - max(y1_min, y2_min))\n",
    "    overlap_area = x_overlap * y_overlap\n",
    "    bbox1_area = (x1_max - x1_min) * (y1_max - y1_min)\n",
    "    bbox2_area = (x2_max - x2_min) * (y2_max - y2_min)\n",
    "    iou = overlap_area / (bbox1_area + bbox2_area - overlap_area)\n",
    "    return overlap_area, iou\n",
    "\n",
    "def compute_overlap(sc1: SingleCellStatic, sc2: SingleCellStatic):\n",
    "    bbox1, bbox2 = sc1.get_bbox(), sc2.get_bbox()\n",
    "    bbox_overlap_area, bbox_iou = bbox_overlap(bbox1, bbox2)\n",
    "    if bbox_iou <= 0:\n",
    "        return 0, 0\n",
    "\n",
    "    merged_bbox = (min(bbox1[0], bbox2[0]), min(bbox1[1], bbox2[1]), max(bbox1[2], bbox2[2]), max(bbox1[3], bbox2[3]))\n",
    "    # calculate overlap\n",
    "    # TODO: add a helper function in single_cell to returna mask with only the current cell in it.\n",
    "    mask1 = sc1.get_contour_mask(crop=False)[merged_bbox[0]:merged_bbox[2], merged_bbox[1]:merged_bbox[3]]\n",
    "    mask2 = sc2.get_contour_mask(crop=False)[merged_bbox[0]:merged_bbox[2], merged_bbox[1]:merged_bbox[3]]\n",
    "    overlap_area = np.logical_and(mask1, mask2).sum()\n",
    "    iou = overlap_area / (mask1 | mask2).sum()\n",
    "    return overlap_area, iou\n",
    "t1, t2 = 0, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_compute_overlap():\n",
    "    for sc in single_cells:\n",
    "        for sc_tmp in single_cells:\n",
    "            # compare two overlap algorithms\n",
    "            overlap_area, iou = compute_overlap(sc, sc_tmp)\n",
    "            overlap_area_bf, iou_bf = compute_overlap_bf(sc, sc_tmp)\n",
    "            # print(overlap_area, overlap_area_bf)\n",
    "            assert overlap_area == overlap_area_bf\n",
    "            assert iou == iou_bf\n",
    "# test_compute_overlap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "def compute_overlaps(sc_list1, sc_list2):\n",
    "    overlap_map = {}\n",
    "    for sc1 in tqdm.tqdm(sc_list1, desc=\"Computing overlaps\"):\n",
    "        for sc2 in sc_list2:\n",
    "            overlap_area, iou = compute_overlap(sc1, sc2)\n",
    "            overlap_map[(sc1, sc2)] = (overlap_area, iou)\n",
    "    # parallel version\n",
    "    return overlap_map\n",
    "\n",
    "overlap_map_by_time = {}\n",
    "times = set(sorted(list(single_cells_by_time.keys())))\n",
    "for time in times:\n",
    "    if time + 1 not in times:\n",
    "        print(f\"Time {time} is the last time point, skipping\")\n",
    "        continue\n",
    "    overlap_map_by_time[time] = compute_overlaps(single_cells_by_time[time], single_cells_by_time[time + 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc1, sc2 = single_cells_by_time[0][0], single_cells_by_time[1][0]\n",
    "overlap_map_by_time[0][(sc1, sc2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(single_cells_by_time[2])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the cells visually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for time in overlap_map_by_time:\n",
    "#     overlap_map = overlap_map_by_time[time]\n",
    "#     for sc_tmp1, sc_tmp2 in overlap_map:\n",
    "#         if sc_tmp1 == sc_tmp2:\n",
    "#             continue\n",
    "#         if overlap_map[(sc_tmp1, sc_tmp2)][0] > 0:\n",
    "#             print(sc_tmp1.timeframe, sc_tmp2.timeframe, overlap_map[(sc_tmp1, sc_tmp2)])\n",
    "#             fig, axes = plt.subplots(1, 6, figsize=(15, 5))\n",
    "#             padding=50\n",
    "#             sc_tmp1.show_contour_mask(crop=False, ax = axes[0])\n",
    "#             sc_tmp2.show_contour_mask(crop=False, ax = axes[1])\n",
    "#             sc_tmp1.show(crop=True, ax = axes[2], padding=padding)\n",
    "#             sc_tmp2.show(crop=True, ax = axes[3], padding=padding)\n",
    "#             sc_tmp1.show_contour_mask(crop=True, ax = axes[4], padding=padding)\n",
    "#             sc_tmp2.show_contour_mask(crop=True, ax = axes[5], padding=padding)\n",
    "#             plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(sc1.mask_dataset.get_img_by_time(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(sc1.mask_dataset.get_img_by_time(1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "sc.datasets[\"img\"]\n",
    "sc.datasets[\"mask\"]\n",
    "sc.datasets[\"label\"]\n",
    "sc.datasets[\"TRITC\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from livecell_tracker.segment.utils import match_mask_labels_by_iou\n",
    "def match_mask_labels_by_iou(seg_label_mask, gt_label_mask, bg_label=0, return_all=False):\n",
    "    \"\"\"compute the similarity between ground truth mask and segmentation mask by intersection over union\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    seg_label_mask : _type_\n",
    "        _description_\n",
    "    gt_label_mask : _type_\n",
    "        _description_\n",
    "    bg_label : int, optional\n",
    "        _description_, by default 0\n",
    "    return_all : bool, optional\n",
    "        _description_, by default False\n",
    "    Returns\n",
    "    -------\n",
    "        A <gt2seg_map>, mapping ground truth keys to a dictionary of the best matching segmentation label and its iou\n",
    "    \"\"\"\n",
    "    gt2seg_map = {}\n",
    "    all_gt2seg_iou__map = {}\n",
    "    # gets all the unique labels in the labeled_seg_mask and gtly_curated_mask\n",
    "    seg_labels = np.unique(seg_label_mask)\n",
    "    gt_labels = np.unique(gt_label_mask)\n",
    "\n",
    "    temp_seg_mask = seg_label_mask.copy()\n",
    "    temp_gt_mask = gt_label_mask.copy()\n",
    "\n",
    "    for gt_label in gt_labels:\n",
    "        if gt_label == bg_label:\n",
    "            continue\n",
    "        gt_label_key = gt_label\n",
    "        all_gt2seg_iou__map[gt_label_key] = []\n",
    "        gt2seg_map[gt_label_key] = {}\n",
    "        temp_gt_mask = gt_label_mask.copy()\n",
    "        # isolates the current cell in the temp gtly_curated_mask and gets its pixels to 1\n",
    "        temp_gt_mask[temp_gt_mask != gt_label] = 0\n",
    "        temp_gt_mask[temp_gt_mask != 0] = 1\n",
    "\n",
    "        best_iou = 0\n",
    "        for seg_label in seg_labels:\n",
    "            if seg_label == bg_label:\n",
    "                continue\n",
    "            temp_seg_mask = seg_label_mask.copy()\n",
    "\n",
    "            # isolate the current cell in the temp_seg_mask and set its pixels to 1\n",
    "            temp_seg_mask[temp_seg_mask != seg_label] = 0\n",
    "            temp_seg_mask[temp_seg_mask != 0] = 1\n",
    "\n",
    "            matching_rows, matching_columns = np.where(temp_seg_mask == 1)\n",
    "            intersection_area = (temp_gt_mask[matching_rows, matching_columns] == 1).sum()\n",
    "            union_area = temp_gt_mask.sum() + temp_seg_mask.sum() - intersection_area\n",
    "            iou = intersection_area / union_area\n",
    "            io_gt = intersection_area / temp_gt_mask.sum()\n",
    "            io_seg = intersection_area / temp_seg_mask.sum()\n",
    "            all_gt2seg_iou__map[gt_label_key].append({\n",
    "                \"seg_label\": seg_label,\n",
    "                \"iou\": iou,\n",
    "                \"io_gt\": io_gt,\n",
    "                \"io_seg\": io_seg,\n",
    "            })\n",
    "\n",
    "            if iou > best_iou:\n",
    "                best_iou = iou\n",
    "                gt2seg_map[gt_label_key][\"best_iou\"] = iou\n",
    "                gt2seg_map[gt_label_key][\"seg_label\"] = seg_label\n",
    "    if return_all:\n",
    "        return gt2seg_map, all_gt2seg_iou__map\n",
    "    else:\n",
    "        return gt2seg_map\n",
    "    \n",
    "match_mask_labels_by_iou(sc1.mask_dataset.get_img_by_time(2), sc1.mask_dataset.get_img_by_time(1), return_all=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply correction CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from livecell_tracker.model_zoo.segmentation.sc_correction import CorrectSegNet\n",
    "ckpt = r\"/home/ken67/LiveCellTracker-dev/notebooks/lightning_logs/version_real-02/checkpoints/epoch=3720-test_loss=0.0085.ckpt\"\n",
    "\n",
    "model = CorrectSegNet.load_from_checkpoint(ckpt)\n",
    "model = model.cuda()\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_cells_by_time[2][12].show_panel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_cells_by_time[2][13].show_panel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from livecell_tracker.segment.ou_utils import create_ou_input_from_sc\n",
    "from torchvision import transforms\n",
    "from livecell_tracker.preprocess.utils import normalize_img_to_uint8\n",
    "import torch\n",
    "transforms = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize(size=(412, 412)),\n",
    "        ]\n",
    ")\n",
    "from livecell_tracker.preprocess.utils import dilate_or_erode_mask\n",
    "def create_ou_input_from_sc(sc: SingleCellStatic, padding_pixels: int = 0, dtype=float, remove_bg=True, one_object=True, scale=0):\n",
    "    if remove_bg:\n",
    "        img_crop = sc.get_contour_img(padding=padding_pixels).astype(dtype)\n",
    "    else:\n",
    "        img_crop = sc.get_img_crop(padding=padding_pixels).astype(dtype)\n",
    "    img_crop = normalize_img_to_uint8(img_crop).astype(dtype)\n",
    "    if one_object:\n",
    "        sc_mask = sc.get_contour_mask(padding=padding_pixels)\n",
    "        sc_mask = dilate_or_erode_mask(sc_mask.astype(np.uint8), scale_factor=scale).astype(bool)\n",
    "        img_crop[~sc_mask] *= -1\n",
    "    else:\n",
    "        img_crop[sc.get_mask_crop(padding=padding_pixels) == 0] *= -1\n",
    "    return img_crop\n",
    "\n",
    "\n",
    "selected_sc_list = [single_cells_by_time[2][12], single_cells_by_time[2][13]]\n",
    "for i, sc in enumerate(selected_sc_list):\n",
    "    print(\"sc index:\", i)\n",
    "    ou_input = create_ou_input_from_sc(sc, padding_pixels=100, remove_bg=False, scale=0.8)\n",
    "    ou_input = transforms(torch.tensor([ou_input]))\n",
    "    ou_input = torch.stack([ou_input, ou_input, ou_input], dim=1)\n",
    "    # ou_input = ou_input.permute(0, 2, 3, 1)\n",
    "    ou_input = ou_input.float().cuda()\n",
    "    output = model(ou_input)\n",
    "\n",
    "    # visualize the input and all 3 output channels\n",
    "    fig, axes = plt.subplots(1, 5, figsize=(15, 5))\n",
    "    axes[0].imshow(ou_input[0, 0].cpu().detach().numpy())\n",
    "    axes[0].set_title(\"input\")\n",
    "    axes[1].imshow(output[0, 0].cpu().detach().numpy())\n",
    "    axes[1].set_title(\"output c0\")\n",
    "    axes[2].imshow(output[0, 1].cpu().detach().numpy())\n",
    "    axes[2].set_title(\"output c1\")\n",
    "    axes[3].imshow(output[0, 2].cpu().detach().numpy())\n",
    "    axes[3].set_title(\"output c2\")\n",
    "    axes[4].imshow(sc.get_mask_crop(padding=50, dtype=int))\n",
    "    axes[4].set_title(\"original mask\")\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[TODO] judge if a case is oversegmentation\n",
    "inputs:\n",
    "    an input mask with other cells included\n",
    "    a corected label mask\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from livecell_tracker.segment.utils import compute_match_label_map\n",
    "\n",
    "t1, t2, label_map = compute_match_label_map(1, 2, mask_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "livecell",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d9c7226d793827cd27273ad20fbb4775c3cb91053ab9378a09de5f8c6f258919"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
