{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "train_data_meta_path = \"./notebook_results/mmaction_train_data_v14-inclusive/train_data.txt\"\n",
    "train_data_df = pd.read_csv(train_data_meta_path, sep=\" \")\n",
    "\n",
    "test_data_meta_path = \"./notebook_results/mmaction_train_data_v14-inclusive/test_data.txt\"\n",
    "test_data_df = pd.read_csv(test_data_meta_path, sep=\" \")\n",
    "\n",
    "video_dir = Path(\"./notebook_results/mmaction_train_data_v14-inclusive/videos\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_df[\"split\"] = \"train\"\n",
    "test_data_df[\"split\"] = \"test\"\n",
    "combined_df = pd.concat([train_data_df, test_data_df], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We filtered a small number of videos due to a decord bug: \"https://github.com/dmlc/decord/issues/150\". Lets keep consistency with V14-inclusive livecellaction data here by only using the videos included in these paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import PosixPath\n",
    "\n",
    "\n",
    "whitelist_paths = [PosixPath('notebook_results/mmaction_train_data_v14-inclusive/mmaction_train_data_video.txt'),\n",
    " PosixPath('notebook_results/mmaction_train_data_v14-inclusive/mmaction_test_data_video.txt'),\n",
    " PosixPath('notebook_results/mmaction_train_data_v14-inclusive/mmaction_train_data_mask.txt'),\n",
    " PosixPath('notebook_results/mmaction_train_data_v14-inclusive/mmaction_test_data_mask.txt'),\n",
    " PosixPath('notebook_results/mmaction_train_data_v14-inclusive/mmaction_train_data_combined.txt'),\n",
    " PosixPath('notebook_results/mmaction_train_data_v14-inclusive/mmaction_test_data_combined.txt'),\n",
    " PosixPath('notebook_results/mmaction_train_data_v14-inclusive/mmaction_train_data_all.txt'),\n",
    " PosixPath('notebook_results/mmaction_train_data_v14-inclusive/mmaction_test_data_all.txt')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# whitelist videos: 336168\n"
     ]
    }
   ],
   "source": [
    "# Read the paths from the whitelist files\n",
    "\n",
    "whitelist_video_paths = []\n",
    "for df_path in whitelist_paths:\n",
    "    _df = pd.read_csv(df_path, sep=\" \", header=None)\n",
    "    cur_paths = _df[0].tolist()\n",
    "    whitelist_video_paths.extend(cur_paths)\n",
    "\n",
    "print(\"# whitelist videos:\", len(whitelist_video_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "whitelist_video_paths = set(whitelist_video_paths)\n",
    "\n",
    "# Filter out the videos that are not in the whitelist from combined_df\n",
    "filtered_combined_df = combined_df[combined_df[\"path\"].isin(whitelist_video_paths)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# combined videos: 168147\n",
      "# filtered videos: 168084\n"
     ]
    }
   ],
   "source": [
    "print(\"# combined videos:\", len(combined_df))\n",
    "print(\"# filtered videos:\", len(filtered_combined_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "del combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decompose all the videos in combined_df to images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 168084/168084 [17:34<00:00, 159.40it/s] \n"
     ]
    }
   ],
   "source": [
    "out_path = PosixPath(\"notebook_results/mmaction_train_data_v14-inclusive-imgs\")\n",
    "out_path.mkdir(exist_ok=True)\n",
    "imgs_dir = out_path / \"imgs\"\n",
    "imgs_dir.mkdir(exist_ok=True)\n",
    "def decompose_to_images(video_path, row, imgs_dir: Path):\n",
    "    # Read the video and decompose it to images, frame by frame. For each timeframe, save the image to the output path\n",
    "\n",
    "    import cv2\n",
    "    # Open the video file\n",
    "    cap = cv2.VideoCapture(str(video_path))\n",
    "\n",
    "    # Check if video opened successfully\n",
    "    if not cap.isOpened(): \n",
    "        print(\"Error opening video file\")\n",
    "\n",
    "    frame_count = 0\n",
    "    filename_without_ext = Path(video_path).stem\n",
    "    data_rows = []\n",
    "    while(cap.isOpened()):\n",
    "        # Capture frame-by-frame\n",
    "        ret, frame = cap.read()\n",
    "        if ret == True:\n",
    "            # Save the resulting frame\n",
    "            _img_path = str(imgs_dir / f\"{filename_without_ext}_{frame_count}.png\")\n",
    "            success = cv2.imwrite(_img_path, frame)\n",
    "            assert success, \"Failed to write image via cv2.imwrite\"\n",
    "            \n",
    "            new_row = row.copy()\n",
    "            new_row[\"img_path\"] = _img_path\n",
    "            new_row[\"frame_idx\"] = frame_count\n",
    "            data_rows.append(new_row)\n",
    "            frame_count += 1\n",
    "        else: \n",
    "            break\n",
    "\n",
    "    # When everything done, release the video capture object\n",
    "    cap.release()\n",
    "    return data_rows\n",
    "\n",
    "from livecellx.core.parallel import parallelize\n",
    "\n",
    "\n",
    "inputs = []\n",
    "for _, row in filtered_combined_df.iterrows():\n",
    "    video_path = video_dir / row[\"path\"]\n",
    "    # data_rows = decompose_to_images(video_path, row, imgs_dir)\n",
    "    inputs.append({\n",
    "       \"video_path\": video_path,\n",
    "        \"imgs_dir\": imgs_dir,\n",
    "        \"row\": row\n",
    "    })\n",
    "\n",
    "\n",
    "outputs = parallelize(decompose_to_images, inputs)\n",
    "\n",
    "data_rows = []\n",
    "for _output in outputs:\n",
    "    data_rows.extend(_output)\n",
    "df = pd.DataFrame(data_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(out_path / \"train_and_test.csv\", index=False)\n",
    "\n",
    "# save train and test splits\n",
    "train_df = df[df[\"split\"] == \"train\"]\n",
    "test_df = df[df[\"split\"] == \"test\"]\n",
    "train_df.to_csv(out_path / \"train.csv\", index=False)\n",
    "test_df.to_csv(out_path / \"test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['path', 'label_index', 'padding_pixels', 'frame_type', 'src_dir',\n",
       "       'track_id', 'start_time', 'end_time', 'first_sc_id',\n",
       "       'mitosis_traj_type', 'split', 'img_path', 'frame_idx'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "livecell",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
