{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from cellpose import models\n",
    "from cellpose.io import imread\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from PIL import Image, ImageSequence\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import os.path\n",
    "from livecell_tracker import segment\n",
    "from livecell_tracker import core\n",
    "from livecell_tracker.core import datasets\n",
    "from livecell_tracker.core.datasets import LiveCellImageDataset\n",
    "from skimage import measure\n",
    "from livecell_tracker.core import SingleCellTrajectory, SingleCellStatic\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "import tqdm\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "import cv2\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from livecell_tracker.segment.detectron_utils import gen_cfg\n",
    "\n",
    "from livecell_tracker.segment.detectron_utils import (\n",
    "    segment_detectron_wrapper,\n",
    "    segment_images_by_detectron,\n",
    "    convert_detectron_instance_pred_masks_to_binary_masks,\n",
    "    convert_detectron_instances_to_label_masks,\n",
    ")\n",
    "from livecell_tracker.segment.detectron_utils import (\n",
    "    convert_detectron_instance_pred_masks_to_binary_masks,\n",
    "    convert_detectron_instances_to_label_masks,\n",
    "    segment_images_by_detectron,\n",
    "    segment_single_img_by_detectron_wrapper,\n",
    ")\n",
    "from livecell_tracker.annotation.coco_utils import coco_to_sc\n",
    "from pycocotools.coco import COCO\n",
    "\n",
    "pos_path = Path(\"XY5\")\n",
    "\n",
    "dataset_dir_path = Path(\n",
    "    \"../datasets/EBSS_Starvation/tif_STAV-A549_VIM_24hours_NoTreat_NA_YL_Ti2e_2022-12-21\"/ pos_path\n",
    ")\n",
    "\n",
    "mask_dataset_path = Path(\"../datasets/EBSS_Starvation/tif_STAV-A549_VIM_24hours_NoTreat_NA_YL_Ti2e_2022-12-21/out\"/ pos_path /\"seg\")\n",
    "\n",
    "out_dir = Path(\"./notebook_results/a549_ccp_vim/train_real_td_data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_from_path(path):\n",
    "    \"\"\"example path: STAV-A549_VIM_24hours_NoTreat_NA_YL_Ti2e_2022-12-21_T287_XY09_TRITC.tif\"\"\"\n",
    "    idx = 0\n",
    "    strs = path.split(\"_\")\n",
    "    while idx < len(strs) - 1:\n",
    "        if strs[idx][:2] == \"XY\":\n",
    "            break\n",
    "        idx += 1\n",
    "    idx -= 1\n",
    "    return int(strs[idx][1:])\n",
    "get_time_from_path(\"example path: STAV-A549_VIM_24hours_NoTreat_NA_YL_Ti2e_2022-12-21_T287_XY09_DIC.tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAX_IMG_NUM = 10\n",
    "MAX_IMG_NUM = int(1e20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample time points by interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_paths = sorted(glob.glob(str(mask_dataset_path / \"*.png\")))[:MAX_IMG_NUM]\n",
    "total_time = len(mask_paths)\n",
    "sample_num = 40\n",
    "sample_interval = total_time//sample_num\n",
    "times = np.linspace(1, total_time, sample_num)\n",
    "\n",
    "# note that we need image (t, t+1) to search for over/under-segmentation pairs\n",
    "times = set([int(t) for t in times] + [int(t+1) for t in times]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_time2url = {}\n",
    "mask_paths = sorted(glob.glob(str(mask_dataset_path / \"*.png\")))[:MAX_IMG_NUM]\n",
    "for mask_path in mask_paths:\n",
    "    mask_time2url[get_time_from_path(mask_path)] = mask_path\n",
    "\n",
    "mask_time2url = {k: v for k, v in mask_time2url.items() if k in times}\n",
    "label_mask_dataset = LiveCellImageDataset(ext=\"png\", time2url=mask_time2url)\n",
    "len(label_mask_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time2url = {}\n",
    "img_paths = sorted(glob.glob(str(dataset_dir_path / \"*_DIC.tif\")))[:MAX_IMG_NUM]\n",
    "\n",
    "for img_path in img_paths:\n",
    "    time = get_time_from_path(img_path)\n",
    "    time2url[time] = img_path\n",
    "\n",
    "time2url = {k: v for k, v in time2url.items() if k in times}\n",
    "dic_dataset = LiveCellImageDataset(dataset_dir_path, time2url=time2url, ext=\"tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(dic_dataset.time2url.items())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dic_dataset.time2url)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check co-existence of times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for time in label_mask_dataset.time2url:\n",
    "    assert time in dic_dataset.time2url\n",
    "\n",
    "for time in dic_dataset.time2url:\n",
    "    assert time in label_mask_dataset.time2url"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert label masks to single cell objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "from skimage.measure import regionprops, find_contours\n",
    "from livecell_tracker.segment.ou_simulator import find_contours_opencv\n",
    "\n",
    "# TODO: fix the function below\n",
    "def process_scs_from_label_mask(label_mask_dataset, dic_dataset, time, bg_val=0):\n",
    "    label_mask = label_mask_dataset.get_img_by_time(time)\n",
    "    labels = set(np.unique(label_mask))\n",
    "    if bg_val in labels:\n",
    "        labels.remove(bg_val)\n",
    "    contours = []\n",
    "    for label in labels:\n",
    "        bin_mask = (label_mask == label).astype(np.uint8)\n",
    "        label_contours = find_contours_opencv(bin_mask)\n",
    "        assert len(label_contours) == 1\n",
    "        contours.append(label_contours[0])\n",
    "\n",
    "    # contours = find_contours(seg_mask) # skimage: find_contours\n",
    "    _scs = []\n",
    "    for contour in contours:\n",
    "        _scs.append(\n",
    "            SingleCellStatic(\n",
    "                timeframe=time,\n",
    "                img_dataset = dic_dataset,\n",
    "                mask_dataset = label_mask_dataset,\n",
    "                contour=contour,\n",
    "            )\n",
    "        )\n",
    "    return _scs\n",
    "\n",
    "def process_mask_wrapper(args):\n",
    "    return process_scs_from_label_mask(*args)\n",
    "\n",
    "def prep_scs_from_mask_dataset(mask_dataset, dic_dataset, cores=None):\n",
    "    scs = []\n",
    "\n",
    "    inputs = [(mask_dataset, dic_dataset, time) for time in mask_dataset.time2url.keys()]\n",
    "    pool = Pool(processes=cores)\n",
    "    for _scs in tqdm.tqdm(pool.imap_unordered(process_mask_wrapper, inputs), total=len(inputs)):\n",
    "        scs.extend(_scs)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return scs\n",
    "\n",
    "single_cells = prep_scs_from_mask_dataset(label_mask_dataset, dic_dataset, cores=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from skimage.measure import regionprops\n",
    "# single_cells = []\n",
    "\n",
    "# for time in tqdm.tqdm(mask_dataset.time2url):\n",
    "#     img = dic_dataset.get_img_by_time(time)\n",
    "#     seg_mask = mask_dataset.get_img_by_time(time)\n",
    "#     props_list = regionprops(seg_mask)\n",
    "#     for prop in props_list:\n",
    "#         single_cells.append(\n",
    "#             SingleCellStatic(\n",
    "#                 timeframe=time,\n",
    "#                 img_dataset = dic_dataset,\n",
    "#                 mask_dataset = mask_dataset,\n",
    "#                 bbox=prop.bbox,\n",
    "#                 contour=prop.coords,\n",
    "#             )\n",
    "#         )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check the number of single cells "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(single_cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from livecell_tracker.core.parallel import parallelize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_sc_label(sc, bg_val=0):\n",
    "    \"\"\"Assume sc.mask_dataset contains label masks\"\"\"\n",
    "    label_mask_pixels = sc.mask_dataset.get_img_by_time(sc.timeframe)[sc.bbox[0]:sc.bbox[2], sc.bbox[1]:sc.bbox[3]][sc.get_contour_mask()]\n",
    "    labels = np.unique(label_mask_pixels)\n",
    "    labels = list(set(labels))\n",
    "    if bg_val in labels:\n",
    "        labels.remove(bg_val) # remove bg label\n",
    "\n",
    "    # TODO: figure out why skimage regionprops sometimes returns contours containing other labels...\n",
    "    # it should be a bug in skimage\n",
    "    if len(labels) != 1:\n",
    "        label_info = []\n",
    "        for i, label in enumerate(labels):\n",
    "            label_sum = (label_mask_pixels == label).sum()\n",
    "            label_info.append((label, label_sum))\n",
    "        label_info = sorted(label_info, key=lambda x: x[1], reverse=True)\n",
    "        # assert label_info[0][1] > (0.9 * sc.get_contour_mask().sum()), r\"no label exceeds 90% of the sc contour mask, percent: {}\".format(label_info[0][1] / sc.get_contour_mask().sum())\n",
    "        if label_info[0][1] < (0.9 * sc.get_contour_mask().sum()):\n",
    "            print(\"Warning: no label exceeds 90% of the sc contour mask, percent: {}\".format(label_info[0][1] / sc.get_contour_mask().sum()))\n",
    "            print(\"sc time\", sc.timeframe, \"labels:\", labels)\n",
    "            print(\"label info (label, pixels):\", label_info, \"percent:\", label_info[0][1] / sc.get_contour_mask().sum())\n",
    "            sc.show_panel()\n",
    "            plt.show()\n",
    "        labels = [label_info[0][0]]\n",
    "        # sc.show_panel()\n",
    "    assert len(labels) == 1, labels\n",
    "    sc.id = list(labels)[0]\n",
    "    return sc\n",
    "\n",
    "single_cells = parallelize(set_sc_label, [[sc] for sc in single_cells], cores=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sc in single_cells:\n",
    "    assert sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# st = SingleCellTrajectory(track_id=-1, timeframe_to_single_cell={idx:sc for idx, sc in enumerate(single_cells)}, img_dataset=dic_dataset, mask_dataset=label_mask_dataset)\n",
    "# st.timeframe_to_single_cell = {idx:sc for idx, sc in enumerate(single_cells)}\n",
    "# st.write_json(\"notebook_results/single_traj.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    sc = random.sample(single_cells, 1)[0]\n",
    "    print(\"sc timeframe: \", sc.timeframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, _ in enumerate(single_cells):\n",
    "    sc = random.sample(single_cells, 1)[0]\n",
    "    print(\"sc time: \", sc.timeframe)\n",
    "    sc.show_panel(padding=50)\n",
    "    plt.show()\n",
    "    if i >= 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for testing\n",
    "# single_cells = single_cells[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_cells_by_time = {}\n",
    "for cell in single_cells:\n",
    "    if cell.timeframe not in single_cells_by_time:\n",
    "        single_cells_by_time[cell.timeframe] = []\n",
    "    single_cells_by_time[cell.timeframe].append(cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = sorted(single_cells_by_time.keys())\n",
    "for time in times[:5]:\n",
    "    print(time, len(single_cells_by_time[time]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize one single cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = single_cells[0]\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(10, 5))\n",
    "sc.show(ax=axes[0])\n",
    "sc.show_mask(ax=axes[1])\n",
    "sc.show_contour_img(ax=axes[2])\n",
    "sc.show_contour_mask(ax=axes[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from livecell_tracker.segment.utils import match_mask_labels_by_iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_cells_by_time.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc1 = single_cells_by_time[1][0]\n",
    "sc2 = single_cells_by_time[2][0]\n",
    "match_mask_labels_by_iou(sc1.mask_dataset.get_img_by_time(2), sc1.mask_dataset.get_img_by_time(1), return_all=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1, t2 = 1, 2\n",
    "mask1 = sc1.mask_dataset.get_img_by_time(t1)\n",
    "mask2 = sc1.mask_dataset.get_img_by_time(t2)\n",
    "\n",
    "def compute_match_label_map(t1, t2, mask_dataset, iou_threshold=0.2):\n",
    "    label_mask1 = mask_dataset.get_img_by_time(t1)\n",
    "    label_mask2 = mask_dataset.get_img_by_time(t2)\n",
    "\n",
    "    # Note: first arg is mask2 and second arg is mask1 to create mask1 label to mask2 label map\n",
    "    # read match_mask_labels_by_iou docstring for more info\n",
    "    _, score_dict = match_mask_labels_by_iou(label_mask2, label_mask1, return_all=True)\n",
    "    iou_threshold = 0.2\n",
    "    label_map = {}\n",
    "    for label_1 in score_dict:\n",
    "        label_map[label_1] = {}\n",
    "        for score_info in score_dict[label_1]:\n",
    "            if score_info[\"iou\"] > iou_threshold:\n",
    "                label_map[label_1][score_info[\"seg_label\"]] = {\n",
    "                    \"iou\": score_info[\"iou\"]\n",
    "                }\n",
    "    return t1, t2, label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = sorted(label_mask_dataset.times)\n",
    "inputs = []\n",
    "for idx in times:\n",
    "    t1 = idx\n",
    "    if t1+1 in times:\n",
    "        t2 = t1+1\n",
    "    else: \n",
    "        continue\n",
    "    inputs.append((t1, t2, label_mask_dataset))\n",
    "outputs = parallelize(compute_match_label_map, inputs, None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load interim results from json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# map_path = \"./notebook_results/multiple_maps.json\"\n",
    "# # read mapping\n",
    "# with open(map_path, \"r\") as f:\n",
    "#     maps = json.load(f)\n",
    "#     res = []\n",
    "#     for data_dict in maps:\n",
    "#         mapping = data_dict[\"mapping\"]\n",
    "#         tmp_mapping = {}\n",
    "#         for k, v in mapping.items():\n",
    "#             tmp_mapping[int(k)] = v\n",
    "#         mapping = tmp_mapping\n",
    "#         res.append((int(data_dict[\"t1\"]), int(data_dict[\"t2\"]), int(data_dict[\"label\"]), mapping))\n",
    "\n",
    "# multiple_maps = res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_maps = []\n",
    "for t1, t2, label_map in outputs:\n",
    "    for label in label_map:\n",
    "        if len(label_map[label]) > 1:\n",
    "            # print(t1, t2, label, label_map[label])\n",
    "            multiple_maps.append((t1, t2, label, label_map[label]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time2id2sc = {}\n",
    "for sc in single_cells:\n",
    "    time = sc.timeframe\n",
    "    if time not in time2id2sc:\n",
    "        time2id2sc[time] = {}\n",
    "    if sc.id in time2id2sc[time]:\n",
    "        print(\"Warning: sc id already exists in time2id2sc, sc id: {}, time: {}\".format(sc.id, time))\n",
    "        sc.show_panel()\n",
    "        time2id2sc[time][sc.id].show_panel()\n",
    "        \n",
    "    assert sc.id not in time2id2sc[time]\n",
    "    time2id2sc[time][sc.id] = sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(multiple_maps)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "write multiple_maps json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1, t2, label, mapping = multiple_maps[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for sc in single_cells_by_time[t1]:\n",
    "#     print(\"sc.id\", sc.id)\n",
    "#     print(\"sc.timeframe\", sc.timeframe)\n",
    "#     sc.show_panel(padding=100)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time2id2sc[t1][label].show_panel(padding=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from livecell_tracker.preprocess.utils import enhance_contrast, normalize_img_to_uint8\n",
    "print(sc.timeframe)\n",
    "\n",
    "# TODO: add to single cell lib\n",
    "plt.imshow(enhance_contrast(normalize_img_to_uint8(sc.get_img()), factor=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tmp_label in mapping:\n",
    "    sc = time2id2sc[t2][tmp_label]\n",
    "    sc.show_panel(padding=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(multiple_maps)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort multiple_maps by t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_maps = sorted(multiple_maps, key=lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "\n",
    "def human_loop_answer_over_under_seg(multiple_maps, time2id2sc, padding=80):\n",
    "    over_maps = []\n",
    "    under_maps = []\n",
    "    discarded_maps = []\n",
    "    fig_offset = 4\n",
    "    \n",
    "    for info in tqdm.tqdm(multiple_maps):\n",
    "        t1, t2, label, mapping = info\n",
    "        print(\"t1:\", t1 , \"t2:\", t2, \"label:\", label)\n",
    "        print(\"info: \", info)\n",
    "        t1_sc = time2id2sc[t1][label]\n",
    "        t2_scs = []\n",
    "        for tmp_label in mapping:\n",
    "            sc = time2id2sc[t2][tmp_label]\n",
    "            t2_scs.append(sc)\n",
    "        # fig, axes = plt.subplots(1, len(t2_scs) * 2 + offset, figsize=(60, 30))\n",
    "        fig, axes = plt.subplots(1, fig_offset, figsize=(60, 30))\n",
    "        axes[0].imshow(enhance_contrast(normalize_img_to_uint8(t1_sc.get_img()), factor=10))\n",
    "        axes[0].set_title(\"t1 img\")\n",
    "        axes[1].imshow(t1_sc.get_mask_crop(padding=padding, bbox=t1_sc.bbox, dtype=int))\n",
    "        axes[1].set_title(\"t1 label mask\")\n",
    "        # t2_scs[0].show_mask(ax=axes[2], padding=padding, crop=True, bbox=t1_sc.bbox)\n",
    "        axes[2].imshow(t2_scs[0].get_mask_crop(padding=padding, bbox=t1_sc.bbox, dtype=int))\n",
    "        axes[2].set_title(\"t2 label mask\")\n",
    "        \n",
    "        # t1_sc.show(crop=True, ax=axes[3], padding=padding)\n",
    "        axes[3].imshow(enhance_contrast(normalize_img_to_uint8(t1_sc.get_img_crop(padding=padding))))\n",
    "        axes[3].set_title(\"t1 img crop\")\n",
    "\n",
    "        def sc_rect(sc, relative_bbox=None, padding=0, color='r', on_crop=False):\n",
    "            if on_crop:\n",
    "                bbox = sc.get_bbox_on_crop(padding=padding, bbox=relative_bbox)\n",
    "            else:\n",
    "                bbox = sc.bbox\n",
    "            return patches.Rectangle((bbox[1], bbox[0]),(bbox[3]-bbox[1]), (bbox[2] - bbox[0]),linewidth=1, edgecolor=color, facecolor='none')\n",
    "        axes[0].add_patch(sc_rect(t1_sc, color='b'))\n",
    "        axes[1].add_patch(sc_rect(t1_sc, relative_bbox=t1_sc.bbox, padding=padding, color='b', on_crop=True))\n",
    "        axes[2].add_patch(sc_rect(t1_sc, relative_bbox=t1_sc.bbox, padding=padding, color='b', on_crop=True))\n",
    "        axes[3].add_patch(sc_rect(t1_sc, relative_bbox=t1_sc.bbox, padding=padding, color='b', on_crop=True))\n",
    "        \n",
    "        # # show individual sc in t2\n",
    "        for idx, sc in enumerate(t2_scs):\n",
    "            # sc.show_contour_mask(ax=axes[idx*2 + offset], padding=padding)\n",
    "            # sc.show_mask(ax=axes[idx*2 + 1 + offset], padding=padding, crop=True)\n",
    "            axes[0].add_patch(sc_rect(sc))\n",
    "            axes[1].add_patch(sc_rect(sc,  relative_bbox=t1_sc.bbox, padding=padding, color='r', on_crop=True))\n",
    "            axes[2].add_patch(sc_rect(sc,  relative_bbox=t1_sc.bbox, padding=padding, color='r', on_crop=True))\n",
    "            axes[3].add_patch(sc_rect(sc, relative_bbox=t1_sc.bbox, padding=padding, on_crop=True))\n",
    "        plt.show()\n",
    "        while True:\n",
    "            ans = input(\"1. over or 2. under 3. discard\")\n",
    "            try:\n",
    "                ans = int(ans)\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(\"invalid input,\", e)\n",
    "                continue\n",
    "        \n",
    "        print(\"selected: \", end=\"\")\n",
    "        if int(ans) == 1:\n",
    "            print(\"<over>\")\n",
    "            over_maps.append(info)\n",
    "        elif int(ans) == 2:\n",
    "            print(\"<under>\")\n",
    "            under_maps.append(info)\n",
    "        else:\n",
    "            print(\"<discard>\")\n",
    "            discarded_maps.append(info)\n",
    "        # plt.clf()\n",
    "        # plt.cla()\n",
    "        plt.close()\n",
    "    return over_maps, under_maps, discarded_maps\n",
    "\n",
    "def save_map_data(mappings, path):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    mappings : _type_\n",
    "        [t1, t2, t1_label, mapping]\n",
    "    path : _type_\n",
    "        _description_\n",
    "    \"\"\"\n",
    "    json_data = []\n",
    "    for smap in mappings:\n",
    "        data = {\n",
    "            \"t1\": smap[0],\n",
    "            \"t2\": smap[1],\n",
    "            \"label\": int(smap[2]),\n",
    "            \"mapping\": {str(k) : v for k, v in smap[3].items()}\n",
    "        }\n",
    "        json_data.append(data)\n",
    "\n",
    "    with open(path, \"w+\") as f:\n",
    "        json.dump(json_data, f)\n",
    "    return json_data\n",
    "\n",
    "%matplotlib inline\n",
    "over_maps, under_maps, discarded_maps = human_loop_answer_over_under_seg(multiple_maps, time2id2sc)\n",
    "\n",
    "pos_data_dir = Path(\"./notebook_results/real_ebss_stav_data\"/pos_path)\n",
    "pos_data_dir.mkdir(exist_ok=True)\n",
    "save_map_data(over_maps, pos_data_dir/(\"overseg_maps_interval-%s.json\" % sample_interval))\n",
    "save_map_data(under_maps, pos_data_dir/ (\"underseg_maps_interval-%s.json\" % sample_interval))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(over_maps), len(under_maps)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load saved over/underseg maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pos_data_dir = Path(\"./notebook_results/real_ebss_stav_data\"/pos_path)\n",
    "# pos_data_dir.mkdir(exist_ok=True)\n",
    "# with open(pos_data_dir/(\"overseg_maps_interval-%s.json\" % sample_interval), \"r\") as f:\n",
    "#     over_maps = json.load(f)\n",
    "# with open(pos_data_dir/ (\"underseg_maps_interval-%s.json\" % sample_interval), \"r\") as f:\n",
    "#     under_maps = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# over_maps = [tuple([map_info[\"t1\"], map_info[\"t2\"], map_info[\"label\"], {int(k): v for k, v in map_info[\"mapping\"].items()}]) for map_info in over_maps]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# under_maps = [tuple([map_info[\"t1\"], map_info[\"t2\"], map_info[\"label\"], {int(k): v for k, v in map_info[\"mapping\"].items()}]) for map_info in under_maps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "over_maps"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COCO\n",
    "```\n",
    "{\n",
    "    \"info\": {...},\n",
    "    \"licenses\": [...],\n",
    "    \"images\": [...],\n",
    "    \"annotations\": [...],\n",
    "    \"categories\": [...], <-- Not in Captions annotations\n",
    "    \"segment_info\": [...] <-- Only in Panoptic annotations\n",
    "}\n",
    "\n",
    "\"annotations\": [\n",
    "    {\n",
    "        \"segmentation\": [[510.66,423.01,511.72,420.03,...,510.45,423.01]],\n",
    "        \"area\": 702.1057499999998,\n",
    "        \"iscrowd\": 0,\n",
    "        \"image_id\": 289343,\n",
    "        \"bbox\": [473.07,395.93,38.65,28.67],\n",
    "        \"category_id\": 18,\n",
    "        \"id\": 1768\n",
    "    },\n",
    "    ...\n",
    "    {\n",
    "        \"segmentation\": {\n",
    "            \"counts\": [179,27,392,41,â€¦,55,20],\n",
    "            \"size\": [426,640]\n",
    "        },\n",
    "        \"area\": 220834,\n",
    "        \"iscrowd\": 1,\n",
    "        \"image_id\": 250282,\n",
    "        \"bbox\": [0,34,639,388],\n",
    "        \"category_id\": 1,\n",
    "        \"id\": 900100250282\n",
    "    }\n",
    "]\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_label2sc = {}\n",
    "for sc in single_cells:\n",
    "    time_label2sc[(sc.timeframe, sc.id)] = sc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OVER_GT_CAT_ID=0\n",
    "UNDER_GT_CAT_ID=1\n",
    "OVER_CAT_ID=2\n",
    "UNDER_CAT_ID=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert label maps to coco\n",
    "\n",
    "def ou_maps_to_coco(data, mask_dataset: LiveCellImageDataset, img_dataset: LiveCellImageDataset, mode, over_gt_cat_id=0,under_gt_cat_id=1, over_cat_id=2, under_cat_id=3):\n",
    "    \"\"\"save over/under segmentation maps to coco format. \n",
    "    <associated_ann_id> key in annotation keys connects the over or under gt and wrong masks.\n",
    "    1. over-segmentation cases, the over-segmentation (one mask) is the ground truth. All the wrong segmentations have the same <associated_ann_id> as the ground truth.\n",
    "    2. under-segmentation cases, the under-segmentation (several masks) masks are the ground truth. All the CORRECT segmentations have the same <associated_ann_id> as the wrong masks.\n",
    "    Four categories can be created: \n",
    "    1. over-segmentation ground truth\n",
    "    2. under-segmentation ground truth\n",
    "    3. over-segmentation\n",
    "    4. under-segmentation\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : _type_\n",
    "        [(t1, t2, t1_label, mapping), ...)]\n",
    "    mask_dataset : _type_\n",
    "        _description_\n",
    "    img_dataset : _type_\n",
    "        _description_\n",
    "    \"\"\"    \n",
    "\n",
    "    def get_coco_contour_from_sc(sc):\n",
    "        contour = np.copy(sc.contour)\n",
    "        contour[:, 0], contour[:, 1] = sc.contour[:, 1], sc.contour[:, 0]\n",
    "        contour = [list([list([int(coord) for coord in pos]) for pos in contour])]\n",
    "        return contour\n",
    "    \n",
    "    res_coco = {\n",
    "        \"annotations\": [],\n",
    "        \"images\": [],\n",
    "        \"categories\": [\n",
    "            {\"supercategory\": \"seg\",\"id\": 0,\"name\": \"gt\"},\n",
    "            {\"supercategory\": \"seg\",\"id\": 1,\"name\": \"overseg\"},\n",
    "            {\"supercategory\": \"seg\",\"id\": 2,\"name\": \"underseg\"},\n",
    "            \n",
    "        ],\n",
    "        \"info\": {\n",
    "            \"description\": \"over/under segmentation maps\",\n",
    "        }\n",
    "    }\n",
    "\n",
    "    times = list(img_dataset.time2url.keys())\n",
    "    for time in times:\n",
    "        img = img_dataset.get_img_by_time(time)\n",
    "        res_coco[\"images\"].append({\n",
    "            \"id\": int(time),\n",
    "            \"file_name\": img_dataset.time2url[time],\n",
    "            \"coco_url\": img_dataset.time2url[time],\n",
    "            \"height\": int(img.shape[1]),\n",
    "            \"width\": int(img.shape[0])\n",
    "        })\n",
    "\n",
    "    if mode == \"overseg\":\n",
    "        t1_cat_label = over_gt_cat_id\n",
    "        t2_cat_label = over_cat_id\n",
    "    elif mode == \"underseg\":\n",
    "        t1_cat_label = under_cat_id\n",
    "        t2_cat_label = under_gt_cat_id\n",
    "    ann_id = 0\n",
    "    for idx, (t1, t2, t1_label, mapping) in enumerate(data):\n",
    "        sc = time_label2sc[(t1, t1_label)]\n",
    "        img_url = img_dataset.time2url[sc.timeframe]\n",
    "        img_id = int(sc.timeframe)\n",
    "        res_coco[\"annotations\"].append({\n",
    "            \"id\": ann_id,\n",
    "            \"image_id\": int(img_id),\n",
    "            \"category_id\": int(t1_cat_label), # gt\n",
    "            \"segmentation\": get_coco_contour_from_sc(sc),\n",
    "            \"label\": int(t1_label),\n",
    "        })\n",
    "        associated_ann_id = ann_id\n",
    "        ann_id += 1\n",
    "        for t2_label in mapping:\n",
    "            tmp_sc = time_label2sc[(t2, t2_label)]\n",
    "            res_coco[\"annotations\"].append({\n",
    "                \"id\": ann_id,\n",
    "                \"image_id\": int(img_id),\n",
    "                \"category_id\": int(t2_cat_label), # overseg\n",
    "                \"segmentation\": get_coco_contour_from_sc(tmp_sc),\n",
    "                \"associated_ann_id\": associated_ann_id,\n",
    "                \"label\": int(t2_label),\n",
    "            })\n",
    "            ann_id += 1\n",
    "    return res_coco\n",
    "\n",
    "\n",
    "over_coco = ou_maps_to_coco(over_maps, label_mask_dataset, dic_dataset, \"overseg\")\n",
    "under_coco = ou_maps_to_coco(under_maps, label_mask_dataset, dic_dataset, \"underseg\")\n",
    "\n",
    "with open(pos_data_dir/(\"coco_overseg_interval-%s.json\" % sample_interval), \"w+\") as f:\n",
    "    json.dump(over_coco, f)\n",
    "with open(pos_data_dir/(\"coco_underseg_interval-%s.json\" % sample_interval), \"w+\") as f:\n",
    "    json.dump(under_coco, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(over_maps), len(under_maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "padding=200\n",
    "sc.show_contour_mask(crop=True, padding=padding)\n",
    "\n",
    "contour_coords = sc.get_contour_coords_on_crop(padding=padding)\n",
    "plt.scatter(contour_coords[:, 1], contour_coords[:, 0], s=1, c=\"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    some_map = random.sample(over_maps, 1)[0]\n",
    "    t1, t2, t1_label, mapping = some_map\n",
    "    sc = time_label2sc[(t1, t1_label)]\n",
    "    print(len(sc.contour))\n",
    "    sc.show_panel()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_data = COCO(pos_data_dir/(\"coco_overseg_interval-%s.json\" % sample_interval))\n",
    "overseg_scs = coco_to_sc(coco_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "over_seg_gt_scs = []\n",
    "for sc in overseg_scs:\n",
    "    if sc.meta[\"category_id\"] == OVER_GT_CAT_ID:\n",
    "        sc.uns[\"associated_scs\"] = []\n",
    "        for other_sc in overseg_scs:\n",
    "            if \"associated_ann_id\" in other_sc.meta and other_sc.meta[\"associated_ann_id\"] == sc.meta[\"id\"]:\n",
    "                sc.uns[\"associated_scs\"].append(other_sc)\n",
    "                assert other_sc.meta[\"category_id\"] == OVER_CAT_ID # must be over-segmentation cat id\n",
    "        over_seg_gt_scs.append(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check `over_seg_gt_scs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(5):\n",
    "    sc = random.sample(over_seg_gt_scs, 1)[0]\n",
    "    sc.show_panel(padding=0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(over_seg_gt_scs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from livecell_tracker.segment.ou_utils import csn_augment_helper"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save overseg cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subdir = Path(\"real_overseg_td1_\" + str(pos_path))\n",
    "overseg_out_dir = out_dir / subdir\n",
    "raw_out_dir = overseg_out_dir / \"raw\"\n",
    "\n",
    "# seg_out_dir is the directory containing all raw segmentation masks for training\n",
    "# e.g. the eroded raw segmentation masks\n",
    "seg_out_dir = overseg_out_dir / \"seg\"\n",
    "\n",
    "# raw_seg_dir is the directory containing all raw segmentation masks for recording purposes\n",
    "raw_seg_dir = overseg_out_dir / \"raw_seg_crop\"\n",
    "gt_out_dir = overseg_out_dir / \"gt\"\n",
    "gt_label_out_dir = overseg_out_dir / \"gt_label_mask\"\n",
    "augmented_seg_dir = overseg_out_dir / \"augmented_seg\"\n",
    "raw_transformed_img_dir = overseg_out_dir / \"raw_transformed_img\"\n",
    "augmented_diff_seg_dir = overseg_out_dir / \"augmented_diff_seg\"\n",
    "meta_path = overseg_out_dir / \"metadata.csv\"\n",
    "overseg_df_save_path = overseg_out_dir / \"data.csv\"\n",
    "\n",
    "os.makedirs(raw_out_dir, exist_ok=True)\n",
    "os.makedirs(seg_out_dir, exist_ok=True)\n",
    "os.makedirs(raw_seg_dir, exist_ok=True)\n",
    "os.makedirs(gt_out_dir, exist_ok=True)\n",
    "os.makedirs(augmented_seg_dir, exist_ok=True)\n",
    "os.makedirs(gt_label_out_dir, exist_ok=True)\n",
    "os.makedirs(raw_transformed_img_dir, exist_ok=True)\n",
    "os.makedirs(augmented_diff_seg_dir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate label of scs\n",
    "# over_seg_gt_scs = parallelize(set_sc_label, [[sc] for sc in over_seg_gt_scs], cores=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import pandas as pd\n",
    "overseg_erosion_scale_factors = np.linspace(-0.1, 0, 10)\n",
    "overseg_train_path_tuples = []\n",
    "augmented_overseg_data = []\n",
    "sample_id = 0\n",
    "\n",
    "all_df = None\n",
    "for sc in tqdm.tqdm(over_seg_gt_scs):\n",
    "    img_crop = sc.get_img_crop()\n",
    "    combined_gt_label_mask = sc.get_contour_mask()\n",
    "    \n",
    "    associated_scs = sc.uns[\"associated_scs\"]\n",
    "    seg_crop = np.zeros(combined_gt_label_mask.shape, dtype=np.uint8)\n",
    "    assert len(associated_scs) > 0 and len(associated_scs) < 256, \"number of associated scs must be in [1, 255]\"\n",
    "    for idx, other_sc in enumerate(associated_scs):\n",
    "        other_seg_crop = other_sc.get_contour_mask(bbox=sc.bbox, crop=False)\n",
    "        seg_crop[other_seg_crop > 0] = idx + 1\n",
    "\n",
    "    raw_seg_crop = sc.get_img_crop()\n",
    "    \n",
    "    img_id = sc.meta[\"img_id\"]\n",
    "    filename_pattern = \"img-%d_sample-%d.tif\"\n",
    "    raw_img_path = raw_out_dir / (\"img-%d_sample-%d.tif\" % (img_id, sample_id))\n",
    "    seg_img_path = seg_out_dir / (\"img-%d_sample-%d.tif\" % (img_id, sample_id))\n",
    "    gt_img_path = gt_out_dir / (\"img-%d_sample-%d.tif\" % (img_id, sample_id))\n",
    "    gt_label_img_path = gt_label_out_dir / (\"img-%d_sample-%d.tif\" % (img_id, sample_id))\n",
    "    raw_seg_img_path = raw_seg_dir / (filename_pattern % (img_id, sample_id))\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 4, figsize=(15, 5))\n",
    "    axes[0].imshow(img_crop)\n",
    "    axes[0].set_title(\"img_crop\")\n",
    "    axes[1].imshow(seg_crop)\n",
    "    axes[1].set_title(\"seg_crop\")\n",
    "    axes[2].imshow(raw_seg_crop)\n",
    "    axes[2].set_title(\"raw_seg_crop\")\n",
    "    axes[3].imshow(combined_gt_label_mask)\n",
    "    axes[3].set_title(\"combined_gt_label_mask\")\n",
    "    plt.show()\n",
    "    res_dict = csn_augment_helper(img_crop=img_crop, \n",
    "            seg_label_crop=seg_crop, \n",
    "            combined_gt_label_mask=combined_gt_label_mask,\n",
    "            overseg_raw_seg_crop=raw_seg_crop,\n",
    "            overseg_raw_seg_img_path=raw_seg_img_path,\n",
    "            scale_factors=overseg_erosion_scale_factors,\n",
    "            train_path_tuples=overseg_train_path_tuples,\n",
    "            augmented_data=augmented_overseg_data,\n",
    "            img_id=img_id,\n",
    "            seg_label=sample_id,\n",
    "            gt_label=None, # t1 sc's label\n",
    "            raw_img_path=raw_img_path,\n",
    "            seg_img_path=seg_img_path,\n",
    "            gt_img_path=gt_img_path,\n",
    "            gt_label_img_path=gt_label_img_path,\n",
    "            augmented_seg_dir=augmented_seg_dir,\n",
    "            augmented_diff_seg_dir=augmented_diff_seg_dir,\n",
    "            filename_pattern=filename_pattern,\n",
    "            raw_transformed_img_dir=raw_transformed_img_dir,\n",
    "            # df_save_path=overseg_df_save_path,\n",
    "    )\n",
    "    df = res_dict[\"df\"]\n",
    "    all_df = df # because we pass train_path_tuples by reference, we don't need to concatenate df\n",
    "\n",
    "with open(overseg_df_save_path, \"w+\") as f:\n",
    "    all_df.to_csv(f, index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save underseg cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "underseg_coco_data = COCO(pos_data_dir/(\"coco_underseg_interval-%s.json\" % sample_interval))\n",
    "underseg_scs = coco_to_sc(underseg_coco_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "under_seg_gt_scs = []\n",
    "for sc in underseg_scs:\n",
    "    if sc.meta[\"category_id\"] == UNDER_GT_CAT_ID:\n",
    "        sc.uns[\"associated_scs\"] = []\n",
    "        for other_sc in underseg_scs:\n",
    "            if sc.meta[\"associated_ann_id\"] == other_sc.meta[\"id\"]:\n",
    "                sc.uns[\"associated_scs\"].append(other_sc)\n",
    "                assert other_sc.meta[\"category_id\"] == UNDER_CAT_ID # must be over-segmentation cat id\n",
    "        under_seg_gt_scs.append(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "underseg_sc2scs = {}\n",
    "for sc in under_seg_gt_scs:\n",
    "    assert len(sc.uns[\"associated_scs\"]) == 1, \"under-segmentation gt sc must have exactly one associated sc\"\n",
    "    underseg_sc = sc.uns[\"associated_scs\"][0]\n",
    "    if underseg_sc in underseg_sc2scs:\n",
    "        underseg_sc2scs[underseg_sc].append(sc)\n",
    "    else:\n",
    "        underseg_sc2scs[underseg_sc] = [sc]\n",
    "\n",
    "len(underseg_sc2scs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from livecell_tracker.segment.ou_utils import csn_augment_helper, underseg_overlay_gt_masks, underseg_overlay_scs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subdir = Path(\"real_underseg_td1_\" + str(pos_path))\n",
    "underseg_out_dir = out_dir / subdir\n",
    "raw_out_dir = underseg_out_dir / \"raw\"\n",
    "\n",
    "# seg_out_dir is the directory containing all raw segmentation masks for training\n",
    "# e.g. the eroded raw segmentation masks\n",
    "seg_out_dir = underseg_out_dir / \"seg\"\n",
    "\n",
    "# raw_seg_dir is the directory containing all raw segmentation masks for recording purposes\n",
    "raw_seg_dir = underseg_out_dir / \"raw_seg_crop\"\n",
    "gt_out_dir = underseg_out_dir / \"gt\"\n",
    "gt_label_out_dir = underseg_out_dir / \"gt_label_mask\"\n",
    "augmented_seg_dir = underseg_out_dir / \"augmented_seg\"\n",
    "raw_transformed_img_dir = underseg_out_dir / \"raw_transformed_img\"\n",
    "augmented_diff_seg_dir = underseg_out_dir / \"augmented_diff_seg\"\n",
    "meta_path = underseg_out_dir / \"metadata.csv\"\n",
    "underseg_df_save_path = underseg_out_dir / \"data.csv\"\n",
    "\n",
    "os.makedirs(raw_out_dir, exist_ok=True)\n",
    "os.makedirs(seg_out_dir, exist_ok=True)\n",
    "os.makedirs(raw_seg_dir, exist_ok=True)\n",
    "os.makedirs(gt_out_dir, exist_ok=True)\n",
    "os.makedirs(augmented_seg_dir, exist_ok=True)\n",
    "os.makedirs(gt_label_out_dir, exist_ok=True)\n",
    "os.makedirs(raw_transformed_img_dir, exist_ok=True)\n",
    "os.makedirs(augmented_diff_seg_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "scale_factors = np.linspace(0, 0.3, 10)\n",
    "train_path_tuples = []\n",
    "augmented_data = []\n",
    "all_df = None\n",
    "for sc in tqdm.tqdm(underseg_sc2scs):\n",
    "    scs = underseg_sc2scs[sc]\n",
    "    img_id, seg_label = int(sc.timeframe), int(sc.meta[\"label\"])\n",
    "    assert len(scs) > 0, \"the list of single cells should not be empty\"\n",
    "    # sc.show_panel()\n",
    "    (img_crop, seg_crop, combined_gt_label_mask) = underseg_overlay_scs(sc, scs, padding_scale=2)\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    axes[0].imshow(img_crop)\n",
    "    axes[0].set_title(\"img_crop\")\n",
    "    axes[1].imshow(seg_crop)\n",
    "    axes[1].set_title(\"seg_crop\")\n",
    "    axes[2].imshow(combined_gt_label_mask)\n",
    "    axes[2].set_title(\"combined_gt_label_mask\")\n",
    "\n",
    "    raw_img_path = raw_out_dir / (\"img-%d_seg-%d.tif\" % (img_id, seg_label))\n",
    "    seg_img_path = seg_out_dir / (\"img-%d_seg-%d.tif\" % (img_id, seg_label))\n",
    "    gt_img_path = gt_out_dir / (\"img-%d_seg-%d.tif\" % (img_id, seg_label))\n",
    "    gt_label_img_path = gt_label_out_dir / (\"img-%d_seg-%d.tif\" % (img_id, seg_label))\n",
    "\n",
    "    # call csn augment helper\n",
    "    res_dict = csn_augment_helper(img_crop=img_crop, \n",
    "        seg_label_crop=seg_crop, \n",
    "        combined_gt_label_mask=combined_gt_label_mask,\n",
    "        scale_factors=scale_factors,\n",
    "        train_path_tuples=train_path_tuples,\n",
    "        augmented_data=augmented_data,\n",
    "        img_id=img_id,\n",
    "        seg_label=seg_label,\n",
    "        gt_label=None,\n",
    "        raw_img_path=raw_img_path,\n",
    "        seg_img_path=seg_img_path,\n",
    "        gt_img_path=gt_img_path,\n",
    "        gt_label_img_path=gt_label_img_path,\n",
    "        augmented_seg_dir=augmented_seg_dir,\n",
    "        augmented_diff_seg_dir=augmented_diff_seg_dir,\n",
    "        raw_transformed_img_dir=raw_transformed_img_dir,\n",
    "    )\n",
    "    all_df = res_dict[\"df\"]\n",
    "    \n",
    "all_df.to_csv(underseg_df_save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from livecell_tracker.segment.ou_utils import csn_augment_helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataframes = []\n",
    "for subdir in out_dir.iterdir():\n",
    "    if subdir.is_dir():\n",
    "        data_path = subdir / \"data.csv\"\n",
    "        dataframe = pd.read_csv(data_path)\n",
    "        dataframe[\"subdir\"] = subdir.name\n",
    "        dataframes.append(dataframe)\n",
    "combined_dataframe = pd.concat(dataframes)\n",
    "combined_dataframe.to_csv(out_dir / \"train_data.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "livecell",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d9c7226d793827cd27273ad20fbb4775c3cb91053ab9378a09de5f8c6f258919"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
