{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a cellpose to segment A549 cells  \n",
    "Author: Ke  \n",
    "Data source: Dr. Weikang Wang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install omnipose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from cellpose import models\n",
    "from cellpose.io import imread\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path for saving re-fitted cellpose model\n",
    "model_save_path = Path(\"./results/cellpose/cellpose_A549_cyto2_cellbody_bg_corrected\")\n",
    "model_save_path.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data for training models from CellPose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dirs = [\n",
    "    r\"D:\\LiveCellTracker-dev\\datasets\\nidhi_data_8-7-2023\\nidhi-training-9-28\"\n",
    "]\n",
    "raw_img_dir = [Path(path) / \"Img\" for path in data_dirs]\n",
    "dist_img_dir = [Path(path) / \"Bwdist\" for path in data_dirs]\n",
    "mask_img_dir = [Path(path) / \"Interior\" for path in data_dirs]\n",
    "\n",
    "# check if paths exist\n",
    "for i in range(len(raw_img_dir)):\n",
    "    assert raw_img_dir[i].exists(), f\"{raw_img_dir[i]} does not exist\"\n",
    "    assert dist_img_dir[i].exists(), f\"{dist_img_dir[i]} does not exist\"\n",
    "    assert mask_img_dir[i].exists(), f\"{mask_img_dir[i]} does not exist\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_img_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_img_paths = [sorted(list(path.glob(\"*.tif\"))) for path in raw_img_dir]\n",
    "dist_img_paths = [sorted(list(path.glob(\"*.tif\"))) for path in dist_img_dir]\n",
    "mask_img_paths = [sorted(list(path.glob(\"*.png\"))) for path in mask_img_dir]\n",
    "\n",
    "# check existence of all images\n",
    "for i in range(len(raw_img_dir)):\n",
    "    assert len(raw_img_paths[i]) == len(\n",
    "        mask_img_paths[i]\n",
    "    ), f\"Number of images in {raw_img_dir[i]}, {dist_img_dir[i]}, {mask_img_dir[i]} do not match, number of images: {len(raw_img_paths[i])}, {len(dist_img_paths[i])}, {len(mask_img_paths[i])}\"\n",
    "\n",
    "# flatten all lists\n",
    "raw_img_paths = [item for sublist in raw_img_paths for item in sublist]\n",
    "dist_img_paths = [item for sublist in dist_img_paths for item in sublist]\n",
    "mask_img_paths = [item for sublist in mask_img_paths for item in sublist]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read images\n",
    "raw_imgs = [imread(str(path)) for path in raw_img_paths]\n",
    "dist_imgs = [imread(str(path)) for path in dist_img_paths]\n",
    "mask_imgs = [imread(str(path)) for path in mask_img_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(raw_imgs), len(dist_imgs), len(mask_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# squeeze images\n",
    "raw_imgs = [img.squeeze() for img in raw_imgs]\n",
    "dist_imgs = [img.squeeze() for img in dist_imgs]\n",
    "mask_imgs = [img.squeeze() for img in mask_imgs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_imgs[0].shape, type(raw_imgs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# convert raw rgb images to grayscale via opencv\n",
    "raw_imgs = [cv2.cvtColor(img, cv2.COLOR_RGB2GRAY) for img in raw_imgs]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check image shape match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(raw_imgs)):\n",
    "    assert (\n",
    "        raw_imgs[i].shape ==  mask_imgs[i].shape\n",
    "    ), f\"Image shapes do not match for image {i}, {raw_imgs[i].shape}, {mask_imgs[i].shape}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(raw_imgs), len(dist_imgs), len(mask_imgs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the following assumptions  \n",
    "    when Dr. WWK annotated datasets, he intentionally avoid overlapping masks, so we can obtain label masks simply by label()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from livecellx.preprocess.utils import normalize_img_to_uint8, standard_preprocess\n",
    "# normalize images\n",
    "raw_imgs = [standard_preprocess(img) for img in raw_imgs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage\n",
    "label_mask_imgs = [skimage.measure.label(mask_img) for mask_img in mask_imgs]\n",
    "\n",
    "# counter how many mask labels are empty\n",
    "empty_mask_label_count = 0\n",
    "for i in range(len(label_mask_imgs)):\n",
    "    if len(np.unique(label_mask_imgs[i])) <= 1:\n",
    "        empty_mask_label_count += 1\n",
    "        # show image and label mask\n",
    "        # fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "        # ax[0].imshow(raw_imgs[i])\n",
    "        # ax[1].imshow(label_mask_imgs[i])\n",
    "print(f\"Number of empty mask labels: {empty_mask_label_count}\", \"total number of images:\", len(label_mask_imgs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Omnipose prediction before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade mahotas==1.4.13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cellpose_omni import models\n",
    "from cellpose_omni.models import MODEL_NAMES\n",
    "\n",
    "MODEL_NAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'bact_phase_omni'\n",
    "use_GPU=True\n",
    "model = models.CellposeModel(gpu=use_GPU, model_type=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "chans = [0,0] #this means segment based on first channel, no second channel \n",
    "\n",
    "n = [-1] # make a list of integers to select which images you want to segment\n",
    "# n = range(nimg) # or just segment them all \n",
    "\n",
    "# define parameters\n",
    "params = {'channels':chans, # always define this with the model\n",
    "          'rescale': None, # upscale or downscale your images, None = no rescaling \n",
    "          'mask_threshold': -1, # erode or dilate masks with higher or lower values \n",
    "          'flow_threshold': 0, # default is .4, but only needed if there are spurious masks to clean up; slows down output\n",
    "          'transparency': True, # transparency in flow output\n",
    "          'omni': True, # we can turn off Omnipose mask reconstruction, not advised \n",
    "          'cluster': True, # use DBSCAN clustering\n",
    "          'resample': True, # whether or not to run dynamics on rescaled grid or original grid \n",
    "          # 'verbose': False, # turn on if you want to see more output \n",
    "          'tile': False, # average the outputs from flipped (augmented) images; slower, usually not needed \n",
    "          'niter': None, # None lets Omnipose calculate # of Euler iterations (usually <20) but you can tune it for over/under segmentation \n",
    "          'augment': False, # Can optionally rotate the image and average outputs, usually not needed \n",
    "          'affinity_seg': False, # new feature, stay tuned...\n",
    "         }\n",
    "\n",
    "tic = time.time() \n",
    "masks, flows, styles = model.eval([raw_imgs[i] for i in n],**params)\n",
    "\n",
    "net_time = time.time() - tic\n",
    "print('total segmentation time: {}s'.format(net_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cellpose_omni import plot\n",
    "import omnipose\n",
    "import matplotlib as mpl\n",
    "\n",
    "\n",
    "for idx,i in enumerate(n):\n",
    "    maski = masks[idx] # get masks\n",
    "    bdi = flows[idx][-1] # get boundaries\n",
    "    flowi = flows[idx][0] # get RGB flows \n",
    "\n",
    "    # set up the output figure to better match the resolution of the images \n",
    "    f = 10\n",
    "    szX = maski.shape[-1]/mpl.rcParams['figure.dpi']*f\n",
    "    szY = maski.shape[-2]/mpl.rcParams['figure.dpi']*f\n",
    "    fig = plt.figure(figsize=(szY,szX*4))\n",
    "    fig.patch.set_facecolor([0]*4)\n",
    "    \n",
    "    plot.show_segmentation(fig, omnipose.utils.normalize99(raw_imgs[i]), \n",
    "                           maski, flowi, bdi, channels=chans, omni=True,\n",
    "                           interpolation=None)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tune on a cellpose model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = r\"D:\\LiveCellTracker-dev\\notebooks\\application_nidhi_JC\\results\\cellpose\\cellpose_A549_cyto2_cellbody_bg_corrected\\models\\cellpose_residual_on_style_on_concatenation_off_cellpose_A549_cyto2_cellbody_bg_corrected_2023_09_28_05_00_13.696883\"\n",
    "model = models.CellposeModel(gpu=True, pretrained_model=model_path)\n",
    "# model.sz.cp.train(train_data=raw_imgs, train_labels=label_mask_imgs, batch_size=5, channels=[0,0], n_epochs=10000, save_path=model_save_path)\n",
    "model.train(raw_imgs, label_mask_imgs, channels=[0,0], n_epochs=10000, save_path=model_save_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Randomly show 10 prediction samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_imgs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from livecellx.segment.cellpose_utils import segment_single_image_by_cellpose\n",
    "\n",
    "for _ in range(5):\n",
    "    index = np.random.randint(0, len(raw_imgs))\n",
    "    # masks = segment_single_image_by_cellpose(raw_imgs[index][0], model, channels=[[0, 0]], diameter=40)\n",
    "    result_tuple = model.eval([raw_imgs[index][0]], diameter=55, channels=[[0, 0]])\n",
    "    # masks, flows, styles, diams = result_tuple\n",
    "    masks, flows, styles = result_tuple\n",
    "    assert len(masks) == 1\n",
    "    masks = masks[0]\n",
    "    flows = flows[0]\n",
    "    print(\"masks shape: \", masks.shape)\n",
    "    print(\"flows length: \", len(flows))\n",
    "    print(\"flows shape: \", flows[0].shape)\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    axes[0].imshow(raw_imgs[index][0])\n",
    "    axes[0].set_title(\"raw image\")\n",
    "    axes[1].imshow(masks)\n",
    "    axes[1].set_title(\"cellpose mask\")\n",
    "    axes[2].imshow(label_mask_imgs[index])\n",
    "    axes[2].set_title(\"label mask\")\n",
    "    plt.show()\n",
    "\n",
    "    flow_fig, flow_axes = plt.subplots(1, 5, figsize=(20, 5))\n",
    "    flow_axes[0].imshow(flows[0])\n",
    "    flow_axes[0].set_title(\"hsv\")\n",
    "    flow_axes[1].imshow(flows[1][0])\n",
    "    flow_axes[1].set_title(\"flows ch0\")\n",
    "    flow_axes[2].imshow(flows[1][1])\n",
    "    flow_axes[2].set_title(\"flows ch1\")\n",
    "    flow_axes[3].imshow(flows[2])\n",
    "    flow_axes[3].set_title(\"flows cell prob ch0\")\n",
    "    flow_axes[4].imshow(flows[2] > 0.7)\n",
    "    # flow_axes[4].imshow(flows[2][1])\n",
    "    # flow_axes[4].set_title(\"flows cell prob ch1\")\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict with the model trained on your own data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img_dir = [Path(r\"D:\\LiveCellTracker-dev\\datasets\\nidhi_data_8-7-2023\\data\\images\")]\n",
    "test_img_paths = [sorted(list(path.glob(\"*.tif\"))) for path in test_img_dir]\n",
    "\n",
    "test_img_paths = test_img_paths[0]\n",
    "test_imgs = [imread(str(path)) for path in test_img_paths]\n",
    "\n",
    "# Nidhi's images are RGB with all channels the same, so we can just take the first channel\n",
    "test_imgs = [img[:, :, 0] for img in test_imgs]\n",
    "\n",
    "masks, flows, styles = model.eval(test_imgs,**params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_imgs[i].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_out_dir = Path(\"./pred_outs\")\n",
    "pred_out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Predict on test_img_paths\n",
    "for idx in range(len(masks)):\n",
    "    maski = masks[idx] # get masks\n",
    "    bdi = flows[idx][-1] # get boundaries\n",
    "    flowi = flows[idx][0] # get RGB flows \n",
    "\n",
    "    # set up the output figure to better match the resolution of the images \n",
    "    f = 10\n",
    "    szX = maski.shape[-1]/mpl.rcParams['figure.dpi']*f\n",
    "    szY = maski.shape[-2]/mpl.rcParams['figure.dpi']*f\n",
    "    # fig = plt.figure(figsize=(szY,szX*4))\n",
    "    fig = plt.figure(figsize=(100, 25))\n",
    "    fig.patch.set_facecolor([0]*4)\n",
    "    # print(test_imgs[idx].shape, maski.shape, flowi.shape, bdi.shape)\n",
    "    plot.show_segmentation(fig, omnipose.utils.normalize99(test_imgs[idx]), \n",
    "                           maski, flowi, bdi, channels=chans, omni=True,\n",
    "                           interpolation=None)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    \n",
    "\n",
    "    plt_file_path = pred_out_dir / f\"pred_{idx}.png\"\n",
    "    mask_file_path = pred_out_dir / f\"mask_{idx}.png\"\n",
    "    plt.savefig(plt_file_path)\n",
    "    plt.imsave(mask_file_path, maski)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    # save the images"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "livecell",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d9c7226d793827cd27273ad20fbb4775c3cb91053ab9378a09de5f8c6f258919"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
