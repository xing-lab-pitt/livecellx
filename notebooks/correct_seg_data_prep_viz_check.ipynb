{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import TQDMProgressBar\n",
    "\n",
    "from livecellx.model_zoo.segmentation.sc_correction import CorrectSegNet\n",
    "import numpy as np\n",
    "import warnings\n",
    "import tqdm\n",
    "torch.manual_seed(237)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.is_available(), torch.cuda.current_device(), torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import torch\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import TQDMProgressBar\n",
    "\n",
    "from livecellx.model_zoo.segmentation.sc_correction import CorrectSegNet\n",
    "from livecellx.model_zoo.segmentation.sc_correction_dataset import CorrectSegNetDataset\n",
    "torch.manual_seed(237)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "# train_dir = Path(\"./notebook_results/a549_ccp_vim/train_data_v4/\")\n",
    "# test_dir = Path(\"./notebook_results/a549_ccp_vim/test_data_v4/\")\n",
    "# train_dir = Path(\"./notebook_results/a549_ccp_vim/train_data_v5/\")\n",
    "# test_dir = Path(\"./notebook_results/a549_ccp_vim/test_data_v5/\")\n",
    "\n",
    "# train_dir = Path(\"./notebook_results/a549_ccp_vim/train_data_v8/\")\n",
    "# test_dir = Path(\"./notebook_results/a549_ccp_vim/test_data_v8/\")\n",
    "# train_csv = train_dir / \"train_data.csv\"\n",
    "\n",
    "# train_csv = \"./notebook_results/a549_ccp_vim/train_real_td_data/real_underseg_td1_XY8/data.csv\"\n",
    "# train_csv = \"./notebook_results/a549_ccp_vim/train_real_td_data/real_overseg_td1_XY9/data.csv\"\n",
    "# train_csv = \"./notebook_results/a549_ccp_vim/train_data_v11/test_overseg_dropout/data.csv\"\n",
    "# train_csv = \"/home/ken67/LiveCellTracker-dev/notebooks/notebook_results/a549_ccp_vim/test_data_v11/real_overseg_td1_XY5_dropout/data.csv\"\n",
    "train_csv = \"/home/ken67/LiveCellTracker-dev/notebooks/notebook_results/a549_ccp_vim/train_data_v11/train_data.csv\"\n",
    "# train_csv = \"/home/ken67/LiveCellTracker-dev/notebooks/notebook_results/a549_ccp_vim/test_data_v11/train_data.csv\"\n",
    "# train_csv = \"D:\\\\LiveCellTracker-dev\\\\datasets\\\\yaxuan_csn_annotation\\\\train_data.csv\"\n",
    "# train_csv = \"/home/ken67/LiveCellTracker-dev/notebooks/notebook_results/a549_ccp_vim/train_data_v6/synthetic_overseg/data.csv\"\n",
    "# train_csv = \"/home/ken67/LiveCellTracker-dev/notebooks/notebook_results/a549_ccp_vim/train_data_v9/synthetic_overseg/data.csv\"\n",
    "\n",
    "# train_csv = r\"/home/ken67/LiveCellTracker-dev/notebooks/notebook_results/a549_ccp_vim/train_data_v6/synthetic_overseg/data.csv\"\n",
    "train_df = pd.read_csv(train_csv)\n",
    "\n",
    "if \"subdir\" not in train_df.columns:\n",
    "    train_df[\"subdir\"] = \"cur\"\n",
    "# test_df = pd.read_csv(test_dir / \"train_data.csv\")\n",
    "train_df[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check all gt labels: any empty?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from livecellx.core.datasets import read_img_default\n",
    "\n",
    "def check_unique_labels(img_paths):\n",
    "    for path in img_paths:\n",
    "        # read tiff\n",
    "        gt_tif = read_img_default(path)\n",
    "        # print(\"gt shape:\", gt_tif.shape)\n",
    "        # print(\"unique labels:\", np.unique(gt_tif))\n",
    "        assert np.unique(gt_tif.flatten()).shape[0] > 1, \"#unique labels should be > 1\"\n",
    "\n",
    "# # check all gt label's unique labels\n",
    "# gt_paths = train_df[\"gt\"].values\n",
    "# check_unique_labels(gt_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from livecellx.model_zoo.segmentation.eval_csn import compute_metrics, assemble_train_test_dataset\n",
    "\n",
    "# model = CorrectSegNet.load_from_checkpoint(r\"/home/ken67/LiveCellTracker-dev/notebooks/lightning_logs/version_v11_02/checkpoints/epoch=3819-global_step=0.ckpt\")\n",
    "# train_dataset_eval, val_dataset_eval, test_dataset_eval, whole_dataset_eval = assemble_train_test_dataset(train_df, train_df, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from livecellx.model_zoo.segmentation.eval_csn import assemble_dataset, assemble_train_test_dataset\n",
    "\n",
    "# split_seed = 237\n",
    "# dataset = assemble_dataset(train_df, apply_gt_seg_edt = model.apply_gt_seg_edt, exclude_raw_input_bg=model.exclude_raw_input_bg, input_type=model.input_type)\n",
    "# train_sample_num = int(len(dataset) * 0.8)\n",
    "# val_sample_num = len(dataset) - train_sample_num\n",
    "# split_generator = torch.Generator().manual_seed(split_seed)\n",
    "# train_dataset, val_dataset = torch.utils.data.random_split(\n",
    "#     dataset, [train_sample_num, val_sample_num], generator=split_generator\n",
    "# )\n",
    "\n",
    "# test_dataset = assemble_dataset(test_df, apply_gt_seg_edt = model.apply_gt_seg_edt, exclude_raw_input_bg=model.exclude_raw_input_bg, input_type=model.input_type)\n",
    "train_dataset = assemble_dataset(train_df, apply_gt_seg_edt = True, exclude_raw_input_bg=False, input_type=\"raw_aug_duplicate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "train_dataset.transform =     transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize((412, 412))\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viz training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.normalize_uint8=False\n",
    "train_dataset.apply_gt_seg_edt = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_dataset), len(train_dataset.raw_img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset[0][\"input\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "def viz_sample_only(sample, cmap = \"viridis\"):\n",
    "    num_imgs = 7\n",
    "    size = 10\n",
    "    fig, axes = plt.subplots(1, num_imgs, figsize=(size * num_imgs, size))\n",
    "    fig.set_facecolor(\"white\")\n",
    "    # Remove the spaces between subfigures\n",
    "    fig.subplots_adjust(wspace=0, hspace=0)\n",
    "\n",
    "    norm = plt.Normalize(vmin=0, vmax=1)\n",
    "    ax_idx = 0\n",
    "    ax = axes[ax_idx]\n",
    "    ax.imshow(sample[\"input\"][0], cmap = cmap)\n",
    "    ax.set_title(\"input: dim0\")\n",
    "\n",
    "    ax_idx += 1\n",
    "    ax = axes[ax_idx]\n",
    "    ax.imshow(sample[\"input\"][1], cmap = cmap)\n",
    "    ax.set_title(\"input: dim1\")\n",
    "\n",
    "    ax_idx += 1\n",
    "    ax = axes[ax_idx]\n",
    "    ax.imshow(sample[\"input\"][2], cmap = cmap)\n",
    "    ax.set_title(\"input:dim2\")\n",
    "\n",
    "    # gt\n",
    "    ax_idx += 1\n",
    "    ax = axes[ax_idx]\n",
    "    ax.imshow(sample[\"gt_mask\"][0], cmap = cmap)\n",
    "    ax.set_title(\"gt0 seg\")\n",
    "\n",
    "    ax_idx += 1\n",
    "    ax = axes[ax_idx]\n",
    "    ax.imshow(sample[\"gt_mask\"][1], cmap = cmap)\n",
    "    ax.set_title(\"gt1 seg\")\n",
    "\n",
    "    ax_idx += 1\n",
    "    ax = axes[ax_idx]\n",
    "    ax.imshow(sample[\"gt_mask\"][2], cmap = cmap)\n",
    "    ax.set_title(\"gt2 seg\")\n",
    "\n",
    "    ax_idx += 1\n",
    "    ax = axes[ax_idx]\n",
    "    ax.imshow(sample[\"gt_label_mask\"], cmap = cmap)\n",
    "    ax.set_title(\"gt label mask\")\n",
    "\n",
    "    for ax in axes:\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "out_dir = Path(\"./tmp/csn_check_data_v6/\")\n",
    "out_dir.mkdir(exist_ok=True, parents=True)\n",
    "for i in range(4):\n",
    "    sample_id = random.randint(0, len(train_dataset) - 1)\n",
    "    sample = train_dataset[sample_id]\n",
    "    df_row = train_dataset.raw_df.iloc[sample_id]\n",
    "    print(\"source subdir:\", df_row[\"subdir\"])\n",
    "    print(\"sample id:\", sample_id)\n",
    "    # plt.hist(sample[\"input\"][0].flatten(), bins=100)\n",
    "    # plt.hist(sample[\"gt_mask\"][1].flatten(), bins=100)\n",
    "    viz_sample_only(sample, cmap=\"inferno\")\n",
    "    plt.suptitle(f\"sample id: {sample_id}, raw_df subdir: {df_row['subdir']}, raw_path: {df_row['raw']}\", fontsize=5)\n",
    "    # plt.subplots_adjust(top=0.55)\n",
    "    plt.subplots_adjust(wspace=0, hspace=0)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    plt.savefig(out_dir / f\"sample_{sample_id}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in tqdm.tqdm(train_dataset):\n",
    "    gt_label_mask = sample[\"gt_label_mask\"]\n",
    "    assert np.unique(gt_label_mask).shape[0] > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from livecellx.model_zoo.segmentation.eval_csn import compute_metrics\n",
    "import importlib\n",
    "import livecellx.model_zoo.segmentation.eval_csn\n",
    "importlib.reload(livecellx.model_zoo.segmentation.eval_csn)\n",
    "\n",
    "model.cuda()\n",
    "model.eval()\n",
    "metrics = livecellx.model_zoo.segmentation.eval_csn.compute_metrics(train_dataset, model, whole_dataset=train_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "livecell",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d9c7226d793827cd27273ad20fbb4775c3cb91053ab9378a09de5f8c6f258919"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
