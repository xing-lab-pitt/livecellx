{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "from livecell_tracker.core import (\n",
    "    SingleCellTrajectory,\n",
    "    SingleCellStatic,\n",
    "    SingleCellTrajectoryCollection,\n",
    ")\n",
    "from livecell_tracker.segment.detectron_utils import (\n",
    "    convert_detectron_instance_pred_masks_to_binary_masks,\n",
    "    convert_detectron_instances_to_label_masks,\n",
    "    segment_images_by_detectron,\n",
    "    segment_single_img_by_detectron_wrapper,\n",
    ")\n",
    "from livecell_tracker.core.datasets import LiveCellImageDataset\n",
    "from livecell_tracker.preprocess.utils import (\n",
    "    overlay,\n",
    "    enhance_contrast,\n",
    "    normalize_img_to_uint8,\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Labelme Json to COCO Json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run the following code once for generating coco json\n",
    "```\n",
    "import livecell_tracker.segment\n",
    "import livecell_tracker.annotation\n",
    "import livecell_tracker.annotation.labelme2coco\n",
    "import os\n",
    "labelme_json_folder = r\"\"\"../datasets/a549_ccnn/annotation_data\"\"\"\n",
    "dataset_folder_path = r\"\"\"../datasets/a549_ccnn/original_data\"\"\"\n",
    "export_dir = \"./notebook_results/correction_cnn_v0.0.0/\"\n",
    "os.makedirs(export_dir, exist_ok=True)\n",
    "livecell_tracker.annotation.labelme2coco.convert(\n",
    "    labelme_json_folder,\n",
    "    export_dir,\n",
    "    train_split_rate=0.9,\n",
    "    dataset_folder_path=dataset_folder_path,\n",
    "    # is_image_in_json_folder=True,\n",
    "    image_file_ext=\"tif\",\n",
    "    # image_file_ext=\"png\",\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load COCO into SingleCell Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycocotools.coco import COCO\n",
    "\n",
    "coco_data = COCO(\"../datasets/a549_ccnn/a549_ccnn_coco_v0.0.0/train.json\")\n",
    "out_dir = Path(\"./notebook_results/a549_ccp_vim/train_data_v6/\")\n",
    "# coco_data = COCO(\"../datasets/a549_ccnn/a549_ccnn_coco_v0.0.0/val.json\")\n",
    "# out_dir = Path(\"./notebook_results/a549_ccp_vim/test_data_v6/\")\n",
    "# out_dir = Path(\"./notebook_results/a549_ccp_vim/test_data_tmp/\")\n",
    "\n",
    "coco_data.anns.keys(), coco_data.anns[1].keys(), coco_data.anns[1][\"segmentation\"][0][\n",
    "    :5\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_data.imgs.keys(), coco_data.imgs[1].keys(), coco_data.imgs[1][\"file_name\"],\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from livecell_tracker.annotation.coco_utils import coco_to_sc\n",
    "\n",
    "single_cells = coco_to_sc(coco_data)\n",
    "\n",
    "\n",
    "# # for testing\n",
    "# single_cells = single_cells[:20]\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(10, 5))\n",
    "cell_id = 10\n",
    "axes[0].imshow(single_cells[cell_id].get_img_crop(padding=100))\n",
    "axes[1].imshow(single_cells[cell_id].get_contour_mask_closed_form(padding=100))\n",
    "axes[2].imshow(single_cells[cell_id].get_contour_mask(padding=100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(single_cells)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save a list of single cell objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SingleCellStatic.write_single_cells_json(\n",
    "    single_cells, \"../datasets/a549_ccnn/single_cells.json\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contour_mask = single_cells[cell_id].get_contour_mask(padding=100)\n",
    "contour_mask.astype(np.uint8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "from livecell_tracker.preprocess.utils import dilate_or_erode_mask\n",
    "\n",
    "plt.imshow(dilate_or_erode_mask(contour_mask.astype(np.uint8), 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sc = single_cells[cell_id]\n",
    "sample_sc.meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "raw_img_dataset = sample_sc.img_dataset\n",
    "seg_data_dir = \"../datasets/a549_ccnn/seg_tiles_CCP_A549-VIM_lessThan24hr_Calcein_1mg-ml_DP_Ti2e_2022-9-11\"\n",
    "seg_paths = glob.glob(os.path.join(seg_data_dir, \"*.png\"))\n",
    "print(\"sample seg paths:\", seg_paths[:2])\n",
    "matched_time2seg = {}\n",
    "# for time, img_path in raw_img_dataset.time2url.items():\n",
    "#     substr = os.path.basename(img_path).split(\".\")[0]\n",
    "#     print(\"substr:\", substr)\n",
    "#     for seg_path\n",
    "#     break\n",
    "corrected_indices = []\n",
    "for seg_path in seg_paths:\n",
    "    substr = os.path.basename(seg_path).split(\".\")[0] # get rid of extension\n",
    "    substr = substr[4:]  # get rid of seg_ prefix\n",
    "    img, path, index = raw_img_dataset.get_img_by_url(\n",
    "        substr, return_path_and_time=True, ignore_missing=True\n",
    "    )\n",
    "    if path is None:\n",
    "        print(\"skip due to substr not found:\", substr)\n",
    "        continue\n",
    "    matched_time2seg[index] = seg_path\n",
    "\n",
    "seg_data = LiveCellImageDataset(time2url=matched_time2seg, ext=\"png\")\n",
    "sample_sc.mask_dataset = seg_data\n",
    "assert len(seg_data) == len(raw_img_dataset)\n",
    "\n",
    "for sc in single_cells:\n",
    "    assert sc.timeframe in seg_data.time2url\n",
    "    sc.mask_dataset = seg_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Synthetic Undersegmentation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc1 = single_cells[10]\n",
    "sc2 = single_cells[1]\n",
    "\n",
    "padding=20\n",
    "fig, axes = plt.subplots(2, 3, figsize=(10, 5))\n",
    "sc1.show(padding=padding, ax=axes[0][0])\n",
    "sc1.show_contour_img(padding=padding, ax=axes[0][1])\n",
    "sc1.show_contour_mask(padding=padding, ax=axes[0][2])\n",
    "sc2.show(padding=padding, ax=axes[1][0])\n",
    "sc2.show_contour_img(padding=padding, ax=axes[1][1])\n",
    "sc2.show_contour_mask(padding=padding, ax=axes[1][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from livecell_tracker.core.datasets import SingleImageDataset\n",
    "\n",
    "\n",
    "def check_contour_in_boundary(contour, boundary):\n",
    "    return np.all(contour >= 0) and np.all(contour < boundary)\n",
    "\n",
    "\n",
    "def adjust_contour_to_bounds(contour, bounds, bound_shift=-1):\n",
    "    bounds = np.array(bounds)\n",
    "    if not check_contour_in_boundary(contour, bounds):\n",
    "        contour = contour.copy()\n",
    "        contour[contour < 0] = 0\n",
    "        contour = np.where(contour >= bounds, bounds + bound_shift, contour)\n",
    "    return contour\n",
    "\n",
    "def shift_contour_randomly(sc_center, contour, bounds):\n",
    "    random_center = np.random.randint(low=0, high=bounds, size=2)\n",
    "    shift = random_center - sc_center\n",
    "    shift = shift.astype(int)\n",
    "    contour_shifted = contour + shift\n",
    "    return random_center, contour_shifted, shift\n",
    "\n",
    "def compute_two_contours_min_distance(contour1, contour2):\n",
    "    min_dist = np.inf\n",
    "    for p1 in contour1:\n",
    "        for p2 in contour2:\n",
    "            dist = np.linalg.norm(p1 - p2)\n",
    "            if dist < min_dist:\n",
    "                min_dist = dist\n",
    "    return min_dist\n",
    "\n",
    "\n",
    "def _add_sc_to_img_helper(sc, new_img, new_sc_mask, shift, in_place=False):\n",
    "    if not in_place:\n",
    "        new_img = new_img.copy()\n",
    "    sc_ori_space_pixel_xy_arr = np.array(new_sc_mask.nonzero()).T - shift\n",
    "    sc_ori_space_pixel_xy_arr[sc_ori_space_pixel_xy_arr < 0] = 0\n",
    "    new_img[new_sc_mask] = sc.get_contour_img()[sc_ori_space_pixel_xy_arr[:, 0], sc_ori_space_pixel_xy_arr[:, 1]]\n",
    "    return new_img\n",
    "    \n",
    "\n",
    "def add_sc_to_img(sc, new_img, mask, bg_img, in_place=False, mask_inplace=True, fix_sc_pos=False):\n",
    "    bg_shape = np.array(bg_img.shape)\n",
    "    sc_prop = sc.compute_regionprops()\n",
    "    sc_contour_coords = sc.get_contour_coords_on_crop().astype(int)\n",
    "    if fix_sc_pos:\n",
    "        sc_new_center = sc_prop.centroid\n",
    "        sc_new_contour = sc_contour_coords\n",
    "        shift = 0\n",
    "    else:\n",
    "        sc_new_center, sc_new_contour, shift = shift_contour_randomly(sc_prop.centroid, sc_contour_coords, bounds=bg_shape)\n",
    "    sc_new_contour = adjust_contour_to_bounds(sc_new_contour, bg_shape)\n",
    "    new_sc_mask = SingleCellStatic.gen_contour_mask(sc_new_contour, bg_img, bbox=None, crop=False)\n",
    "    new_sc_mask_bool = new_sc_mask > 0 # convert to bool\n",
    "    new_img = _add_sc_to_img_helper(sc, new_img, new_sc_mask, shift, in_place=in_place)\n",
    "\n",
    "    if mask_inplace:\n",
    "        mask = mask.copy()\n",
    "    mask[new_sc_mask_bool] = True\n",
    "    return new_img, sc_new_contour, mask, shift\n",
    "\n",
    "def combine_two_scs_monte_carlo(sc1, sc2, bg_img=None, bg_scale=1.5, fix_sc1=False):\n",
    "    def _gen_empty_bg_img():\n",
    "        sc1_shape = sc1.get_img_crop().shape\n",
    "        sc2_shape = sc2.get_img_crop().shape\n",
    "        bg_shape = np.array([max(sc1_shape[0], sc2_shape[0]), max(sc1_shape[1], sc2_shape[1])])\n",
    "        bg_shape = (bg_shape * bg_scale).astype(int)\n",
    "        bg_img = np.zeros(shape=bg_shape)\n",
    "        return bg_img\n",
    "    \n",
    "    if bg_img is None:\n",
    "        bg_img = _gen_empty_bg_img()\n",
    "\n",
    "    bg_shape = np.array(bg_img.shape)\n",
    "    new_img = bg_img.copy()\n",
    "    new_mask = np.zeros(shape=bg_shape, dtype=bool)\n",
    "\n",
    "    _, sc1_new_contour, sc1_new_mask, shift1 = add_sc_to_img(sc1, new_img, bg_img=bg_img, mask=new_mask, in_place=True, fix_sc_pos=fix_sc1)\n",
    "    _, sc2_new_contour, sc2_new_mask, shift2 = add_sc_to_img(sc2, new_img, bg_img=bg_img, mask=new_mask, in_place=True)\n",
    "\n",
    "    new_sc1 = SingleCellStatic(timeframe=SingleImageDataset.DEFAULT_TIME, contour=sc1_new_contour, img_dataset=SingleImageDataset(new_img), mask_dataset=SingleImageDataset(sc1_new_mask))\n",
    "    new_sc2 = SingleCellStatic(timeframe=SingleImageDataset.DEFAULT_TIME, contour=sc2_new_contour, img_dataset=SingleImageDataset(new_img), mask_dataset=SingleImageDataset(sc2_new_mask))\n",
    "    return new_sc1, new_sc2\n",
    "\n",
    "# has_overlap = np.any(new_sc1_mask & new_sc2_mask)\n",
    "# print(has_overlap)\n",
    "# fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "# ax = axes[0][0]\n",
    "# ax.imshow(new_sc1_mask | new_sc2_mask)\n",
    "# ax = axes[0][1]\n",
    "# ax.imshow(new_img)\n",
    "bg_scale = 3.0\n",
    "\n",
    "def viz_check_combined_sc_result(sc1, sc2):\n",
    "    fig, axes = plt.subplots(1, 8, figsize=(18, 5))\n",
    "    ax_idx = 0\n",
    "    ax = axes[ax_idx]\n",
    "    sc1.show_whole_img(ax=ax)\n",
    "    ax.set_title(\"sc1 whole img\")\n",
    "    ax_idx += 1\n",
    "\n",
    "    ax = axes[ax_idx]\n",
    "    sc1.show(ax=ax)\n",
    "    ax.set_title(\"sc1 img crop\")\n",
    "    ax_idx += 1\n",
    "\n",
    "    ax = axes[ax_idx]\n",
    "    sc1.show_mask(ax=ax, padding=20)\n",
    "    ax.set_title(\"sc1 mask\")\n",
    "    ax_idx += 1\n",
    "\n",
    "    ax = axes[ax_idx]\n",
    "    sc1.show_contour_img(ax=ax, padding=20)\n",
    "    ax.set_title(\"sc1 contour img\")\n",
    "    ax_idx += 1\n",
    "\n",
    "    ax = axes[ax_idx]\n",
    "    sc2.show_whole_img(ax=ax)\n",
    "    ax.set_title(\"sc2 whole img\")\n",
    "    ax_idx += 1\n",
    "\n",
    "    ax = axes[ax_idx]\n",
    "    sc2.show(ax=ax, crop=True)\n",
    "    ax.set_title(\"sc2 img crop\")\n",
    "    ax_idx += 1\n",
    "\n",
    "    ax = axes[ax_idx]\n",
    "    sc2.show_mask(ax=ax, padding=20)\n",
    "    ax.set_title(\"sc2 mask\")\n",
    "    ax_idx += 1\n",
    "\n",
    "    ax = axes[ax_idx]\n",
    "    sc2.show_contour_img(ax=ax, padding=20)\n",
    "    ax.set_title(\"sc2 contour img\")\n",
    "    ax_idx += 1\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "for i in range(4):\n",
    "    new_sc1, new_sc2 = combine_two_scs_monte_carlo(sc1, sc2, bg_img=None)\n",
    "    viz_check_combined_sc_result(new_sc1, new_sc2)\n",
    "\n",
    "# for i in range(4):\n",
    "#     new_sc1, new_sc2 = combine_two_scs_monte_carlo(sc1, sc2, bg_img=None, fix_sc1=True)\n",
    "#     viz_check_combined_sc_result(new_sc1, new_sc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_check_combined_sc_result(new_sc1, new_sc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_synthetic_overlap_scs(sc1, sc2, max_overlap_percent=0.2, bg_scale=2.0, fix_sc1=False, min_reserved_area_percent = 0.7, max_try=1000):\n",
    "    # TODO: optimize in the future via computational geometry; now simply use monte carlo for generating required synthetic data\n",
    "    is_success = False\n",
    "    counter = 0\n",
    "    while not is_success and counter < max_try:\n",
    "        is_success = True\n",
    "        new_sc1, new_sc2 = combine_two_scs_monte_carlo(sc1, sc2, bg_img=None, bg_scale=bg_scale, fix_sc1=fix_sc1)\n",
    "        # check overlap\n",
    "        overlap_mask = np.logical_and(new_sc1.get_mask(), new_sc2.get_mask())\n",
    "        overlap_percent = float(np.sum(overlap_mask)) / min(np.sum(new_sc1.get_mask()), np.sum(new_sc2.get_mask()))\n",
    "        if overlap_percent > 0 and overlap_percent < max_overlap_percent:\n",
    "            pass\n",
    "        else:\n",
    "            is_success = False\n",
    "\n",
    "        # check area percent to prevent scs that are too small\n",
    "        area = float(np.sum((new_sc1.get_contour_mask()>0).flatten())) + np.sum((new_sc2.get_contour_mask()>0).flatten())\n",
    "        old_area = float(np.sum((sc1.get_contour_mask()>0).flatten())) + np.sum((sc2.get_contour_mask()>0).flatten())\n",
    "        if (area / old_area)  < min_reserved_area_percent:\n",
    "            is_success = False\n",
    "        counter += 1\n",
    "\n",
    "    return new_sc1, new_sc2, overlap_percent, is_success\n",
    "\n",
    "\n",
    "\n",
    "# # check results\n",
    "# for i in tqdm(range(4)):\n",
    "#     new_sc1, new_sc2, _, is_success = gen_synthetic_overlap_scs(sc1, sc2)\n",
    "#     viz_check_combined_sc_result(new_sc1, new_sc2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate synthetic non-overlapping underseg cells "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_distance_by_contour(sc1, sc2):\n",
    "    # compute distance between two scs by their contour\n",
    "    c1, c2 = sc1.get_contour(), sc2.get_contour()\n",
    "    return compute_two_contours_min_distance(c1, c2)\n",
    "\n",
    "sc3 = single_cells[3]\n",
    "# fig, axes = plt.subplots(1, 3, figsize=(10, 5))\n",
    "# sc1.show_contour_img(ax=axes[0], padding=10000)\n",
    "# sc2.show_contour_img(ax=axes[1], padding=10000)\n",
    "# sc3.show_contour_img(ax=axes[2], padding=10000)\n",
    "\n",
    "\n",
    "compute_distance_by_contour(sc1, sc2), compute_distance_by_contour(sc1, sc3), compute_distance_by_contour(sc2, sc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_gauss_sc_bg(sc: SingleCellStatic, shape):\n",
    "    \"\"\"generate background for sc by gaussian noise\"\"\"\n",
    "    img = sc.get_img()\n",
    "    mask = sc.get_mask().astype(bool)\n",
    "    bg_mask = np.logical_not(mask)\n",
    "\n",
    "    # compute gauss distribution of background pixels\n",
    "    pixels = img[bg_mask].flatten()\n",
    "    mean = np.mean(pixels)\n",
    "    std = np.std(pixels)\n",
    "    res_bg_img = np.random.normal(0, 1, shape)\n",
    "    res_bg_img = res_bg_img * std + mean\n",
    "    return res_bg_img\n",
    "\n",
    "plt.imshow(gen_gauss_sc_bg(sc1, (512, 512)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_sc_bg_crop(sc, shape):\n",
    "    \"\"\"generate background for sc by cropping from the sc's image. For regions belong to single cells, remove cells and fill with gaussian noise.\"\"\"\n",
    "    img = sc.get_img()\n",
    "    mask = sc.get_mask().astype(bool)\n",
    "    bg_mask = np.logical_not(mask)\n",
    "    if not (img.shape[0] >= shape[0] and img.shape[1] >= shape[1]):\n",
    "        print(\"Shape of sc is smaller than the required shape, return None...\")\n",
    "        return None\n",
    "    # compute gauss distribution of background pixels\n",
    "    pixels = img[bg_mask].flatten()\n",
    "    mean = np.mean(pixels)\n",
    "    std = np.std(pixels)\n",
    "\n",
    "    # randomly crop a region from the large image\n",
    "    bounds = np.array(img.shape) - np.array(shape)\n",
    "    crop_row, crop_col = np.random.randint(low=0, high=bounds, size=2)\n",
    "    res_bg_img = np.array(img[crop_row:crop_row+shape[0], crop_col:crop_col+shape[1]])\n",
    "    res_bg_mask = np.array(bg_mask[crop_row:crop_row+shape[0], crop_col:crop_col+shape[1]])\n",
    "\n",
    "    res_bg_img[~res_bg_mask] = np.random.normal(0, 1, np.sum(~res_bg_mask)) * std + mean\n",
    "    return res_bg_img\n",
    "\n",
    "\n",
    "plt.imshow(gen_sc_bg_crop(sc1, (512, 512)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_two_scs(sc1: SingleCellStatic, sc2: SingleCellStatic, pos_offset_vec, bg_img, inplace=False):\n",
    "    if not inplace:\n",
    "        sc1 = sc1.copy()\n",
    "        sc2 = sc2.copy()\n",
    "    img_space_dims = bg_img.shape\n",
    "    pos_offset_vec = np.array(pos_offset_vec).astype(int)\n",
    "    new_contour = np.array(sc2.get_contour()) + pos_offset_vec\n",
    "    contour_before_adjust = new_contour.copy()\n",
    "    tmp_sc2_bbox_before_adjust = SingleCellStatic.get_bbox_from_contour(contour_before_adjust)\n",
    "    new_contour = adjust_contour_to_bounds(new_contour, img_space_dims)\n",
    "    tmp_sc2 = sc2.copy()\n",
    "    tmp_sc2.update_contour(new_contour, update_bbox=True)\n",
    "\n",
    "    new_img = bg_img.copy()\n",
    "    new_mask = np.zeros(bg_img.shape, dtype=np.uint8)\n",
    "    sc1_bbox, sc2_bbox = sc1.get_bbox(), sc2.get_bbox()\n",
    "    new_sc_bbox = tmp_sc2.get_bbox()\n",
    "    projected_new_sc_bbox = (new_sc_bbox.reshape(2, 2) - pos_offset_vec).flatten()\n",
    "\n",
    "    # Note that the boundaries are imgage dims + 1 because if skimage bbox's definition is [min_row, min_col, max_row, max_col)\n",
    "    projected_new_sc_bbox = adjust_contour_to_bounds(projected_new_sc_bbox.reshape(2, 2), np.array(img_space_dims), bound_shift=0).flatten()\n",
    "    if projected_new_sc_bbox[0] == img_space_dims[0]:\n",
    "        projected_new_sc_bbox[0] -= 1\n",
    "    if projected_new_sc_bbox[1] == img_space_dims[1]:\n",
    "        projected_new_sc_bbox[1] -= 1\n",
    "    \n",
    "    # fix a corner case that may cause the projected_new_sc_bbox to be empty\n",
    "    if projected_new_sc_bbox[2] == projected_new_sc_bbox[0]:\n",
    "        projected_new_sc_bbox[2] += 1\n",
    "    if projected_new_sc_bbox[3] == projected_new_sc_bbox[1]:\n",
    "        projected_new_sc_bbox[3] += 1\n",
    "    # print(\"dims: \", img_space_dims)\n",
    "    # print(\"projected_new_sc_bbox: \", projected_new_sc_bbox)\n",
    "    # print(\"new_sc_bbox: \", new_sc_bbox)\n",
    "\n",
    "    # update datasets\n",
    "    # TODO: consider if we have more datasets in single cell objects?\n",
    "    new_img[sc1_bbox[0]:sc1_bbox[2], sc1_bbox[1]:sc1_bbox[3]] = sc1.get_img_crop()\n",
    "    new_img[new_sc_bbox[0]:new_sc_bbox[2], new_sc_bbox[1]:new_sc_bbox[3]] = sc2.get_img_crop(bbox=projected_new_sc_bbox)\n",
    "    new_mask[sc1_bbox[0]:sc1_bbox[2], sc1_bbox[1]:sc1_bbox[3]] |= sc1.get_mask_crop()\n",
    "    new_mask[new_sc_bbox[0]:new_sc_bbox[2], new_sc_bbox[1]:new_sc_bbox[3]] |= sc2.get_mask_crop(bbox=projected_new_sc_bbox)\n",
    "    \n",
    "    # set image datasets of scs\n",
    "    sc1.img_dataset = SingleImageDataset(new_img)\n",
    "    sc1.mask_dataset = SingleImageDataset(new_mask)\n",
    "\n",
    "    sc2.img_dataset = sc1.img_dataset\n",
    "    sc2.mask_dataset = sc1.mask_dataset\n",
    "    sc2.update_contour(tmp_sc2.get_contour(), update_bbox=True)\n",
    "\n",
    "    return sc1, sc2\n",
    "\n",
    "def move_two_syn_scs_close_or_apart(sc1: SingleCellStatic, sc2: SingleCellStatic, dist, bg_img, inplace=False, apart=False):\n",
    "    if not inplace:\n",
    "        sc1 = sc1.copy()\n",
    "        sc2 = sc2.copy()\n",
    "    overlap = sc1.compute_overlap_percent(sc2)\n",
    "    img_space_dims = bg_img.shape\n",
    "    assert overlap <= 1e-5, \"Two scs should not overlap\"\n",
    "\n",
    "    # move sc2 toward sc1\n",
    "    norm_vec = (sc1.get_center(crop=False) - sc2.get_center(crop=False))\n",
    "    norm_vec = norm_vec / np.linalg.norm(norm_vec)\n",
    "    pos_offset_vec = (norm_vec * dist).astype(int)\n",
    "    if apart:\n",
    "        pos_offset_vec = -pos_offset_vec\n",
    "    return move_two_scs(sc1, sc2, pos_offset_vec=pos_offset_vec, bg_img=bg_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def move_util_in_range(sc1: SingleCellStatic, sc2: SingleCellStatic, dist_per_move, bg_img, min_dist=-np.inf, max_dist=np.inf, inplace=False, max_move=100, allow_overlap=False):\n",
    "    \"\"\"utilize move_two_syn_scs_close_or_apart to move two scs within a certain distance range\"\"\"\n",
    "    if not inplace:\n",
    "        sc1 = sc1.copy()\n",
    "        sc2 = sc2.copy()\n",
    "\n",
    "    # move sc2 toward sc1\n",
    "    norm_vec = (sc1.get_center(crop=False) - sc2.get_center(crop=False))\n",
    "    norm_vec = norm_vec / np.linalg.norm(norm_vec)\n",
    "\n",
    "    cur_dist = compute_two_contours_min_distance(sc1.get_contour(), sc2.get_contour())\n",
    "    if dist_per_move is None:\n",
    "        # # TODO: make distance per move more efficient \n",
    "        # if cur_dist > max_dist:\n",
    "        #     dist_per_move = (cur_dist - max_dist) / 2\n",
    "        # elif cur_dist < min_dist:\n",
    "        #     dist_per_move = (min_dist - cur_dist) / 2\n",
    "        # else:\n",
    "        #     dist_per_move = (max_dist - min_dist) / 2\n",
    "        dist_per_move = (max_dist - min_dist) / 2\n",
    "\n",
    "    pos_offset_vec_toward = (norm_vec * dist_per_move).astype(int)\n",
    "    pos_offset_vec = pos_offset_vec_toward\n",
    "    if cur_dist < min_dist:\n",
    "        pos_offset_vec = - pos_offset_vec\n",
    "\n",
    "    print(\"start dist: \", cur_dist, \"pos_offset_vec: \", pos_offset_vec, \"min_dist: \", min_dist, \"max_dist: \", max_dist, \"allow_overlap: \", allow_overlap)\n",
    "    counter = 0\n",
    "    iou = sc1.compute_iou(sc2)\n",
    "    while (cur_dist < min_dist or cur_dist > max_dist or (not allow_overlap and iou > 0)) and counter < max_move:\n",
    "        sc1, sc2 = move_two_scs(sc1, sc2, pos_offset_vec=pos_offset_vec, bg_img=bg_img, inplace=inplace)\n",
    "        cur_dist = compute_two_contours_min_distance(sc1.get_contour(), sc2.get_contour())\n",
    "        iou = sc1.compute_iou(sc2)\n",
    "        print(\"cur_dist: \", cur_dist, \"iou: \", iou, \"pos_offset_vec: \", pos_offset_vec)\n",
    "        norm_vec = (sc1.get_center(crop=False) - sc2.get_center(crop=False))\n",
    "        norm_vec = norm_vec / np.linalg.norm(norm_vec)\n",
    "        pos_offset_vec_toward = (norm_vec * dist_per_move).astype(int)\n",
    "        if iou > 0 or cur_dist < min_dist:\n",
    "            pos_offset_vec = - pos_offset_vec_toward\n",
    "        else:\n",
    "            pos_offset_vec = pos_offset_vec_toward\n",
    "        counter += 1\n",
    "    return sc1, sc2\n",
    "\n",
    "def gen_synthetic_nonoverlap_scs(sc1: SingleCellStatic, sc2: SingleCellStatic, min_dist=-np.inf, max_dist=np.inf, min_reserved_area_percent = 0.7, bg_scale=3.0, fix_sc1=False, max_try=1000, gen_bg_func=None, use_move_close=True, dist_per_move=None):\n",
    "    is_success = False\n",
    "    counter = 0\n",
    "    sc1_shape = sc1.get_contour_mask().shape\n",
    "    sc2_shape = sc2.get_contour_mask().shape\n",
    "    max_shape = np.max(np.array([sc1_shape, sc2_shape]), axis=0) * bg_scale\n",
    "\n",
    "    syn_bg_shape = (int(max_shape[0]), int(max_shape[1]))\n",
    "\n",
    "    while not is_success and counter < max_try:\n",
    "        is_success = True\n",
    "        bg_img = None\n",
    "        if gen_bg_func is not None:\n",
    "            bg_img = gen_bg_func(sc1, shape=syn_bg_shape)\n",
    "            if bg_img is None:\n",
    "                is_success = False\n",
    "                continue\n",
    "        \n",
    "        # TODO: we can improve this function by replacing monte carlo method\n",
    "        # TODO: calculate distance between two scs and move two scs together can satisfy the conditions efficiently\n",
    "        new_sc1, new_sc2 = combine_two_scs_monte_carlo(sc1, sc2, bg_img=bg_img, bg_scale=bg_scale, fix_sc1=fix_sc1)\n",
    "        if use_move_close:\n",
    "            new_sc1, new_sc2 = move_util_in_range(new_sc1, new_sc2, dist_per_move=dist_per_move, bg_img=bg_img, min_dist=min_dist, max_dist=max_dist, inplace=True, max_move=100)\n",
    "        # check overlap\n",
    "        overlap_percent = new_sc1.compute_iou(new_sc2)\n",
    "        if overlap_percent > 1e-5:\n",
    "            is_success = False\n",
    "        dist = compute_distance_by_contour(new_sc1, new_sc2)\n",
    "        if dist < min_dist or dist > max_dist:\n",
    "            is_success = False\n",
    "\n",
    "        # check area percent to prevent scs that are too small\n",
    "        area = float(np.sum((new_sc1.get_contour_mask()>0).flatten())) + np.sum((new_sc2.get_contour_mask()>0).flatten())\n",
    "        old_area = float(np.sum((sc1.get_contour_mask()>0).flatten())) + np.sum((sc2.get_contour_mask()>0).flatten())\n",
    "        if (area / old_area)  < min_reserved_area_percent:\n",
    "            is_success = False\n",
    "\n",
    "        print(\"counter: {}, overlap: {}, dist: {}, %%area: {}\".format(counter, overlap_percent, dist, area / old_area))\n",
    "        counter += 1\n",
    "    return new_sc1, new_sc2, dist, is_success\n",
    "\n",
    "# # check results\n",
    "# min_dist = 30\n",
    "# max_dist = 100\n",
    "# for i in tqdm(range(2)):\n",
    "#     new_sc1, new_sc2, _, is_success = gen_synthetic_nonoverlap_scs(sc1, sc2, gen_bg_func=gen_sc_bg_crop, min_dist=min_dist, max_dist=max_dist, dist_per_move=30)\n",
    "#     viz_check_combined_sc_result(new_sc1, new_sc2)\n",
    "\n",
    "# for i in tqdm(range(2)):\n",
    "#     new_sc1, new_sc2, _, is_success = gen_synthetic_nonoverlap_scs(sc1, sc2, gen_bg_func=gen_gauss_sc_bg, min_dist=min_dist, max_dist=max_dist, dist_per_move=30)\n",
    "#     viz_check_combined_sc_result(new_sc1, new_sc2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test move cells functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in tqdm(range(5)):\n",
    "    new_sc1, new_sc2, _, is_success = gen_synthetic_nonoverlap_scs(sc1, sc2, gen_bg_func=gen_gauss_sc_bg, min_dist=10, max_dist=1000,  min_reserved_area_percent=1)\n",
    "    viz_check_combined_sc_result(new_sc1, new_sc2)\n",
    "    # move_two_syn_scs_close_or_apart(new_sc1, new_sc2, dist=40, bg_img=gen_gauss_sc_bg(new_sc1, shape=new_sc1.get_img().shape), inplace=True)\n",
    "    move_util_in_range(new_sc1, new_sc2, dist_per_move=30, bg_img=gen_gauss_sc_bg(new_sc1, shape=new_sc1.get_img().shape), min_dist=10, max_dist=40, inplace=True, max_move=100)\n",
    "    viz_check_combined_sc_result(new_sc1, new_sc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "from skimage.measure import regionprops\n",
    "import pandas as pd\n",
    "from livecell_tracker.core.io_utils import save_tiff\n",
    "from livecell_tracker.segment.ou_utils import csn_augment_helper, underseg_overlay_gt_masks, gen_aug_diff_mask\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check sc areas \n",
    "```\n",
    "for sc in single_cells:\n",
    "    prop = sc.compute_regionprops()\n",
    "    assert prop.area > 5\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_and_save_merged_sc(sc: SingleCellStatic, scale_factors, scs, img_id, seg_label, syn_id, out_dir):\n",
    "    # img_crop = sc.get_img_crop()\n",
    "    # seg_crop = sc.get_mask_crop()\n",
    "\n",
    "    # Note: do not use get_img_crop() and get_mask_crop() here, because we want to use the original image and mask\n",
    "    # which are consistent across scs passed in\n",
    "    img_crop = sc.get_img()\n",
    "    seg_crop = sc.get_mask()\n",
    "\n",
    "    syn_underseg_out_dir = out_dir\n",
    "    raw_out_dir = syn_underseg_out_dir / \"raw\"\n",
    "    seg_out_dir = syn_underseg_out_dir / \"seg\"\n",
    "    gt_out_dir = syn_underseg_out_dir / \"gt\"\n",
    "    gt_label_out_dir = syn_underseg_out_dir / \"gt_label_mask\"\n",
    "    augmented_seg_dir = syn_underseg_out_dir / \"augmented_seg\"\n",
    "    raw_transformed_img_dir = syn_underseg_out_dir / \"raw_transformed_img\"\n",
    "    augmented_diff_seg_dir = syn_underseg_out_dir / \"augmented_diff_seg\"\n",
    "\n",
    "    # makedirs\n",
    "    all_dirs = [syn_underseg_out_dir, raw_out_dir, seg_out_dir, gt_out_dir, gt_label_out_dir, augmented_seg_dir, raw_transformed_img_dir, augmented_diff_seg_dir]\n",
    "    for directory in all_dirs:\n",
    "        if not directory.exists():\n",
    "            print(\">>> creating dir: \", directory)\n",
    "            os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "\n",
    "    # generate combined gt label mask\n",
    "    combined_gt_label_mask = sc.get_mask().astype(int)\n",
    "    for i, tmp_sc in enumerate(scs):\n",
    "        # mask = SingleCellStatic.gen_skimage_bbox_img_crop(sc.bbox, tmp_sc.get_mask())\n",
    "        mask = tmp_sc.get_mask().astype(bool)\n",
    "        if mask.shape != combined_gt_label_mask.shape:\n",
    "            print(\"mask dim: \", mask.shape)\n",
    "            print(\"combined_gt_label_mask dim: \", combined_gt_label_mask.shape)\n",
    "        combined_gt_label_mask[mask] = i + 1\n",
    "\n",
    "    raw_img_path = raw_out_dir / (\"syn-underseg-img-%d_seg-%d.tif\" % (img_id, seg_label))\n",
    "    seg_img_path = seg_out_dir / (\"syn-underseg-img-%d_seg-%d.tif\" % (img_id, seg_label))\n",
    "    gt_img_path = gt_out_dir / (\"syn-underseg-img-%d_seg-%d.tif\" % (img_id, seg_label))\n",
    "    gt_label_img_path = gt_label_out_dir / (\"img-%d_seg-%d.tif\" % (img_id, seg_label))\n",
    "\n",
    "    underseg_train_tuples = []\n",
    "    augmented_data = []\n",
    "    filename_pattern = \"syn-underseg-img-%d_seg-%d.tif\"\n",
    "    res_dict = csn_augment_helper(img_crop=img_crop, \n",
    "        seg_crop=seg_crop, \n",
    "        combined_gt_label_mask=combined_gt_label_mask,\n",
    "        overseg_raw_seg_crop=None,\n",
    "        overseg_raw_seg_img_path=None,\n",
    "        scale_factors=scale_factors,\n",
    "        train_path_tuples=underseg_train_tuples,\n",
    "        augmented_data=augmented_data,\n",
    "        img_id=img_id,\n",
    "        seg_label=syn_id,\n",
    "        gt_label=-1,\n",
    "        raw_img_path=raw_img_path,\n",
    "        seg_img_path=seg_img_path,\n",
    "        gt_img_path=gt_img_path,\n",
    "        gt_label_img_path=gt_label_img_path,\n",
    "        augmented_seg_dir=augmented_seg_dir,\n",
    "        augmented_diff_seg_dir=augmented_diff_seg_dir,\n",
    "        filename_pattern=filename_pattern,\n",
    "        raw_transformed_img_dir=raw_transformed_img_dir,\n",
    "        df_save_path=syn_underseg_out_dir/\"data.csv\",\n",
    "    )\n",
    "    return res_dict\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from skimage.measure import find_contours\n",
    "import cv2\n",
    "\n",
    "def show_cv2_contours(contours, img):\n",
    "    im = np.expand_dims(img.astype(np.uint8), axis=2).repeat(3, axis=2) \n",
    "    for k, _ in enumerate(contours):\n",
    "        im = cv.drawContours(im, contours, k, (0, 230, 255), 6)\n",
    "    plt.imshow(im)\n",
    "    plt.show()\n",
    "\n",
    "def find_contours_opencv(mask) -> list:\n",
    "    contours, hierarchy = cv2.findContours(mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    contours = list(contours)\n",
    "    for i, contour in enumerate(contours):\n",
    "        contour = np.array(contour)\n",
    "        contour = contour[:, :, ::-1]\n",
    "        contour = contour.reshape(-1, 2)\n",
    "        contours[i] = contour\n",
    "    return contours\n",
    "\n",
    "def merge_two_scs_overlap(sc1: SingleCellStatic, sc2: SingleCellStatic):\n",
    "    new_mask = np.logical_or(sc1.get_mask().astype(bool), sc2.get_mask().astype(bool))\n",
    "    # plt.imshow(new_mask)\n",
    "    # plt.show()\n",
    "    # print(np.unique(new_mask))\n",
    "    # contours = find_contours(new_mask, fully_connected=\"high\")\n",
    "\n",
    "    contours = find_contours_opencv(new_mask.astype(np.uint8))\n",
    "    assert len(contours) != 0, \"must contain at least one contour\"\n",
    "    if len(contours) > 1:\n",
    "        print(\"WARNING: more than one contour found, return merge failure to the caller...\")\n",
    "        return None, False\n",
    "    new_contour = contours[0]\n",
    "    res_sc = SingleCellStatic(\n",
    "        timeframe=SingleImageDataset.DEFAULT_TIME,\n",
    "        contour=new_contour,\n",
    "        img_dataset=sc1.img_dataset,\n",
    "        mask_dataset=SingleImageDataset(new_mask),\n",
    "    )\n",
    "    return res_sc, True\n",
    "\n",
    "\n",
    "\n",
    "def merge_two_scs_nonoverlap(sc1: SingleCellStatic, sc2: SingleCellStatic, max_dilate_iter=998, kernel_shape=(3, 3)):\n",
    "    new_mask = np.logical_or(sc1.get_mask().astype(bool), sc2.get_mask().astype(bool))\n",
    "\n",
    "    contours = find_contours_opencv(new_mask.astype(np.uint8))\n",
    "    assert len(contours) != 0, \"must contain at least one contour\"\n",
    "    if len(contours) != 2:\n",
    "        print(\"WARNING: #contours should be exactly 2 for merging two cells in non-overlap case, return merge failure to the caller...\")\n",
    "        return None, False\n",
    "\n",
    "    # dilate until the two contours are merged\n",
    "    kernel = np.ones(kernel_shape, np.uint8)\n",
    "    counter = 0\n",
    "    while len(contours) != 1 and counter < max_dilate_iter:\n",
    "        new_mask = cv2.dilate(new_mask.astype(np.uint8), kernel, iterations=1)\n",
    "        contours = find_contours_opencv(new_mask.astype(np.uint8))\n",
    "        counter += 1\n",
    "\n",
    "    if len(contours) != 1:\n",
    "        print(\"WARNING: #contours should be exactly 1 after merging two cells in the non-overlap case, return merge failure to the caller...\")\n",
    "        return None, False\n",
    "    \n",
    "    new_contour = contours[0]\n",
    "    res_sc = SingleCellStatic(\n",
    "        timeframe=SingleImageDataset.DEFAULT_TIME,\n",
    "        contour=new_contour,\n",
    "        img_dataset=sc1.img_dataset,\n",
    "        mask_dataset=SingleImageDataset(new_mask),\n",
    "    )\n",
    "    return res_sc, True\n",
    "\n",
    "\n",
    "def gen_underseg_scs_sample(scs, num_cells, save_dir=None, sample_id=None, augment_scale_factors=None,viz_check=False, sc_generator_func=gen_synthetic_overlap_scs, sc_generator_func_kwargs={}, merge_func=merge_two_scs_overlap):\n",
    "    assert len(scs) > 0, \"tmp_scs is empty\"\n",
    "    cur_merged_sc = scs[0].copy()\n",
    "    # merged_scs contains each individual single AFTER merging\n",
    "    _merged_scs = None\n",
    "    is_success = True\n",
    "    for j in range(1, num_cells):\n",
    "        is_success = True\n",
    "        cur_sc = scs[j]\n",
    "        cur_merged_sc, new_sc2, _, is_gen_success = sc_generator_func(cur_merged_sc, cur_sc, fix_sc1=True, **sc_generator_func_kwargs)\n",
    "        is_success &= is_gen_success\n",
    "        if not is_success:\n",
    "            break\n",
    "\n",
    "        if _merged_scs is None:\n",
    "            _merged_scs = [cur_merged_sc, new_sc2]\n",
    "        else:\n",
    "            _merged_scs.append(new_sc2)\n",
    "\n",
    "        assert cur_merged_sc.get_mask().shape == new_sc2.get_mask().shape, \"contact developer: two generated underseg scs should have the same shape\"\n",
    "        cur_merged_sc, is_merge_success = merge_func(cur_merged_sc, new_sc2)\n",
    "        is_success &= is_merge_success\n",
    "        if not is_success:\n",
    "            break\n",
    "    \n",
    "    # at some point, the merging process failed\n",
    "    if not is_success:\n",
    "        print(\"synthesize failure for combination:\", scs)\n",
    "        return {\"is_success\": False}\n",
    "    \n",
    "    if viz_check:\n",
    "        viz_check_combined_sc_result(cur_merged_sc, new_sc2)\n",
    "\n",
    "    # Now we make sure that the masks of the merged scs have the same shape (in the same space)\n",
    "    # for operate them easier later (e.g. merge the mask and generate label masks)\n",
    "    # the scs' bbox coordinates keeps the same, relative to the cur_merged_sc\n",
    "    # the image and mask dataset may be different in each iteration above\n",
    "    # thus we need to update the img_dataset and mask_dataset for each sc in merged_syn_scs\n",
    "    for sc in _merged_scs:\n",
    "        sc.img_dataset = cur_merged_sc.img_dataset\n",
    "\n",
    "        # all datasets below should be single image datasets\n",
    "        sc_mask_shape = cur_merged_sc.get_mask().shape\n",
    "        sc_mask_in_merged_space = np.zeros(sc_mask_shape, dtype=np.uint8)\n",
    "        sc.update_bbox()\n",
    "\n",
    "        # update sc_mask by intersection of bbox\n",
    "        # note that the new sc_mask should be smaller than the original sc_mask due to our simulator's scale factor setting\n",
    "        # sometimes the bbox is out of range, we need to check it.\n",
    "        # TODO: investigate why the following condition is not always true...\n",
    "        is_bbox_make_sense = sc.bbox[0] >= 0 and sc.bbox[1] >= 0 and sc.bbox[2] <= sc_mask_shape[0] and sc.bbox[3] <= sc_mask_shape[1]\n",
    "        if not is_bbox_make_sense:\n",
    "            print(\"generated sc_mask of the merged cell is smaller than that of one sc: sc bbox is out of range, sc.bbox=%s, sc_mask_shape=%s\" % (str(sc.bbox), str(sc_mask_shape)))\n",
    "            return {\"is_success\": False}\n",
    "\n",
    "        # when we generate the synthetic underseg scs, we fix coordinates of the first sc, so the cooridnates of the synthetic cells are always fixed relative to the first sc and in the same space. \n",
    "        sc_mask_in_merged_space[sc.bbox[0]:sc.bbox[2], sc.bbox[1]:sc.bbox[3]] = sc.get_mask()[sc.bbox[0]:sc.bbox[2], sc.bbox[1]:sc.bbox[3]]\n",
    "        if viz_check:\n",
    "            fig, axes = plt.subplots(1, 2)\n",
    "            axes[0].imshow(sc.get_mask())\n",
    "            axes[0].set_title(\"sc mask\")\n",
    "            axes[1].imshow(sc_mask_in_merged_space)\n",
    "            axes[1].set_title(\"sc mask after update\")\n",
    "            plt.show()\n",
    "        sc.mask_dataset = SingleImageDataset(sc_mask_in_merged_space)\n",
    "        contours = find_contours_opencv(sc_mask_in_merged_space)\n",
    "        if len(contours) > 1 or len(contours) == 0:\n",
    "            print(\"[WARNING] contours numbers=\", len(contours), \" when aligning synthetic single cells. Probably there is something wrong with contour finding algorithm used. Skipping this sample...\")\n",
    "            is_success = False\n",
    "            return {\n",
    "                \"is_success\": False,\n",
    "            }\n",
    "        sc.update_contour(contours[0])\n",
    "        assert sc.get_mask().shape == cur_merged_sc.get_mask().shape, \"Two generated underseg scs should have the same shape\"\n",
    "\n",
    "    cur_merged_sc.meta = {\n",
    "        \"num_merged_cells\": num_cells,\n",
    "    }\n",
    "    if save_dir:\n",
    "        assert sample_id is not None, \"sample_id should be provided if save_dir is provided\"\n",
    "        assert augment_scale_factors is not None, \"augment_scale_factors should be provided if save_dir is provided\"\n",
    "        res_dict = augment_and_save_merged_sc(cur_merged_sc, augment_scale_factors, scs=_merged_scs, img_id=sample_id, seg_label=sample_id, syn_id=sample_id, out_dir=save_dir)\n",
    "        df = res_dict[\"df\"]\n",
    "    return {\n",
    "        \"is_success\": is_success,\n",
    "        \"merged_scs\": _merged_scs,\n",
    "        \"cur_merged_sc\": cur_merged_sc,\n",
    "        \"df\": df,\n",
    "    }\n",
    "            \n",
    "\n",
    "def _gen_underseg_scs_sample_wrapper(inputs):\n",
    "    return gen_underseg_scs_sample(**inputs)\n",
    "\n",
    "\n",
    "def gen_underseg_scs(scs, num_cells = 3, total_sample_num = 1000, return_scs=False, save_dir: Path=None, augment_scale_factors=np.linspace(0, 0.1, 10), shuffle=True, sample_id_offset=0, viz_check=False, parallel=True, sc_generator_func=gen_synthetic_overlap_scs, sc_generator_func_kwargs=dict(), merge_func=merge_two_scs_overlap):\n",
    "    import random\n",
    "    import math\n",
    "    import tqdm\n",
    "    i = sample_id_offset\n",
    "    scs = list(scs)\n",
    "    random.shuffle(scs)\n",
    "    def _process_sequential():\n",
    "        with tqdm.tqdm(total=total_sample_num) as pbar:\n",
    "            counter = 0\n",
    "            for i, tmp_scs in enumerate(itertools.combinations(scs, num_cells)):\n",
    "                sample_id = i + sample_id_offset\n",
    "                res_data = gen_underseg_scs_sample(tmp_scs, num_cells, viz_check=viz_check, save_dir=save_dir, sample_id=sample_id, augment_scale_factors=augment_scale_factors, sc_generator_func=sc_generator_func, sc_generator_func_kwargs=sc_generator_func_kwargs, merge_func=merge_func)\n",
    "                if not res_data[\"is_success\"]:\n",
    "                    continue\n",
    "                _merged_scs = res_data[\"merged_scs\"]\n",
    "                cur_merged_sc = res_data[\"cur_merged_sc\"]\n",
    "\n",
    "                sample_id += 1\n",
    "                counter += 1\n",
    "                pbar.update(1)\n",
    "                if counter >= total_sample_num:\n",
    "                    break\n",
    "\n",
    "    # parallel version\n",
    "    if parallel:\n",
    "        inputs = []\n",
    "        for i in range(total_sample_num):\n",
    "            tmp_scs = random.sample(scs, num_cells)\n",
    "            inputs.append({\n",
    "                    \"scs\": tmp_scs,\n",
    "                    \"num_cells\": num_cells,\n",
    "                    \"save_dir\": save_dir,\n",
    "                    \"sample_id\": i + sample_id_offset,\n",
    "                    \"augment_scale_factors\": augment_scale_factors,\n",
    "                    \"viz_check\": viz_check,\n",
    "                    \"sc_generator_func\": sc_generator_func,\n",
    "                    \"sc_generator_func_kwargs\": sc_generator_func_kwargs,\n",
    "                    \"merge_func\": merge_func,\n",
    "                })\n",
    "\n",
    "        from multiprocessing import Pool\n",
    "        pool = Pool()\n",
    "        res_single_cells = []\n",
    "        all_df = None\n",
    "        for res_dict in tqdm.tqdm(pool.imap_unordered(_gen_underseg_scs_sample_wrapper, inputs), total=len(inputs)):\n",
    "            if not res_dict[\"is_success\"]:\n",
    "                continue\n",
    "            _merged_scs = res_dict[\"merged_scs\"]\n",
    "            cur_merged_sc = res_dict[\"cur_merged_sc\"]\n",
    "            df = res_dict[\"df\"]\n",
    "            if all_df is None:\n",
    "                all_df = df\n",
    "            else:\n",
    "                all_df = pd.concat([all_df, df], ignore_index=True)\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "        return all_df\n",
    "    else:\n",
    "        _process_sequential()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viz merge two cells"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overlap case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sc1, new_sc2, _, _ = gen_synthetic_overlap_scs(sc1, sc2, min_reserved_area_percent=1)\n",
    "sc3, is_success = merge_two_scs_overlap(new_sc1, new_sc2)\n",
    "if is_success:\n",
    "    sc3.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nonoverlap case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sc1, new_sc2, _, _ = gen_synthetic_nonoverlap_scs(sc1, sc2, gen_bg_func=gen_gauss_sc_bg, min_dist=10, max_dist=50, bg_scale=2, min_reserved_area_percent=1)\n",
    "sc3, is_success = merge_two_scs_nonoverlap(new_sc1, new_sc2)\n",
    "if is_success:\n",
    "    sc3.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "show nonoverlap merge case: merge by dilation. sc3 represents a generated under-segmentation case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sc1, new_sc2, _, _ = gen_synthetic_nonoverlap_scs(sc1, sc2, gen_bg_func=gen_sc_bg_crop)\n",
    "sc3, is_success = merge_two_scs_nonoverlap(new_sc1, new_sc2)\n",
    "if is_success:\n",
    "    fig, axes = plt.subplots(1, 4)\n",
    "    padding = 100\n",
    "    new_sc1.show_mask(ax=axes[0], crop=True, padding=padding)\n",
    "    axes[0].set_title(\"sc1\")\n",
    "    new_sc2.show_mask(ax=axes[1], crop=True, padding=padding)\n",
    "    axes[1].set_title(\"sc2\")\n",
    "    sc3.show_mask(ax=axes[2], crop=True, padding=padding)\n",
    "    axes[2].set_title(\"sc3\")\n",
    "\n",
    "    axes[3].imshow(new_sc1.get_mask() + new_sc2.get_mask())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_num = 1000\n",
    "\n",
    "def test_gen_underseg_scs():\n",
    "    subdir = Path(\"synthetic_underseg_overlap\")\n",
    "    underseg_out_dir = out_dir / subdir\n",
    "    gen_underseg_scs(scs=single_cells, save_dir=underseg_out_dir, sample_id_offset=0, num_cells=4, total_sample_num=1)\n",
    "    gen_underseg_scs(scs=single_cells, save_dir=underseg_out_dir, sample_id_offset=1, num_cells=4, total_sample_num=1)\n",
    "\n",
    "def gen_syn_underseg_data_v6(sample_num=10):\n",
    "    subdir = Path(\"synthetic_underseg_overlap\")\n",
    "    underseg_out_dir = out_dir / subdir\n",
    "    # generate training data\n",
    "    gen_underseg_scs(scs=single_cells, save_dir=underseg_out_dir, sample_id_offset=0, num_cells=4, total_sample_num=sample_num)\n",
    "    gen_underseg_scs(scs=single_cells, save_dir=underseg_out_dir, sample_id_offset=sample_num, num_cells=3, total_sample_num=sample_num)\n",
    "    gen_underseg_scs(scs=single_cells, save_dir=underseg_out_dir, sample_id_offset=sample_num * 2, num_cells=2, total_sample_num=sample_num * 2)\n",
    "\n",
    "\n",
    "def gen_syn_nonoverlap_underseg_test_data_v6():\n",
    "    def _save_all_df(all_df):\n",
    "        all_df.to_csv(out_dir / \"synthetic_underseg_overlap\" / \"test.csv\", index=False)\n",
    "\n",
    "    subdir = Path(\"synthetic_underseg_overlap\")\n",
    "    underseg_out_dir = out_dir / subdir\n",
    "    # generate training data\n",
    "    sample_num = 100\n",
    "    all_df = gen_underseg_scs(scs=single_cells, save_dir=underseg_out_dir, sample_id_offset=0, num_cells=4, total_sample_num=sample_num)\n",
    "    _save_all_df(all_df)\n",
    "    df = gen_underseg_scs(scs=single_cells, save_dir=underseg_out_dir, sample_id_offset=sample_num, num_cells=3, total_sample_num=sample_num)\n",
    "    all_df = pd.concat([all_df, df], ignore_index=True)\n",
    "    _save_all_df(all_df)\n",
    "    df = gen_underseg_scs(scs=single_cells, save_dir=underseg_out_dir, sample_id_offset=sample_num * 2, num_cells=2, total_sample_num=sample_num * 2)\n",
    "    all_df = pd.concat([all_df, df], ignore_index=True)\n",
    "    _save_all_df(all_df)\n",
    "\n",
    "\n",
    "\n",
    "def gen_syn_nonoverlap_underseg_train_data(gen_bg_func, subdir, sample_num = 10):\n",
    "    underseg_out_dir = out_dir / subdir\n",
    "    def _save_all_df(all_df):\n",
    "        all_df.to_csv(underseg_out_dir / \"data.csv\", index=False)\n",
    "\n",
    "\n",
    "    # generate training data\n",
    "    \n",
    "    generator_args = {\n",
    "        \"min_dist\": 10,\n",
    "        \"max_dist\": 30,\n",
    "        \"bg_scale\": 3,\n",
    "        \"gen_bg_func\": gen_bg_func\n",
    "    }\n",
    "    all_df = gen_underseg_scs(scs=single_cells, save_dir=underseg_out_dir, sample_id_offset=0, num_cells=4, total_sample_num=sample_num, sc_generator_func=gen_synthetic_nonoverlap_scs, sc_generator_func_kwargs=generator_args, merge_func=merge_two_scs_nonoverlap)\n",
    "    _save_all_df(all_df)\n",
    "    df = gen_underseg_scs(scs=single_cells, save_dir=underseg_out_dir, sample_id_offset=sample_num, num_cells=3, total_sample_num=sample_num, sc_generator_func=gen_synthetic_nonoverlap_scs, sc_generator_func_kwargs=generator_args, merge_func=merge_two_scs_nonoverlap)\n",
    "    all_df = pd.concat([all_df, df], ignore_index=True)\n",
    "    _save_all_df(all_df)\n",
    "    df = gen_underseg_scs(scs=single_cells, save_dir=underseg_out_dir, sample_id_offset=sample_num * 2, num_cells=2, total_sample_num=sample_num * 2, sc_generator_func=gen_synthetic_nonoverlap_scs, sc_generator_func_kwargs=generator_args, merge_func=merge_two_scs_nonoverlap)\n",
    "    all_df = pd.concat([all_df, df], ignore_index=True)\n",
    "    _save_all_df(all_df)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Single core version for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subdir = Path(\"synthetic_underseg_nonoverlap\")\n",
    "underseg_out_dir = out_dir / subdir\n",
    "generator_args = {\"min_dist\": 10, \"max_dist\": 30, \"bg_scale\": 3, \"gen_bg_func\": gen_gauss_sc_bg}\n",
    "df = gen_underseg_scs(\n",
    "    scs=single_cells,\n",
    "    save_dir=underseg_out_dir,\n",
    "    sample_id_offset=0,\n",
    "    num_cells=3,\n",
    "    total_sample_num=5,\n",
    "    sc_generator_func=gen_synthetic_nonoverlap_scs,\n",
    "    sc_generator_func_kwargs=generator_args,\n",
    "    merge_func=merge_two_scs_nonoverlap,\n",
    "    viz_check=True,\n",
    "    parallel=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_syn_nonoverlap_underseg_train_data(gen_bg_func=gen_gauss_sc_bg, subdir=Path(\"synthetic_underseg_nonoverlap_gauss\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gen_syn_underseg_data_v6(sample_num=1000)\n",
    "gen_syn_nonoverlap_underseg_test_data_v6()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_underseg_scs(scs=single_cells, total_sample_num=2, save_dir=Path(\"./notebook_results/tmp/test_v6\"), num_cells=4, viz_check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gen_underseg_scs(scs=single_cells, total_sample_num=5, save_dir=None, num_cells=3, viz_check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gen_underseg_scs(scs=single_cells, total_sample_num=5, save_dir=None, num_cells=2, viz_check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = []\n",
    "for subdir in out_dir.iterdir():\n",
    "    if subdir.is_dir():\n",
    "        data_path = subdir / \"data.csv\"\n",
    "        dataframe = pd.read_csv(data_path)\n",
    "        dataframe[\"subdir\"] = subdir.name\n",
    "        dataframes.append(dataframe)\n",
    "combined_dataframe = pd.concat(dataframes)\n",
    "combined_dataframe.to_csv(out_dir / \"train_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subdir = Path(\"synthetic_underseg_overlap\")\n",
    "# overseg_out_dir = out_dir / subdir\n",
    "# raw_out_dir = overseg_out_dir / \"raw\"\n",
    "\n",
    "# # seg_out_dir is the directory containing all raw segmentation masks for training\n",
    "# # e.g. the eroded raw segmentation masks\n",
    "# seg_out_dir = overseg_out_dir / \"seg\"\n",
    "\n",
    "# # raw_seg_dir is the directory containing all raw segmentation masks for recording purposes\n",
    "# raw_seg_dir = overseg_out_dir / \"raw_seg_crop\"\n",
    "# gt_out_dir = overseg_out_dir / \"gt\"\n",
    "# gt_label_out_dir = overseg_out_dir / \"gt_label_mask\"\n",
    "# augmented_seg_dir = overseg_out_dir / \"augmented_seg\"\n",
    "# raw_transformed_img_dir = overseg_out_dir / \"raw_transformed_img\"\n",
    "# augmented_diff_seg_dir = overseg_out_dir / \"augmented_diff_seg\"\n",
    "# meta_path = overseg_out_dir / \"metadata.csv\"\n",
    "\n",
    "# os.makedirs(raw_out_dir, exist_ok=True)\n",
    "# os.makedirs(seg_out_dir, exist_ok=True)\n",
    "# os.makedirs(raw_seg_dir, exist_ok=True)\n",
    "# os.makedirs(gt_out_dir, exist_ok=True)\n",
    "# os.makedirs(augmented_seg_dir, exist_ok=True)\n",
    "# os.makedirs(gt_label_out_dir, exist_ok=True)\n",
    "# os.makedirs(raw_transformed_img_dir, exist_ok=True)\n",
    "# os.makedirs(augmented_diff_seg_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "# overseg_train_path_tuples = []\n",
    "# augmented_overseg_data = []\n",
    "# filename_pattern = \"img-%d_syn-%d.tif\"\n",
    "# overseg_metadata = []\n",
    "# underseg_erosion_scale_factors = np.linspace(0, 0.1, 10)\n",
    "# for sc in tqdm(single_cells):\n",
    "#     img_id = sc.timeframe\n",
    "#     for syn_id, overseg_datarow in enumerate(sc.uns[overseg_uns_key]):\n",
    "#         params = overseg_datarow[1]\n",
    "#         img_crop = sc.get_contour_img()\n",
    "#         raw_seg_crop = overseg_datarow[0]\n",
    "#         eroded_seg_crop = overseg_datarow[1]\n",
    "\n",
    "#         combined_gt_label_mask = sc.get_contour_mask()\n",
    "#         assert img_crop.shape == raw_seg_crop.shape == combined_gt_label_mask.shape\n",
    "#         raw_img_path = raw_out_dir / (filename_pattern % (img_id, syn_id))\n",
    "#         seg_img_path = seg_out_dir / (filename_pattern % (img_id, syn_id))\n",
    "#         raw_seg_img_path = raw_seg_dir / (filename_pattern % (img_id, syn_id))\n",
    "#         gt_img_path = gt_out_dir / (filename_pattern % (img_id, syn_id))\n",
    "#         gt_label_img_path = gt_label_out_dir / (filename_pattern % (img_id, syn_id))\n",
    "\n",
    "#         # metadata is a dict, containing params used to genereate our synthetic overseg data\n",
    "#         meta_info = overseg_datarow[2]\n",
    "#         meta_info[\"raw_img_path\"] = raw_img_path\n",
    "#         meta_info[\"seg_img_path\"] = seg_img_path\n",
    "#         meta_info[\"gt_img_path\"] = gt_img_path\n",
    "        \n",
    "#         overseg_metadata.append(meta_info)\n",
    "\n",
    "#         # call csn augment helper\n",
    "#         csn_augment_helper(img_crop=img_crop, \n",
    "#             seg_crop=eroded_seg_crop, \n",
    "#             combined_gt_label_mask=combined_gt_label_mask,\n",
    "#             overseg_raw_seg_crop=raw_seg_crop,\n",
    "#             overseg_raw_seg_img_path=raw_seg_img_path,\n",
    "#             scale_factors=underseg_erosion_scale_factors,\n",
    "#             train_path_tuples=overseg_train_path_tuples,\n",
    "#             augmented_data=augmented_overseg_data,\n",
    "#             img_id=img_id,\n",
    "#             seg_label=syn_id,\n",
    "#             gt_label=sc.timeframe,\n",
    "#             raw_img_path=raw_img_path,\n",
    "#             seg_img_path=seg_img_path,\n",
    "#             gt_img_path=gt_img_path,\n",
    "#             gt_label_img_path=gt_label_img_path,\n",
    "#             augmented_seg_dir=augmented_seg_dir,\n",
    "#             augmented_diff_seg_dir=augmented_diff_seg_dir,\n",
    "#             filename_pattern=filename_pattern,\n",
    "#         )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to handle two cases:\n",
    "1) there is any overlap between two objects  \n",
    "    a) simply dilate and create underseg cases  \n",
    "2) there is no overlap (future work) \n",
    "    b) fill in the pixels in-between the two objects  \n",
    "    c) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine data.csv files generated in each subfolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = []\n",
    "for subdir in out_dir.iterdir():\n",
    "    if subdir.is_dir():\n",
    "        data_path = subdir / \"data.csv\"\n",
    "        dataframe = pd.read_csv(data_path)\n",
    "        dataframe[\"subdir\"] = subdir.name\n",
    "        dataframes.append(dataframe)\n",
    "combined_dataframe = pd.concat(dataframes)\n",
    "combined_dataframe.to_csv(out_dir / \"train_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(combined_dataframe)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "livecell",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d9c7226d793827cd27273ad20fbb4775c3cb91053ab9378a09de5f8c6f258919"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
