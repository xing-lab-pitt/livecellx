{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "from livecell_tracker.core import (\n",
    "    SingleCellTrajectory,\n",
    "    SingleCellStatic,\n",
    "    SingleCellTrajectoryCollection,\n",
    ")\n",
    "from livecell_tracker.segment.detectron_utils import (\n",
    "    convert_detectron_instance_pred_masks_to_binary_masks,\n",
    "    convert_detectron_instances_to_label_masks,\n",
    "    segment_images_by_detectron,\n",
    "    segment_single_img_by_detectron_wrapper,\n",
    ")\n",
    "from livecell_tracker.core.datasets import LiveCellImageDataset\n",
    "from livecell_tracker.preprocess.utils import (\n",
    "    overlay,\n",
    "    enhance_contrast,\n",
    "    normalize_img_to_uint8,\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Labelme Json to COCO Json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run the following code once for generating coco json\n",
    "```\n",
    "import livecell_tracker.segment\n",
    "import livecell_tracker.annotation\n",
    "import livecell_tracker.annotation.labelme2coco\n",
    "import os\n",
    "labelme_json_folder = r\"\"\"../datasets/a549_ccnn/annotation_data\"\"\"\n",
    "dataset_folder_path = r\"\"\"../datasets/a549_ccnn/original_data\"\"\"\n",
    "export_dir = \"./notebook_results/correction_cnn_v0.0.0/\"\n",
    "os.makedirs(export_dir, exist_ok=True)\n",
    "livecell_tracker.annotation.labelme2coco.convert(\n",
    "    labelme_json_folder,\n",
    "    export_dir,\n",
    "    train_split_rate=0.9,\n",
    "    dataset_folder_path=dataset_folder_path,\n",
    "    # is_image_in_json_folder=True,\n",
    "    image_file_ext=\"tif\",\n",
    "    # image_file_ext=\"png\",\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load COCO into SingleCell Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycocotools.coco import COCO\n",
    "\n",
    "coco_data = COCO(\"../datasets/a549_ccnn/a549_ccnn_coco_v0.0.0/train.json\")\n",
    "out_dir = Path(\"./notebook_results/a549_ccp_vim/train_data_v6/\")\n",
    "\n",
    "coco_data.anns.keys(), coco_data.anns[1].keys(), coco_data.anns[1][\"segmentation\"][0][\n",
    "    :5\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_data.imgs.keys(), coco_data.imgs[1].keys(), coco_data.imgs[1][\"file_name\"],\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from livecell_tracker.annotation.coco_utils import coco_to_sc\n",
    "\n",
    "single_cells = coco_to_sc(coco_data)\n",
    "\n",
    "\n",
    "# for testing\n",
    "single_cells = single_cells[:20]\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(10, 5))\n",
    "cell_id = 10\n",
    "axes[0].imshow(single_cells[cell_id].get_img_crop(padding=100))\n",
    "axes[1].imshow(single_cells[cell_id].get_contour_mask_closed_form(padding=100))\n",
    "axes[2].imshow(single_cells[cell_id].get_contour_mask(padding=100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(single_cells)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save a list of single cell objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SingleCellStatic.write_single_cells_json(\n",
    "    single_cells, \"../datasets/a549_ccnn/single_cells.json\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contour_mask = single_cells[cell_id].get_contour_mask(padding=100)\n",
    "contour_mask.astype(np.uint8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "from livecell_tracker.preprocess.utils import dilate_or_erode_mask\n",
    "\n",
    "plt.imshow(dilate_or_erode_mask(contour_mask.astype(np.uint8), 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sc = single_cells[cell_id]\n",
    "sample_sc.meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "raw_img_dataset = sample_sc.img_dataset\n",
    "seg_data_dir = \"../datasets/a549_ccnn/seg_tiles_CCP_A549-VIM_lessThan24hr_Calcein_1mg-ml_DP_Ti2e_2022-9-11\"\n",
    "seg_paths = glob.glob(os.path.join(seg_data_dir, \"*.png\"))\n",
    "print(\"sample seg paths:\", seg_paths[:2])\n",
    "matched_time2seg = {}\n",
    "# for time, img_path in raw_img_dataset.time2url.items():\n",
    "#     substr = os.path.basename(img_path).split(\".\")[0]\n",
    "#     print(\"substr:\", substr)\n",
    "#     for seg_path\n",
    "#     break\n",
    "corrected_indices = []\n",
    "for seg_path in seg_paths:\n",
    "    substr = os.path.basename(seg_path).split(\".\")[0] # get rid of extension\n",
    "    substr = substr[4:]  # get rid of seg_ prefix\n",
    "    img, path, index = raw_img_dataset.get_img_by_url(\n",
    "        substr, return_path_and_time=True, ignore_missing=True\n",
    "    )\n",
    "    if path is None:\n",
    "        print(\"skip due to substr not found:\", substr)\n",
    "        continue\n",
    "    matched_time2seg[index] = seg_path\n",
    "\n",
    "seg_data = LiveCellImageDataset(time2url=matched_time2seg, ext=\"png\")\n",
    "sample_sc.mask_dataset = seg_data\n",
    "assert len(seg_data) == len(raw_img_dataset)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Synthetic Undersegmentation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc1 = single_cells[10]\n",
    "sc2 = single_cells[1]\n",
    "\n",
    "padding=20\n",
    "fig, axes = plt.subplots(2, 3, figsize=(10, 5))\n",
    "sc1.show(padding=padding, ax=axes[0][0])\n",
    "sc1.show_contour_img(padding=padding, ax=axes[0][1])\n",
    "sc1.show_contour_mask(padding=padding, ax=axes[0][2])\n",
    "sc2.show(padding=padding, ax=axes[1][0])\n",
    "sc2.show_contour_img(padding=padding, ax=axes[1][1])\n",
    "sc2.show_contour_mask(padding=padding, ax=axes[1][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from livecell_tracker.core.datasets import SingleImageDataset\n",
    "\n",
    "\n",
    "def check_contour_in_boundary(contour, boundary):\n",
    "    return np.all(contour >= 0) and np.all(contour < boundary)\n",
    "\n",
    "\n",
    "def adjust_contour_to_bounds(contour, bounds):\n",
    "    if not check_contour_in_boundary(contour, bounds):\n",
    "        contour = contour.copy()\n",
    "        contour[contour < 0] = 0\n",
    "        contour = np.where(contour >= bounds, bounds - 1, contour)\n",
    "    return contour\n",
    "\n",
    "def shift_contour_randomly(sc_center, contour, bounds):\n",
    "    random_center = np.random.randint(low=0, high=bounds, size=2)\n",
    "    shift = random_center - sc_center\n",
    "    shift = shift.astype(int)\n",
    "    contour_shifted = contour + shift\n",
    "    return random_center, contour_shifted, shift\n",
    "\n",
    "def compute_two_contours_min_distance(contour1, contour2):\n",
    "    min_dist = np.inf\n",
    "    for p1 in contour1:\n",
    "        for p2 in contour2:\n",
    "            dist = np.linalg.norm(p1 - p2)\n",
    "            if dist < min_dist:\n",
    "                min_dist = dist\n",
    "    return min_dist\n",
    "\n",
    "def combine_two_scs_monte_carlo(sc1, sc2, bg_img=None, bg_scale=1.5, fix_sc1=False):\n",
    "    def _gen_empty_bg_img():\n",
    "        sc1_shape = sc1.get_img_crop().shape\n",
    "        sc2_shape = sc2.get_img_crop().shape\n",
    "        bg_shape = np.array([max(sc1_shape[0], sc2_shape[0]), max(sc1_shape[1], sc2_shape[1])])\n",
    "        bg_shape = (bg_shape * bg_scale).astype(int)\n",
    "        bg_img = np.zeros(shape=bg_shape)\n",
    "        return bg_img\n",
    "    \n",
    "    if bg_img is None:\n",
    "        bg_img = _gen_empty_bg_img()\n",
    "\n",
    "    bg_shape = np.array(bg_img.shape)\n",
    "    new_img = bg_img.copy()\n",
    "    new_mask = np.zeros(shape=bg_shape, dtype=np.bool)\n",
    "\n",
    "    def _add_sc_to_img_helper(sc, new_img, new_sc_mask, shift, in_place=False):\n",
    "        if not in_place:\n",
    "            new_img = new_img.copy()\n",
    "        sc_ori_space_pixel_xy_arr = np.array(new_sc_mask.nonzero()).T - shift\n",
    "        sc_ori_space_pixel_xy_arr[sc_ori_space_pixel_xy_arr < 0] = 0\n",
    "        new_img[new_sc_mask] = sc.get_contour_img()[sc_ori_space_pixel_xy_arr[:, 0], sc_ori_space_pixel_xy_arr[:, 1]]\n",
    "        return new_img\n",
    "\n",
    "    def add_sc_to_img(sc, new_img, mask, in_place=False, mask_inplace=True, fix_sc_pos=False):\n",
    "    \n",
    "        sc_prop = sc.compute_regionprops()\n",
    "        sc_contour_coords = sc.get_contour_coords_on_crop().astype(int)\n",
    "        if fix_sc_pos:\n",
    "            sc_new_center = sc_prop.centroid\n",
    "            sc_new_contour = sc_contour_coords\n",
    "            shift = 0\n",
    "        else:\n",
    "            sc_new_center, sc_new_contour, shift = shift_contour_randomly(sc_prop.centroid, sc_contour_coords, bounds=bg_shape)\n",
    "        sc_new_contour = adjust_contour_to_bounds(sc_new_contour, bg_shape)\n",
    "        new_sc_mask = SingleCellStatic.gen_contour_mask(sc_new_contour, bg_img, bbox=None)\n",
    "        new_sc_mask_bool = new_sc_mask > 0 # convert to bool\n",
    "        new_img = _add_sc_to_img_helper(sc, new_img, new_sc_mask, shift, in_place=in_place)\n",
    "\n",
    "        if mask_inplace:\n",
    "            mask = mask.copy()\n",
    "        mask[new_sc_mask_bool] = True\n",
    "        return new_img, sc_new_contour, mask, shift\n",
    "\n",
    "    _, sc1_new_contour, sc1_new_mask, shift1 = add_sc_to_img(sc1, new_img, mask=new_mask, in_place=True, fix_sc_pos=fix_sc1)\n",
    "    _, sc2_new_contour, sc2_new_mask, shift2 = add_sc_to_img(sc2, new_img, mask=new_mask, in_place=True)\n",
    "\n",
    "    new_sc1 = SingleCellStatic(timeframe=SingleImageDataset.DEFAULT_TIME, contour=sc1_new_contour, img_dataset=SingleImageDataset(new_img), mask_dataset=SingleImageDataset(sc1_new_mask))\n",
    "    new_sc2 = SingleCellStatic(timeframe=SingleImageDataset.DEFAULT_TIME, contour=sc2_new_contour, img_dataset=SingleImageDataset(new_img), mask_dataset=SingleImageDataset(sc2_new_mask))\n",
    "    return new_sc1, new_sc2\n",
    "\n",
    "# has_overlap = np.any(new_sc1_mask & new_sc2_mask)\n",
    "# print(has_overlap)\n",
    "# fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "# ax = axes[0][0]\n",
    "# ax.imshow(new_sc1_mask | new_sc2_mask)\n",
    "# ax = axes[0][1]\n",
    "# ax.imshow(new_img)\n",
    "bg_scale = 3.0\n",
    "\n",
    "def viz_check_combined_sc_result(sc1, sc2):\n",
    "    fig, axes = plt.subplots(1, 8, figsize=(18, 5))\n",
    "    ax_idx = 0\n",
    "    ax = axes[ax_idx]\n",
    "    sc1.show_whole_img(ax=ax)\n",
    "    ax.set_title(\"sc1 whole img\")\n",
    "    ax_idx += 1\n",
    "\n",
    "    ax = axes[ax_idx]\n",
    "    sc1.show(ax=ax)\n",
    "    ax_idx += 1\n",
    "\n",
    "    ax = axes[ax_idx]\n",
    "    sc1.show_mask(ax=ax, padding=20)\n",
    "    ax_idx += 1\n",
    "\n",
    "    ax = axes[ax_idx]\n",
    "    sc1.show_contour_img(ax=ax, padding=20)\n",
    "    ax.set_title(\"sc1 contour img\")\n",
    "    ax_idx += 1\n",
    "\n",
    "    ax = axes[ax_idx]\n",
    "    sc2.show_whole_img(ax=ax)\n",
    "    ax.set_title(\"sc2 whole img\")\n",
    "    ax_idx += 1\n",
    "\n",
    "    ax = axes[ax_idx]\n",
    "    sc2.show(ax=ax)\n",
    "    ax_idx += 1\n",
    "\n",
    "    ax = axes[ax_idx]\n",
    "    sc2.show_mask(ax=ax, padding=20)\n",
    "    ax_idx += 1\n",
    "\n",
    "    ax = axes[ax_idx]\n",
    "    sc2.show_contour_img(ax=ax, padding=20)\n",
    "    ax.set_title(\"sc2 contour img\")\n",
    "    ax_idx += 1\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "for i in range(4):\n",
    "    new_sc1, new_sc2 = combine_two_scs_monte_carlo(sc1, sc2, bg_img=None)\n",
    "    viz_check_combined_sc_result(new_sc1, new_sc2)\n",
    "\n",
    "# for i in range(4):\n",
    "#     new_sc1, new_sc2 = combine_two_scs_monte_carlo(sc1, sc2, bg_img=None, fix_sc1=True)\n",
    "#     viz_check_combined_sc_result(new_sc1, new_sc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_check_combined_sc_result(new_sc1, new_sc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_synthetic_overlap_scs(sc1, sc2, max_overlap_percent=0.3, bg_scale=2.0, fix_sc1=False):\n",
    "    # TODO: optimize in the future via computational geometry; now simply use monte carlo for generating required synthetic data\n",
    "    check_flag = False\n",
    "    while not check_flag:\n",
    "        new_sc1, new_sc2 = combine_two_scs_monte_carlo(sc1, sc2, bg_img=None, bg_scale=bg_scale, fix_sc1=fix_sc1)\n",
    "        overlap_mask = np.logical_and(new_sc1.get_mask(), new_sc2.get_mask())\n",
    "        overlap_percent = float(np.sum(overlap_mask)) / min(np.sum(new_sc1.get_mask()), np.sum(new_sc2.get_mask()))\n",
    "        if overlap_percent > 0 and overlap_percent < max_overlap_percent:\n",
    "            check_flag = True\n",
    "    return new_sc1, new_sc2, overlap_percent\n",
    "\n",
    "\n",
    "def gen_synthetic_nonoverlap_scs(min_dist=10, max_dist=100, n=10, ):\n",
    "    pass\n",
    "\n",
    "\n",
    "# check results\n",
    "for i in tqdm(range(4)):\n",
    "    new_sc1, new_sc2, _ = gen_synthetic_overlap_scs(sc1, sc2)\n",
    "    viz_check_combined_sc_result(new_sc1, new_sc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from skimage.measure import find_contours\n",
    "import cv2\n",
    "\n",
    "def show_cv2_contours(contours, img):\n",
    "    im = np.expand_dims(img.astype(np.uint8), axis=2).repeat(3, axis=2) \n",
    "    for k, _ in enumerate(contours):\n",
    "        im = cv.drawContours(im, contours, k, (0, 230, 255), 6)\n",
    "    plt.imshow(im)\n",
    "    plt.show()\n",
    "\n",
    "def merge_two_scs(sc1: SingleCellStatic, sc2: SingleCellStatic):\n",
    "    new_mask = np.logical_or(sc1.get_mask().astype(bool), sc2.get_mask().astype(bool))\n",
    "    plt.imshow(new_mask)\n",
    "    plt.show()\n",
    "    print(np.unique(new_mask))\n",
    "    # contours = find_contours(new_mask, fully_connected=\"high\")\n",
    "\n",
    "    contours, hierarchy = cv2.findContours(new_mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    show_cv2_contours(contours, new_mask)\n",
    "    print(\"#contours found: \", len(contours))\n",
    "    # assert len(contours) == 1, \"only support single contour\"\n",
    "    assert len(contours) != 0, \"must contain at least one contour\"\n",
    "    if len(contours) > 1:\n",
    "        print(\"WARNING: more than one contour found, use the first one\")\n",
    "    new_contour = np.array(contours[0])\n",
    "    # swap xy in new_contour\n",
    "    new_contour = new_contour[:, :, ::-1]\n",
    "    new_contour = new_contour.reshape(-1, 2)\n",
    "    print(np.array(new_contour).shape)\n",
    "    res_sc = SingleCellStatic(\n",
    "        timeframe=SingleImageDataset.DEFAULT_TIME,\n",
    "        contour=new_contour,\n",
    "        img_dataset=sc1.img_dataset,\n",
    "        mask_dataset=SingleImageDataset(new_mask),\n",
    "    )\n",
    "    return res_sc\n",
    "\n",
    "\n",
    "num_cells = 3\n",
    "for i, tmp_scs in enumerate(itertools.combinations(single_cells, num_cells)):\n",
    "    cur_merged_sc = None\n",
    "    for j in range(num_cells):\n",
    "        cur_sc = tmp_scs[j]\n",
    "        if cur_merged_sc is None:\n",
    "            cur_merged_sc = new_sc1.copy()\n",
    "            continue\n",
    "        cur_merged_sc, new_sc2, _ = gen_synthetic_overlap_scs(cur_merged_sc, cur_sc, fix_sc1=True)\n",
    "        cur_merged_sc = merge_two_scs(cur_merged_sc, new_sc2)\n",
    "        print(\"j=\", j)\n",
    "        viz_check_combined_sc_result(cur_merged_sc, new_sc2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subdir = Path(\"synthetic_underseg_overlap\")\n",
    "overseg_out_dir = out_dir / subdir\n",
    "raw_out_dir = overseg_out_dir / \"raw\"\n",
    "\n",
    "# seg_out_dir is the directory containing all raw segmentation masks for training\n",
    "# e.g. the eroded raw segmentation masks\n",
    "seg_out_dir = overseg_out_dir / \"seg\"\n",
    "\n",
    "# raw_seg_dir is the directory containing all raw segmentation masks for recording purposes\n",
    "raw_seg_dir = overseg_out_dir / \"raw_seg_crop\"\n",
    "gt_out_dir = overseg_out_dir / \"gt\"\n",
    "gt_label_out_dir = overseg_out_dir / \"gt_label_mask\"\n",
    "augmented_seg_dir = overseg_out_dir / \"augmented_seg\"\n",
    "raw_transformed_img_dir = overseg_out_dir / \"raw_transformed_img\"\n",
    "augmented_diff_seg_dir = overseg_out_dir / \"augmented_diff_seg\"\n",
    "meta_path = overseg_out_dir / \"metadata.csv\"\n",
    "\n",
    "os.makedirs(raw_out_dir, exist_ok=True)\n",
    "os.makedirs(seg_out_dir, exist_ok=True)\n",
    "os.makedirs(raw_seg_dir, exist_ok=True)\n",
    "os.makedirs(gt_out_dir, exist_ok=True)\n",
    "os.makedirs(augmented_seg_dir, exist_ok=True)\n",
    "os.makedirs(gt_label_out_dir, exist_ok=True)\n",
    "os.makedirs(raw_transformed_img_dir, exist_ok=True)\n",
    "os.makedirs(augmented_diff_seg_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "overseg_train_path_tuples = []\n",
    "augmented_overseg_data = []\n",
    "filename_pattern = \"img-%d_syn-%d.tif\"\n",
    "overseg_metadata = []\n",
    "underseg_erosion_scale_factors = np.linspace(0, 0.1, 10)\n",
    "for sc in tqdm(single_cells):\n",
    "    img_id = sc.timeframe\n",
    "    for syn_id, overseg_datarow in enumerate(sc.uns[overseg_uns_key]):\n",
    "        params = overseg_datarow[1]\n",
    "        img_crop = sc.get_contour_img()\n",
    "        raw_seg_crop = overseg_datarow[0]\n",
    "        eroded_seg_crop = overseg_datarow[1]\n",
    "\n",
    "        combined_gt_label_mask = sc.get_contour_mask()\n",
    "        assert img_crop.shape == raw_seg_crop.shape == combined_gt_label_mask.shape\n",
    "        raw_img_path = raw_out_dir / (filename_pattern % (img_id, syn_id))\n",
    "        seg_img_path = seg_out_dir / (filename_pattern % (img_id, syn_id))\n",
    "        raw_seg_img_path = raw_seg_dir / (filename_pattern % (img_id, syn_id))\n",
    "        gt_img_path = gt_out_dir / (filename_pattern % (img_id, syn_id))\n",
    "        gt_label_img_path = gt_label_out_dir / (filename_pattern % (img_id, syn_id))\n",
    "\n",
    "        # metadata is a dict, containing params used to genereate our synthetic overseg data\n",
    "        meta_info = overseg_datarow[2]\n",
    "        meta_info[\"raw_img_path\"] = raw_img_path\n",
    "        meta_info[\"seg_img_path\"] = seg_img_path\n",
    "        meta_info[\"gt_img_path\"] = gt_img_path\n",
    "        \n",
    "        overseg_metadata.append(meta_info)\n",
    "\n",
    "        # call csn augment helper\n",
    "        csn_augment_helper(img_crop=img_crop, \n",
    "            seg_crop=eroded_seg_crop, \n",
    "            combined_gt_label_mask=combined_gt_label_mask,\n",
    "            overseg_raw_seg_crop=raw_seg_crop,\n",
    "            overseg_raw_seg_img_path=raw_seg_img_path,\n",
    "            scale_factors=underseg_erosion_scale_factors,\n",
    "            train_path_tuples=overseg_train_path_tuples,\n",
    "            augmented_data=augmented_overseg_data,\n",
    "            img_id=img_id,\n",
    "            seg_label=syn_id,\n",
    "            gt_label=sc.timeframe,\n",
    "            raw_img_path=raw_img_path,\n",
    "            seg_img_path=seg_img_path,\n",
    "            gt_img_path=gt_img_path,\n",
    "            gt_label_img_path=gt_label_img_path,\n",
    "            augmented_seg_dir=augmented_seg_dir,\n",
    "            augmented_diff_seg_dir=augmented_diff_seg_dir,\n",
    "            filename_pattern=filename_pattern,\n",
    "        )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to handle two cases:\n",
    "1) there is any overlap between two objects  \n",
    "    a) simply dilate and create underseg cases  \n",
    "2) there is no overlap (future work) \n",
    "    b) fill in the pixels in-between the two objects  \n",
    "    c) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine data.csv files generated in each subfolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = []\n",
    "for subdir in out_dir.iterdir():\n",
    "    if subdir.is_dir():\n",
    "        data_path = subdir / \"data.csv\"\n",
    "        dataframe = pd.read_csv(data_path)\n",
    "        dataframe[\"subdir\"] = subdir.name\n",
    "        dataframes.append(dataframe)\n",
    "combined_dataframe = pd.concat(dataframes)\n",
    "combined_dataframe.to_csv(out_dir / \"train_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(combined_dataframe)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "livecell",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d9c7226d793827cd27273ad20fbb4775c3cb91053ab9378a09de5f8c6f258919"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
